<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Sqoop" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/Sqoop/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T00:49:49.453Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="一、sqoop介绍"><a href="#一、sqoop介绍" class="headerlink" title="一、sqoop介绍"></a>一、sqoop介绍</h1><p><strong>Apache Sqoop是在<code>Hadoop生态体系和RDBMS体系</code>之间<code>传送数据</code>的一种工具。来自于Apache软件基金会提供。</strong></p>
<p>Sqoop工作机制是将导入或导出命令**<code>翻译成mapreduce程序</code>**来实现。在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。</p>
<ul>
<li>Hadoop生态系统包括：HDFS、Hive、Hbase等</li>
<li>RDBMS体系包括：Mysql、Oracle、DB2等</li>
<li>Sqoop可以理解为：<code>“SQL 到 Hadoop 和 Hadoop 到SQL”。</code></li>
</ul>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230201223800617.png" alt="image-20230201223800617"></p>
<p>站在Apache立场看待数据流转问题，可以分为数据的导入导出:</p>
<ul>
<li>Import：数据导入。RDBMS—–&gt;Hadoop</li>
<li>Export：数据导出。Hadoop—-&gt;RDBMS</li>
</ul>
<h1 id="二、sqoop安装"><a href="#二、sqoop安装" class="headerlink" title="二、sqoop安装"></a>二、sqoop安装</h1><p>安装sqoop的前提是已经具备java、mysql、hadoop和hive环境。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">最新稳定版： 1.4.6</span><br><span class="line"></span><br><span class="line">安装位置：node2</span><br><span class="line"></span><br><span class="line">配置文件修改：</span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment">#SQOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> SQOOP_HOME=/export/server/sqoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SQOOP_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$SQOOP_HOME</span>/conf</span><br><span class="line"><span class="built_in">mv</span> sqoop-env-template.sh sqoop-env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi sqoop-env.sh</span><br><span class="line"></span><br><span class="line">export HADOOP_COMMON_HOME= /export/server/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME= /export/server/hadoop</span><br><span class="line">export HIVE_HOME= /export/server/hive</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">加入mysql的jdbc驱动包</span><br><span class="line"><span class="built_in">cp</span> /export/server/hive/lib/mysql-connector-java-5.1.32.jar <span class="variable">$SQOOP_HOME</span>/lib/</span><br></pre></td></tr></table></figure>


<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">验证启动</span><br><span class="line">bin/sqoop list-databases \</span><br><span class="line"> --connect jdbc:mysql://node1:3306/ \</span><br><span class="line"> --username root --password hadoop</span><br><span class="line">本命令会列出所有mysql的数据库。</span><br><span class="line">到这里，整个Sqoop安装工作完成。</span><br></pre></td></tr></table></figure>

<img src=".\md图\sqoop.assets\image-20230202135937633.png" alt="image-20230202135937633" style="zoom:80%;" />

<h1 id="三、Sqoop导入"><a href="#三、Sqoop导入" class="headerlink" title="三、Sqoop导入"></a>三、Sqoop导入</h1><p>“导入工具”<code>导入单个表从RDBMS到HDFS</code>。表中的<code>每一行被视为HDFS的记录</code>。所有记录都存储为文本文件的文本数据</p>
<p>下面的语法用于将数据导入HDFS。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sqoop import (generic-args) (import-args)</span><br></pre></td></tr></table></figure>

<p><strong>Sqoop测试表数据</strong></p>
<p><code>在mysql中创建数据库userdb</code>，然后执行参考资料中的sql脚本：</p>
<p>创建三张表: **<code>emp</code>**雇员表、 **<code>emp_add</code><strong>雇员地址表、</strong><code>emp_conn</code>**雇员联系表。</p>
<img src=".\md图\sqoop.assets\image-20230201233237216.png" alt="image-20230201233237216" style="zoom:80%;" />

<h2 id="1．-全量导入mysql表数据到HDFS"><a href="#1．-全量导入mysql表数据到HDFS" class="headerlink" title="1． 全量导入mysql表数据到HDFS"></a>1． 全量导入mysql表数据到HDFS</h2><p>下面的命令用于从MySQL数据库服务器中的emp表导入HDFS。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example1-mysql-hdfs-start</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--target-dir /sqoop/sqoopresult \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>

<p>其中**<code>--target-dir可以用来指定导出数据存放至HDFS的目录；</code>**</p>
<p>为了验证在HDFS导入的数据，请使用以下命令查看导入的数据：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">cat</span> /sqoopresult/part-m-00000</span><br></pre></td></tr></table></figure>

<p>可以看出它会在HDFS上默认用逗号,分隔emp表的数据和字段。</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230201235032488.png" alt="image-20230201235032488"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> 注意：</span><br><span class="line">- mysql的地址尽量不要使用localhost  请使用ip或者host</span><br><span class="line">- 如果不指定，导入到hdfs默认分隔符是  &quot;,&quot;</span><br><span class="line">- 可以通过-- fields-terminated-by &#x27;\t&#x27;指定具体的分隔符</span><br><span class="line">- 如果表的数据比较大 可以并行启动多个maptask执行导入操作，如果表没有主键，请指定根据哪个字段进行切分（使用--m 指定并行度）</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example2-mysql-hdfs-terminated</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/sqoopresult2 \</span><br><span class="line">--fields-terminated-by &#x27;\t&#x27; \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230201235320242.png" alt="image-20230201235320242"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example3-mysql-hdfs-split</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/sqoopresult3 \</span><br><span class="line">--fields-terminated-by &#x27;\t&#x27; \</span><br><span class="line">--split-by id \</span><br><span class="line">--table emp --m 2</span><br></pre></td></tr></table></figure>

<p> <strong>part-m-00000</strong></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230201235706065.png" alt="image-20230201235706065"></p>
<p> <strong>part-m-00001</strong></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230201235723198.png" alt="image-20230201235723198"></p>
<h2 id="2．-全量导入mysql表数据到HIVE"><a href="#2．-全量导入mysql表数据到HIVE" class="headerlink" title="2． 全量导入mysql表数据到HIVE"></a>2． 全量导入mysql表数据到HIVE</h2><h3 id="2-1．-方式一：先复制表结构到hive中再导入数据"><a href="#2-1．-方式一：先复制表结构到hive中再导入数据" class="headerlink" title="2.1． 方式一：先复制表结构到hive中再导入数据"></a>2.1． 方式一：先复制表结构到hive中再导入数据</h3><h4 id="1-在hive中新建数据库sqoop-test用于测试"><a href="#1-在hive中新建数据库sqoop-test用于测试" class="headerlink" title="1.在hive中新建数据库sqoop_test用于测试"></a>1.在hive中新建数据库<strong>sqoop_test</strong>用于测试</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> sqoop_test comment &quot;this is sqoop db&quot; <span class="keyword">with</span> dbproperties(<span class="string">&#x27;createdBy&#x27;</span><span class="operator">=</span><span class="string">&#x27;yzl&#x27;</span>);</span><br><span class="line"></span><br><span class="line">use sqoop_test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"></span><br><span class="line"><span class="keyword">desc</span> formatted emp_add_sp;</span><br></pre></td></tr></table></figure>



<h4 id="2-将关系型数据的表结构复制到hive中"><a href="#2-将关系型数据的表结构复制到hive中" class="headerlink" title="2.将关系型数据的表结构复制到hive中"></a>2.将关系型数据的表结构复制到hive中</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example4-1-mysql-hive-structure</span></span><br><span class="line">bin/sqoop create-hive-table \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--table emp_add \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--hive-table sqoop_test.emp_add_sp</span><br><span class="line"></span><br><span class="line">其中：</span><br><span class="line"> --table emp_add为mysql中的数据库userdb中的表。  </span><br><span class="line"> --hive-table emp_add_sp 为hive中新建的表名称。</span><br></pre></td></tr></table></figure>



<h4 id="3-从关系数据库导入文件到hive中"><a href="#3-从关系数据库导入文件到hive中" class="headerlink" title="3.从关系数据库导入文件到hive中"></a>3.从关系数据库导入文件到hive中</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example4-2-mysql-hive-data</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table emp_add \</span><br><span class="line">--hive-table sqoop_test.emp_add_sp \</span><br><span class="line">--hive-import \</span><br><span class="line">--m 1</span><br></pre></td></tr></table></figure>



<h3 id="2-2．-方式二：直接复制表结构数据到hive中"><a href="#2-2．-方式二：直接复制表结构数据到hive中" class="headerlink" title="2.2． 方式二：直接复制表结构数据到hive中"></a>2.2． 方式二：直接复制表结构数据到hive中</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example5-mysql-hive</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table emp_conn \</span><br><span class="line">--hive-import \</span><br><span class="line">--m 1 \</span><br><span class="line">--hive-database sqoop_test;</span><br></pre></td></tr></table></figure>

<img src=".\md图\sqoop.assets\image-20230201223342410.png" alt="image-20230201223342410" style="zoom:80%;" />



<h2 id="3．-导入表数据子集-where过滤"><a href="#3．-导入表数据子集-where过滤" class="headerlink" title="3． 导入表数据子集(where过滤)"></a>3． 导入表数据子集(where过滤)</h2><blockquote>
<p>–where可以指定从关系数据库导入数据时的查询条件。它执行在数据库服务器相应的SQL查询，并将结果存储在HDFS的目标目录。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example6-mysql-hdfs-where</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--where &quot;city =&#x27;sec-bad&#x27;&quot; \</span><br><span class="line">--target-dir /sqoop/wherequery \</span><br><span class="line">--table emp_add --m 1</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230203103145831.png" alt="image-20230203103145831"></p>
<h2 id="4．-导入表数据子集-query查询"><a href="#4．-导入表数据子集-query查询" class="headerlink" title="4． 导入表数据子集(query查询)"></a>4． 导入表数据子集(query查询)</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">注意事项：</span><br><span class="line">-使用query sql语句来进行查找不能加参数--table ;</span><br><span class="line">-并且必须要添加where条件;</span><br><span class="line">-并且where条件后面必须带一个$CONDITIONS 这个字符串;</span><br><span class="line">-并且这个sql语句必须用单引号，不能用双引号;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example7-mysql-hdfs-query</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/wherequery2 \</span><br><span class="line">--query &#x27;select id,name,deg from emp WHERE  id&gt;1203 and $CONDITIONS&#x27; \</span><br><span class="line">--split-by id \</span><br><span class="line">--fields-terminated-by &#x27;\001&#x27; \</span><br><span class="line">--m 2</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230203103632861.png" alt="image-20230203103632861"></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230203103652011.png" alt="image-20230203103652011"></p>
<blockquote>
<p>sqoop命令中 <strong>–split-by id</strong>通常配合**-m 10**参数使用。<br>首先sqoop会向关系型数据库比如mysql发送一个命令:select max(id),min(id) from test。<br>然后会把max、min之间的区间平均分为10分，最后10个并行的map去找数据库，导数据就正式开始。</p>
</blockquote>
<h2 id="5．-增量导入"><a href="#5．-增量导入" class="headerlink" title="5． 增量导入"></a>5． 增量导入</h2><p>在实际工作当中，数据的导入，很多时候都是只需要导入增量数据即可，并不需要将表中的数据每次都全部导入到hive或者hdfs当中去，这样会造成数据重复的问题。因此一般都是选用一些字段进行增量的导入， sqoop支持增量的导入数据。</p>
<p><strong>增量导入是仅导入新添加的表中的行的技术。</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">--check-column (col)</span><br><span class="line">用来指定一些列，这些列在增量导入时用来检查这些数据是否作为增量数据进行导入，和关系型数据库中的自增字段及时间戳类似。</span><br><span class="line">注意:这些被指定的列的类型不能使任意字符类型，如char、varchar等类型都是不可以的，同时-- check-column可以去指定多个列。</span><br><span class="line"></span><br><span class="line">--incremental (mode)</span><br><span class="line">append：追加，比如对大于last-value指定的值之后的记录进行追加导入。</span><br><span class="line">lastmodified：最后的修改时间，追加last-value指定的日期之后的记录</span><br><span class="line"></span><br><span class="line">--last-value (value)</span><br><span class="line">指定自从上次导入后列的最大值（大于该指定的值），也可以自己设定某一值</span><br></pre></td></tr></table></figure>

<h3 id="5-1．-Append模式增量导入"><a href="#5-1．-Append模式增量导入" class="headerlink" title="5.1． Append模式增量导入"></a>5.1． Append模式增量导入</h3><p>执行以下指令先将我们之前的数据导入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example8-1-mysql-hdfs-append</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/appendresult \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>

<p>使用hdfs dfs -cat查看生成的数据文件，发现数据已经导入到hdfs中</p>
<p>然后在mysql的emp表中插入2条数据:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> `userdb`.`emp` (`id`, `name`, `deg`, `salary`, `dept`) <span class="keyword">values</span> (<span class="string">&#x27;1206&#x27;</span>, <span class="string">&#x27;allen&#x27;</span>, <span class="string">&#x27;admin&#x27;</span>, <span class="string">&#x27;30000&#x27;</span>, <span class="string">&#x27;tp&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> `userdb`.`emp` (`id`, `name`, `deg`, `salary`, `dept`) <span class="keyword">values</span> (<span class="string">&#x27;1207&#x27;</span>, <span class="string">&#x27;woon&#x27;</span>, <span class="string">&#x27;admin&#x27;</span>, <span class="string">&#x27;40000&#x27;</span>, <span class="string">&#x27;tp&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>执行如下的指令，实现增量的导入:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example8-2-mysql-hdfs-append</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table emp --m 1 \</span><br><span class="line">--target-dir /sqoop/appendresult \</span><br><span class="line">--incremental append \</span><br><span class="line">--check-column id \</span><br><span class="line">--last-value 1205</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">总结：增量数据的导入</span><br><span class="line">- 所谓的增量数据指的是上次至今中间新增加的数据</span><br><span class="line">- sqoop支持两种模式的增量导入 </span><br><span class="line">- append追加 根据数值类型字段进行追加导入  大于指定的last-value</span><br><span class="line">- lastmodified 根据时间戳类型字段进行追加  大于等于指定的last-value</span><br><span class="line">- 注意在lastmodified 模式下 还分为两种情形：append  merge-key</span><br></pre></td></tr></table></figure>

<img src=".\md图\sqoop.assets\image-20230202134830695.png" alt="image-20230202134830695" style="zoom:150%;" />

<p>最后验证导入数据目录 可以发现多了一个文件 里面就是增量数据</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202134847323.png" alt="image-20230202134847323"></p>
<h3 id="5-2．-Lastmodified模式增量导入"><a href="#5-2．-Lastmodified模式增量导入" class="headerlink" title="5.2． Lastmodified模式增量导入"></a>5.2． Lastmodified模式增量导入</h3><p>（1）首先创建一个customer表，指定一个时间戳字段：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> customertest(id <span class="type">int</span>,name <span class="type">varchar</span>(<span class="number">20</span>),last_mod <span class="type">timestamp</span> <span class="keyword">default</span> <span class="built_in">current_timestamp</span> <span class="keyword">on</span> <span class="keyword">update</span> <span class="built_in">current_timestamp</span>);</span><br></pre></td></tr></table></figure>

<p><strong>此处的时间戳设置为在数据的产生和更新时都会发生改变.</strong> </p>
<p>（2）插入如下记录:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customertest(id,name) <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">&#x27;neil&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customertest(id,name) <span class="keyword">values</span>(<span class="number">2</span>,<span class="string">&#x27;jack&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customertest(id,name) <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">&#x27;martin&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customertest(id,name) <span class="keyword">values</span>(<span class="number">4</span>,<span class="string">&#x27;tony&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customertest(id,name) <span class="keyword">values</span>(<span class="number">5</span>,<span class="string">&#x27;eric&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>（3）此时执行sqoop指令将数据导入hdfs:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example9-1-mysql-hdfs-Lastmodified</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/lastmodifiedresult \</span><br><span class="line">--table customertest --m 1</span><br></pre></td></tr></table></figure>

<p>查看此时导入的结果数据：</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202135317642.png" alt="image-20230202135317642"></p>
<p>（4）再次插入一条数据进入customertest表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customertest(id,name) <span class="keyword">values</span>(<span class="number">6</span>,<span class="string">&#x27;james&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>（5）使用incremental的方式进行增量的导入:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example9-2-mysql-hdfs-Lastmodified</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table customertest \</span><br><span class="line">--target-dir /sqoop/lastmodifiedresult \</span><br><span class="line">--check-column last_mod \</span><br><span class="line">--incremental lastmodified \</span><br><span class="line">--last-value &quot;2019-05-28 18:42:06&quot; \</span><br><span class="line">--m 1 \</span><br><span class="line">--append</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202135437377.png" alt="image-20230202135437377"></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202135443401.png" alt="image-20230202135443401"></p>
<p>此处已经会导入我们最后插入的一条记录,但是我们却发现此处插入了2条数据，这是为什么呢？ </p>
<p>这是因为采用<strong>lastmodified模式去处理增量时，会将大于等于last-value值的数据当做增量插入。</strong></p>
<h3 id="5-3．-Lastmodified模式-append、merge-key"><a href="#5-3．-Lastmodified模式-append、merge-key" class="headerlink" title="5.3． Lastmodified模式:append、merge-key"></a>5.3． Lastmodified模式:append、merge-key</h3><p>使用lastmodified模式进行增量处理要指定增量数据是以</p>
<ul>
<li><strong>append</strong>模式(附加)</li>
<li><strong>merge-key</strong>(合并)模式添加</li>
</ul>
<p>下面演示使用merge-by的模式进行增量更新</p>
<p>（1）我们去更新 id为1的name字段。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> customertest <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;Neil&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>更新之后，这条数据的时间戳会更新为更新数据时的系统时间.</p>
<p>（2）执行如下指令，把id字段作为merge-key:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example10-mysql-hdfs-merge-key</span></span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table customertest \</span><br><span class="line">--target-dir /sqoop/lastmodifiedresult \</span><br><span class="line">--check-column last_mod \</span><br><span class="line">--incremental lastmodified \</span><br><span class="line">--last-value &quot;2019-05-28 18:42:06&quot; \</span><br><span class="line">--m 1 \</span><br><span class="line">--merge-key id</span><br></pre></td></tr></table></figure>

<blockquote>
<p>由于merge-key这种模式是进行了一次完整的mapreduce操作，<br>因此最终我们在lastmodifiedresult文件夹下可以看到生成的为part-r-00000这样的文件，<br>会发现<strong>id&#x3D;1的name</strong>已经得到修改，同时<strong>新增了id&#x3D;6</strong>的数据</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">总结：</span><br><span class="line">关于lastmodified 中的两种模式：</span><br><span class="line">- append 只会追加增量数据到一个新的文件中  并且会产生数据的重复问题</span><br><span class="line">  因为默认是从指定的last-value 大于等于其值的数据开始导入</span><br><span class="line">- merge-key 把增量的数据合并到一个文件中  处理追加增量数据之外 如果之前的数据有变化修改</span><br><span class="line">  也可以进行修改操作 底层相当于进行了一次完整的mr作业。数据不会重复。</span><br></pre></td></tr></table></figure>



<h1 id="四、-Sqoop导出"><a href="#四、-Sqoop导出" class="headerlink" title="四、 Sqoop导出"></a>四、 Sqoop导出</h1><p><strong>将数据从Hadoop生态体系导出到RDBMS数据库导出前，目标表必须存在于目标数据库中。</strong></p>
<p>export有三种模式：</p>
<ol>
<li><p>默认操作是从将文件中的数据使用INSERT语句插入到表中。</p>
</li>
<li><p>更新模式：Sqoop将生成UPDATE替换数据库中现有记录的语句。</p>
</li>
<li><p>调用模式：Sqoop将为每条记录创建一个存储过程调用。</p>
</li>
</ol>
<p>以下是export命令语法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sqoop <span class="built_in">export</span> (generic-args) (export-args)</span></span><br></pre></td></tr></table></figure>



<h2 id="1．-默认模式导出HDFS数据到mysql"><a href="#1．-默认模式导出HDFS数据到mysql" class="headerlink" title="1． 默认模式导出HDFS数据到mysql"></a>1． 默认模式导出HDFS数据到mysql</h2><p>默认情况下，sqoop export将每行输入记录转换成一条INSERT语句，添加到目标数据库表中。如果数据库中的表具有约束条件（例如，其值必须唯一的主键列）并且已有数据存在，则必须注意避免插入违反这些约束条件的记录。如果INSERT语句失败，导出过程将失败。<strong>此模式主要用于将记录导出到可以接收这些结果的空表中</strong>。通常用于全表数据导出。</p>
<p>导出时可以是将Hive表中的全部记录或者HDFS数据（可以是全部字段也可以部分字段）导出到Mysql目标表。</p>
<h3 id="1-1．-准备HDFS数据"><a href="#1-1．-准备HDFS数据" class="headerlink" title="1.1． 准备HDFS数据"></a>1.1． 准备HDFS数据</h3><p> 在HDFS文件系统中“&#x2F;emp&#x2F;”目录的下创建一个文件emp_data.txt：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /export/data/sqoop-data/emp/</span><br><span class="line"></span><br><span class="line">vim emp_data.txt</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1201,gopal,manager,50000,TP</span><br><span class="line">1202,manisha,preader,50000,TP</span><br><span class="line">1203,kalil,php dev,30000,AC</span><br><span class="line">1204,prasanth,php dev,30000,AC</span><br><span class="line">1205,kranthi,admin,20000,TP</span><br><span class="line">1206,satishp,grpdes,20000,GR</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传至hdfs</span></span><br><span class="line">hadoop fs -mkdir /sqoop/emp_data</span><br><span class="line">hadoop fs -put emp_data.txt /sqoop/emp_data </span><br></pre></td></tr></table></figure>

<h3 id="1-2．-手动创建mysql中的目标表"><a href="#1-2．-手动创建mysql中的目标表" class="headerlink" title="1.2． 手动创建mysql中的目标表"></a>1.2． 手动创建mysql中的目标表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> use userdb;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> employee ( </span><br><span class="line">   id <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">primary</span> key, </span><br><span class="line">   name <span class="type">varchar</span>(<span class="number">20</span>), </span><br><span class="line">   deg <span class="type">varchar</span>(<span class="number">20</span>),</span><br><span class="line">   salary <span class="type">int</span>,</span><br><span class="line">   dept <span class="type">varchar</span>(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>

<h3 id="1-3．-执行导出命令"><a href="#1-3．-执行导出命令" class="headerlink" title="1.3． 执行导出命令"></a>1.3． 执行导出命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example10-hdfs-mysql-export</span></span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table employee1 \</span><br><span class="line">--columns id,name,deg,salary,dept \</span><br><span class="line">--export-dir /sqoop/emp_data/</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202170211379.png" alt="image-20230202170211379"></p>
<h3 id="1-4．-相关配置参数"><a href="#1-4．-相关配置参数" class="headerlink" title="1.4． 相关配置参数"></a>1.4． 相关配置参数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--input-fields-terminated-by &#x27;\t&#x27;  </span><br><span class="line">指定文件中的分隔符</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--columns </span><br><span class="line">选择列并控制它们的排序。当导出数据文件和目标表字段列顺序完全一致的时候可以不写。否则以逗号为间隔选择和排列各个列。没有被包含在–columns后面列名或字段要么具备默认值，要么就允许插入空值。否则数据库会拒绝接受sqoop导出的数据，导致Sqoop作业失败</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--export-dir 导出目录，在执行导出的时候，必须指定这个参数，同时需要具备--table或--call参数两者之一，</span><br><span class="line">--table是指的导出数据库当中对应的表，</span><br><span class="line">--call是指的某个存储过程。</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--input-null-string --input-null-non-string</span><br><span class="line">如果没有指定第一个参数，对于字符串类型的列来说，“NULL”这个字符串就回被翻译成空值，如果没有使用第二个参数，无论是“NULL”字符串还是说空字符串也好，对于非字符串类型的字段来说，这两个类型的空串都会被翻译成空值。比如：</span><br><span class="line">--input-null-string &quot;\\N&quot; --input-null-non-string &quot;\\N&quot;</span><br></pre></td></tr></table></figure>

<h3 id="1-5-注意"><a href="#1-5-注意" class="headerlink" title="1.5 注意"></a>1.5 注意</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">数据导出操作</span><br><span class="line"></span><br><span class="line">- 注意：导出的目标表需要自己手动提前创建 也就是sqoop并不会帮我们创建复制表结构</span><br><span class="line">- 导出有三种模式：</span><br><span class="line">  - 默认模式   目标表是空表  底层把数据一条条insert进去</span><br><span class="line">  - 更新模式   底层是update语句</span><br><span class="line">  - 调用模式   调用存储过程</span><br><span class="line">- 相关配置参数</span><br><span class="line">  - 导出文件的分隔符  如果不指定 默认以“,”去切割读取数据文件   --input-fields-terminated-by</span><br><span class="line">  - 如果文件的字段顺序和表中顺序不一致 需要--columns 指定 多个字段之间以&quot;,&quot;</span><br><span class="line">  - 导出的时候需要指定导出数据的目的 export-dir 和导出到目标的表名或者存储过程名</span><br><span class="line">  - 针对空字符串类型和非字符串类型的转换  &quot;\n&quot;</span><br></pre></td></tr></table></figure>



<h2 id="2．-更新导出（updateonly模式）"><a href="#2．-更新导出（updateonly模式）" class="headerlink" title="2． 更新导出（updateonly模式）"></a>2． 更新导出（updateonly模式）</h2><h3 id="2-1．-参数说明"><a href="#2-1．-参数说明" class="headerlink" title="2.1． 参数说明"></a>2.1． 参数说明</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- update-key,更新标识，即根据某个字段进行更新，例如id，可以指定多个更新标识的字段，多个字段之间用逗号分隔。</span><br><span class="line"></span><br><span class="line">-- updatemod，指定updateonly（默认模式），仅仅更新已存在的数据记录，不会插入新纪录。</span><br></pre></td></tr></table></figure>

<h3 id="2-2．-准备HDFS数据"><a href="#2-2．-准备HDFS数据" class="headerlink" title="2.2． 准备HDFS数据"></a>2.2． 准备HDFS数据</h3><p>在HDFS文件系统中&#x2F;sqoop&#x2F;updateonly_1&#x2F;目录的下创建一个文件updateonly_1.txt：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1201,gopal,manager,50000</span><br><span class="line">1202,manisha,preader,50000</span><br><span class="line">1203,kalil,php dev,30000</span><br></pre></td></tr></table></figure>

<h3 id="2-3．-手动创建mysql中的目标表"><a href="#2-3．-手动创建mysql中的目标表" class="headerlink" title="2.3． 手动创建mysql中的目标表"></a>2.3． 手动创建mysql中的目标表</h3><p>手动创建mysql中的目标表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> USE userdb;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> updateonly ( </span><br><span class="line">   id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line">   name <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">   deg <span class="type">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">   salary <span class="type">INT</span>);</span><br></pre></td></tr></table></figure>

<h3 id="2-4．-先执行全部导出操作"><a href="#2-4．-先执行全部导出操作" class="headerlink" title="2.4． 先执行全部导出操作"></a>2.4． 先执行全部导出操作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example11-1-hdfs-mysql-export-updateonly</span></span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table updateonly \</span><br><span class="line">--export-dir /sqoop/updateonly_1/</span><br></pre></td></tr></table></figure>

<h3 id="2-5．-查看此时mysql中的数据"><a href="#2-5．-查看此时mysql中的数据" class="headerlink" title="2.5． 查看此时mysql中的数据"></a>2.5． 查看此时mysql中的数据</h3><p>可以发现是全量导出，全部的数据</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202213846761.png" alt="image-20230202213846761"></p>
<h3 id="2-6．-新增一个文件"><a href="#2-6．-新增一个文件" class="headerlink" title="2.6． 新增一个文件"></a>2.6． 新增一个文件</h3><p>新增一个文件updateonly_2.txt：<strong>修改了前三条数据并且新增了一条记录</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1201,gopal,manager,1212</span><br><span class="line">1202,manisha,preader,1313</span><br><span class="line">1203,kalil,php dev,1414</span><br><span class="line">1204,allen,java,1515</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /sqoop/updateonly_2</span><br><span class="line">hadoop fs -put updateonly_2.txt /sqoop/updateonly_2</span><br></pre></td></tr></table></figure>

<h3 id="2-7．-执行更新导出"><a href="#2-7．-执行更新导出" class="headerlink" title="2.7． 执行更新导出"></a>2.7． 执行更新导出</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example11-2-hdfs-mysql-export-updateonly</span></span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table updateonly \</span><br><span class="line">--export-dir /sqoop/updateonly_2 \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode updateonly</span><br></pre></td></tr></table></figure>

<h3 id="2-8．-查看最终结果"><a href="#2-8．-查看最终结果" class="headerlink" title="2.8． 查看最终结果"></a>2.8． 查看最终结果</h3><p>虽然导出时候的日志显示导出4条记录：</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202214142738.png" alt="image-20230202214142738"></p>
<p>但最终只进行了更新操作</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202214154136.png" alt="image-20230202214154136"></p>
<h2 id="3．-更新导出（allowinsert模式）"><a href="#3．-更新导出（allowinsert模式）" class="headerlink" title="3． 更新导出（allowinsert模式）"></a>3． 更新导出（allowinsert模式）</h2><h3 id="3-1．-参数说明"><a href="#3-1．-参数说明" class="headerlink" title="3.1． 参数说明"></a>3.1． 参数说明</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- update-key，更新标识，即根据某个字段进行更新，例如id，可以指定多个更新标识的字段，多个字段之间用逗号分隔。</span><br><span class="line"></span><br><span class="line">-- updatemod，指定allowinsert，更新已存在的数据记录，同时插入新纪录。实质上是一个insert &amp; update的操作。</span><br></pre></td></tr></table></figure>

<h3 id="3-2．-准备HDFS数据"><a href="#3-2．-准备HDFS数据" class="headerlink" title="3.2． 准备HDFS数据"></a>3.2． 准备HDFS数据</h3><p>在HDFS &#x2F;sqoop&#x2F;allowinsert_1&#x2F;目录的下创建一个文件allowinsert_1.txt：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1201,gopal,manager,50000</span><br><span class="line">1202,manisha,preader,50000</span><br><span class="line">1203,kalil,php dev,30000</span><br></pre></td></tr></table></figure>

<h3 id="3-3．-手动创建mysql中的目标表"><a href="#3-3．-手动创建mysql中的目标表" class="headerlink" title="3.3． 手动创建mysql中的目标表"></a>3.3． 手动创建mysql中的目标表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> USE userdb;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> allowinsert ( </span><br><span class="line">   id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line">   name <span class="type">VARCHAR</span>(<span class="number">20</span>), </span><br><span class="line">   deg <span class="type">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">   salary <span class="type">INT</span>);</span><br></pre></td></tr></table></figure>

<h3 id="3-4．-先执行全部导出操作"><a href="#3-4．-先执行全部导出操作" class="headerlink" title="3.4． 先执行全部导出操作"></a>3.4． 先执行全部导出操作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example12-1-hdfs-mysql-export-allowinsert</span></span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table allowinsert \</span><br><span class="line">--export-dir /sqoop/allowinsert_1/</span><br></pre></td></tr></table></figure>

<h3 id="3-5．-查看此时mysql中的数据"><a href="#3-5．-查看此时mysql中的数据" class="headerlink" title="3.5． 查看此时mysql中的数据"></a>3.5． 查看此时mysql中的数据</h3><p>可以发现是全量导出，全部的数据</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202214522375.png" alt="image-20230202214522375"></p>
<h3 id="3-6．-新增文件"><a href="#3-6．-新增文件" class="headerlink" title="3.6． 新增文件"></a>3.6． 新增文件</h3><p>创建文件allowinsert_2.txt。修改前三条数据并且新增了一条记录。上传至 &#x2F;sqoop&#x2F;allowinsert_2&#x2F;目录下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1201,gopal,manager,1212</span><br><span class="line">1202,manisha,preader,1313</span><br><span class="line">1203,kalil,php dev,1414</span><br><span class="line">1204,allen,java,1515</span><br></pre></td></tr></table></figure>

<h3 id="3-7．-执行更新导出"><a href="#3-7．-执行更新导出" class="headerlink" title="3.7． 执行更新导出"></a>3.7． 执行更新导出</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example12-2-hdfs-mysql-export-allowinsert</span></span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root --password hadoop \</span><br><span class="line">--table allowinsert \</span><br><span class="line">--export-dir /sqoop/allowinsert_2/ \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode allowinsert</span><br></pre></td></tr></table></figure>

<h3 id="3-8．-查看最终结果"><a href="#3-8．-查看最终结果" class="headerlink" title="3.8． 查看最终结果"></a>3.8． 查看最终结果</h3><p>导出时候的日志显示导出4条记录：</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202214838765.png" alt="image-20230202214838765"></p>
<p>数据进行更新操作的同时也进行了新增的操作</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Csqoop.assets%5Cimage-20230202214850120.png" alt="image-20230202214850120"></p>
<h3 id="3-9-总结"><a href="#3-9-总结" class="headerlink" title="3.9 总结"></a>3.9 总结</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">更新导出</span><br><span class="line"></span><br><span class="line">- updateonly  只更新已经存在的数据  不会执行insert增加新的数据</span><br><span class="line">- allowinsert  更新已有的数据  插入新的数据 底层相当于insert&amp;update</span><br></pre></td></tr></table></figure>

<h1 id="五、sqoop-job作业介绍"><a href="#五、sqoop-job作业介绍" class="headerlink" title="五、sqoop job作业介绍"></a>五、sqoop job作业介绍</h1><h2 id="1-job语法"><a href="#1-job语法" class="headerlink" title="1.job语法"></a>1.job语法</h2><p>以下是创建Sqoop作业的语法。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sqoop job (generic-args) (job-args)</span></span><br><span class="line">   [-- [subtool-name] (subtool-args)]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sqoop-job (generic-args) (job-args)</span></span><br><span class="line">   [-- [subtool-name] (subtool-args)]</span><br></pre></td></tr></table></figure>

<h2 id="2-创建job-–create"><a href="#2-创建job-–create" class="headerlink" title="2.创建job(–create)"></a>2.创建job(–create)</h2><p>在这里，我们创建一个名为myjob，这可以从RDBMS表的数据导入到HDFS作业。下面的命令用于创建一个从DB数据库的employee表导入到HDFS文件的作业。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example13-1-mysql-hdfs-job</span></span><br><span class="line">bin/sqoop job --create myjob -- import --connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/sqoopresult555 \</span><br><span class="line">--table emp --m 1</span><br><span class="line"></span><br><span class="line">注意import前要有空格</span><br></pre></td></tr></table></figure>

<h2 id="3-验证job-–list"><a href="#3-验证job-–list" class="headerlink" title="3.验证job (–list)"></a>3.验证job (–list)</h2><p><strong>‘–list’</strong> 参数是用来验证保存的作业。下面的命令用来验证保存Sqoop作业的列表。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example13-2-mysql-hdfs-job</span></span><br><span class="line">bin/sqoop job --list</span><br></pre></td></tr></table></figure>

<p>它显示了保存作业列表。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Available jobs: </span><br><span class="line">   myjob</span><br></pre></td></tr></table></figure>

<h2 id="4-检查job-–show"><a href="#4-检查job-–show" class="headerlink" title="4.检查job(–show)"></a>4.检查job(–show)</h2><p><strong>‘–show’</strong> 参数用于检查或验证特定的工作，及其详细信息。以下命令和样本输出用来验证一个名为myjob的作业。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example13-3-mysql-hdfs-job</span></span><br><span class="line">bin/sqoop job --show myjob</span><br></pre></td></tr></table></figure>

<p>它显示了工具和它们的选择，这是使用在myjob中作业情况。</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Job</span>: <span class="string">myjob </span></span><br><span class="line"> <span class="attr">Tool</span>: <span class="string">import Options:</span></span><br><span class="line"> <span class="attr">----------------------------</span> <span class="string"></span></span><br><span class="line"> <span class="attr">direct.import</span> = <span class="string">true</span></span><br><span class="line"> <span class="attr">codegen.input.delimiters.record</span> = <span class="string">0</span></span><br><span class="line"> <span class="attr">hdfs.append.dir</span> = <span class="string">false </span></span><br><span class="line"> <span class="attr">db.table</span> = <span class="string">employee</span></span><br><span class="line"> <span class="attr">...</span></span><br><span class="line"> <span class="attr">incremental.last.value</span> = <span class="string">1206</span></span><br><span class="line"> <span class="attr">...</span></span><br></pre></td></tr></table></figure>

<h2 id="5-执行job-–exec"><a href="#5-执行job-–exec" class="headerlink" title="5.执行job (–exec)"></a>5.执行job (–exec)</h2><p><strong>‘–exec’</strong> 选项用于执行保存的作业。下面的命令用于执行保存的作业称为myjob。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example13-4-mysql-hdfs-job</span></span><br><span class="line">bin/sqoop job --exec myjob</span><br><span class="line"></span><br><span class="line">sqoop需要输入mysql密码</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>它会显示下面的输出。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">10/08/19 13:08:45 INFO tool.CodeGenTool: Beginning code generation </span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h2 id="6-job的免密输入"><a href="#6-job的免密输入" class="headerlink" title="6.job的免密输入"></a>6.job的免密输入</h2><p>sqoop在创建job时，使用–password-file参数，可以避免输入mysql密码，如果使用–password将出现警告，并且每次都要手动输入密码才能执行job，<strong>sqoop规定密码文件必须存放在HDFS上，并且权限必须是400</strong>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo -n &quot;hadoop&quot; &gt; node1-mysql.pwd</span><br><span class="line">hadoop fs -mkdir -p /sqoop/pwd/</span><br><span class="line">hadoop fs -put node1-mysql.pwd /sqoop/pwd/</span><br><span class="line">hadoop fs -chmod 400 /sqoop/pwd/node1-mysql.pwd</span><br></pre></td></tr></table></figure>

<p><strong>检查sqoop的sqoop-site.xml是否存在如下配置：</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>sqoop.metastore.client.record.password<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, allow saved passwords in the metastore.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><h5 id="创建sqoop-job"><a href="#创建sqoop-job" class="headerlink" title="创建sqoop job"></a>创建sqoop job</h5></li>
</ul>
<p>在创建job时，使用–password-file参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example14-1-mysql-hdfs-job-nopwd</span></span><br><span class="line">bin/sqoop job --create myjob2 -- import --connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password-file /sqoop/pwd/node1-mysql.pwd \</span><br><span class="line">--target-dir /sqoop/sqoopresult666 \</span><br><span class="line">--table emp --m 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><h5 id="执行job"><a href="#执行job" class="headerlink" title="执行job"></a>执行job</h5></li>
</ul>
<p>通过命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">example14-2-mysql-hdfs-job-nopwd</span></span><br><span class="line">sqoop job -exec myjob2</span><br></pre></td></tr></table></figure>

<p>如果password文件格式错误会有如下提示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ERROR manager.SqlManager: Error executing statement: java.sql.SQLException: Access denied for user &#x27;root&#x27;@&#x27;spark220&#x27; (using password: YES)</span><br><span class="line"></span><br><span class="line">ERROR tool.ImportTool: Encountered IOException running import job: java.io.IOException: No columns to generate for ClassWriter at org.apache.sqoop.orm.ClassWriter.generate(ClassWriter.java:1652)</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/Sqoop/" data-id="clj254b6n000400ur59ozec6a" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark部署文档" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/Spark%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T00:49:49.451Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Spark-Local环境部署"><a href="#Spark-Local环境部署" class="headerlink" title="Spark Local环境部署"></a>Spark Local环境部署</h1><h2 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h2><p><a target="_blank" rel="noopener" href="https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz">https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz</a></p>
<h2 id="条件"><a href="#条件" class="headerlink" title="条件"></a>条件</h2><ul>
<li>PYTHON 推荐3.8</li>
<li>JDK 1.8</li>
</ul>
<h2 id="Anaconda-On-Linux-安装"><a href="#Anaconda-On-Linux-安装" class="headerlink" title="Anaconda On Linux 安装"></a>Anaconda On Linux 安装</h2><p>本次课程的Python环境需要安装到Linux(虚拟机)和Windows(本机)上</p>
<p>参见最下方, 附1: Anaconda On Linux 安装</p>
<h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><p>解压下载的Spark安装包</p>
<p><code>tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</code></p>
<h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><p>配置Spark由如下5个环境变量需要设置</p>
<ul>
<li>SPARK_HOME: 表示Spark安装路径在哪里 </li>
<li>PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器 </li>
<li>JAVA_HOME: 告知Spark Java在哪里 </li>
<li>HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里 </li>
<li>HADOOP_HOME: 告知Spark  Hadoop安装在哪里</li>
</ul>
<p>这5个环境变量 都需要配置在: <code>/etc/profile</code>中<br>​</p>
<p><img src="/./md%E5%9B%BE/spark.assets/1.jpg"></p>
<p>PYSPARK_PYTHON和 JAVA_HOME 需要同样配置在: <code>/root/.bashrc</code>中</p>
<p><img src="/./md%E5%9B%BE/spark.assets/2.jpg"></p>
<h2 id="上传Spark安装包"><a href="#上传Spark安装包" class="headerlink" title="上传Spark安装包"></a>上传Spark安装包</h2><p>资料中提供了: <code>spark-3.2.0-bin-hadoop3.2.tgz</code></p>
<p>上传这个文件到Linux服务器中</p>
<p>将其解压, 课程中将其解压(安装)到: <code>/export/server</code>内.</p>
<p><code>tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</code></p>
<p>由于spark目录名称很长, 给其一个软链接:</p>
<p><code>ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</code><br>​</p>
<p><img src="/./md%E5%9B%BE/spark.assets/3.jpg"><br><img src="/./md%E5%9B%BE/spark.assets/4.jpg"></p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="bin-x2F-pyspark"><a href="#bin-x2F-pyspark" class="headerlink" title="bin&#x2F;pyspark"></a>bin&#x2F;pyspark</h3><p>bin&#x2F;pyspark 程序, 可以提供一个  <code>交互式</code>的 Python解释器环境, 在这里面可以写普通python代码, 以及spark代码<br>​</p>
<p><img src="/./md%E5%9B%BE/spark.assets/5.jpg"></p>
<p>如图:</p>
<p><img src="/./md%E5%9B%BE/spark.assets/6.jpg"></p>
<p>在这个环境内, 可以运行spark代码</p>
<p>图中的: <code>parallelize</code> 和 <code>map</code> 都是spark提供的API</p>
<p><code>sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect()</code><br>​</p>
<h3 id="WEB-UI-4040"><a href="#WEB-UI-4040" class="headerlink" title="WEB UI (4040)"></a>WEB UI (4040)</h3><p>Spark程序在运行的时候, 会绑定到机器的<code>4040</code>端口上.</p>
<p>如果4040端口被占用, 会顺延到4041 … 4042…<br><img src="/./md%E5%9B%BE/spark.assets/7.jpg"></p>
<p>4040端口是一个WEBUI端口, 可以在浏览器内打开:</p>
<p>输入:<code>服务器ip:4040</code> 即可打开:<br><img src="/./md%E5%9B%BE/spark.assets/8.jpg"></p>
<p>打开监控页面后, 可以发现 在程序内仅有一个Driver</p>
<p>因为我们是Local模式, Driver即管理 又 干活.</p>
<p>同时, 输入jps<br>​</p>
<p><img src="/./md%E5%9B%BE/spark.assets/9.jpg"></p>
<p>可以看到local模式下的唯一进程存在</p>
<p>这个进程 即是master也是worker</p>
<h3 id="bin-x2F-spark-shell-了解"><a href="#bin-x2F-spark-shell-了解" class="headerlink" title="bin&#x2F;spark-shell - 了解"></a>bin&#x2F;spark-shell - 了解</h3><p>同样是一个解释器环境, 和<code>bin/pyspark</code>不同的是, 这个解释器环境 运行的不是python代码, 而是scala程序代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">scala&gt; </span><span class="language-bash">sc.parallelize(Array(1,2,3,4,5)).map(x=&gt; x + 1).collect()</span></span><br><span class="line">res0: Array[Int] = Array(2, 3, 4, 5, 6)</span><br></pre></td></tr></table></figure>


<blockquote>
<p>这个仅作为了解即可, 因为这个是用于scala语言的解释器环境</p>
</blockquote>
<h3 id="bin-x2F-spark-submit-PI"><a href="#bin-x2F-spark-submit-PI" class="headerlink" title="bin&#x2F;spark-submit (PI)"></a>bin&#x2F;spark-submit (PI)</h3><p>作用: 提交指定的Spark代码到Spark环境中运行</p>
<p>使用方法:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">语法</span></span><br><span class="line">bin/spark-submit [可选的一些选项] jar包或者python代码的路径 [代码的参数]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">示例</span></span><br><span class="line">bin/spark-submit /export/server/spark/examples/src/main/python/pi.py 10</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">此案例 运行Spark官方所提供的示例代码 来计算圆周率值.  后面的10 是主函数接受的参数, 数字越高, 计算圆周率越准确.</span></span><br></pre></td></tr></table></figure>


<p>对比</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>bin&#x2F;spark-submit</th>
<th>bin&#x2F;pyspark</th>
<th>bin&#x2F;spark-shell</th>
</tr>
</thead>
<tbody><tr>
<td>功能</td>
<td>提交java\scala\python代码到spark中运行</td>
<td>提供一个<code>python</code></td>
<td></td>
</tr>
<tr>
<td>解释器环境用来以python代码执行spark程序</td>
<td>提供一个<code>scala</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>解释器环境用来以scala代码执行spark程序</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>特点</td>
<td>提交代码用</td>
<td>解释器环境 写一行执行一行</td>
<td>解释器环境 写一行执行一行</td>
</tr>
<tr>
<td>使用场景</td>
<td>正式场合, 正式提交spark程序运行</td>
<td>测试\学习\写一行执行一行\用来验证代码等</td>
<td>测试\学习\写一行执行一行\用来验证代码等</td>
</tr>
</tbody></table>
<h1 id="Spark-StandAlone环境部署"><a href="#Spark-StandAlone环境部署" class="headerlink" title="Spark StandAlone环境部署"></a>Spark StandAlone环境部署</h1><h2 id="新角色-历史服务器"><a href="#新角色-历史服务器" class="headerlink" title="新角色 历史服务器"></a>新角色 历史服务器</h2><blockquote>
<p>历史服务器不是Spark环境的必要组件, 是可选的.</p>
</blockquote>
<blockquote>
<p>回忆: 在YARN中 有一个历史服务器, 功能: 将YARN运行的程序的历史日志记录下来, 通过历史服务器方便用户查看程序运行的历史信息.</p>
</blockquote>
<p>Spark的历史服务器, 功能: 将Spark运行的程序的历史日志记录下来, 通过历史服务器方便用户查看程序运行的历史信息.</p>
<p>搭建集群环境, 我们一般<code>推荐将历史服务器也配置上</code>, 方面以后查看历史记录<br>​</p>
<h2 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h2><p>课程中 使用三台Linux虚拟机来组成集群环境, 非别是:</p>
<p>node1\ node2\ node3</p>
<p>node1运行: Spark的Master进程  和 1个Worker进程</p>
<p>node2运行: spark的1个worker进程</p>
<p>node3运行: spark的1个worker进程</p>
<p>整个集群提供: 1个master进程 和 3个worker进程</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="在所有机器安装Python-Anaconda"><a href="#在所有机器安装Python-Anaconda" class="headerlink" title="在所有机器安装Python(Anaconda)"></a>在所有机器安装Python(Anaconda)</h3><p>参考 附1内容, 如何在Linux上安装anaconda</p>
<p>同时不要忘记 都创建<code>pyspark</code>虚拟环境 以及安装虚拟环境所需要的包<code>pyspark jieba pyhive</code></p>
<h3 id="在所有机器配置环境变量"><a href="#在所有机器配置环境变量" class="headerlink" title="在所有机器配置环境变量"></a>在所有机器配置环境变量</h3><p>参考 Local模式下 环境变量的配置内容</p>
<p><code>确保3台都配置</code></p>
<h3 id="配置配置文件"><a href="#配置配置文件" class="headerlink" title="配置配置文件"></a>配置配置文件</h3><p>进入到spark的配置文件目录中, <code>cd $SPARK_HOME/conf</code></p>
<p>配置workers文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">改名, 去掉后面的.template后缀</span></span><br><span class="line">mv workers.template workers</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑worker文件</span></span><br><span class="line">vim workers</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将里面的localhost删除, 追加</span></span><br><span class="line">node1</span><br><span class="line">node2</span><br><span class="line">node3</span><br><span class="line">到workers文件内</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">功能: 这个文件就是指示了  当前SparkStandAlone环境下, 有哪些worker</span></span><br></pre></td></tr></table></figure>


<p>配置spark-env.sh文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 改名</span></span><br><span class="line">mv spark-env.sh.template spark-env.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 编辑spark-env.sh, 在底部追加如下内容</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 设置JAVA安装目录</span></span></span><br><span class="line">JAVA_HOME=/export/server/jdk</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</span></span></span><br><span class="line">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 指定spark老大Master的IP和提交任务的通信端口</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">告知Spark的master运行在哪个机器上</span></span><br><span class="line">export SPARK_MASTER_HOST=node1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">告知sparkmaster的通讯端口</span></span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">告知spark master的 webui端口</span></span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">worker cpu可用核数</span></span><br><span class="line">SPARK_WORKER_CORES=1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">worker可用内存</span></span><br><span class="line">SPARK_WORKER_MEMORY=1g</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">worker的工作通讯地址</span></span><br><span class="line">SPARK_WORKER_PORT=7078</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">worker的 webui地址</span></span><br><span class="line">SPARK_WORKER_WEBUI_PORT=8081</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 设置历史服务器</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置的意思是  将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中</span></span><br><span class="line">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;</span><br></pre></td></tr></table></figure>


<p>注意, 上面的配置的路径 要根据你自己机器实际的路径来写</p>
<p>在HDFS上创建程序运行历史记录存放的文件夹:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /sparklog</span><br><span class="line">hadoop fs -chmod 777 /sparklog</span><br></pre></td></tr></table></figure>


<p>配置spark-defaults.conf文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 改名</span></span><br><span class="line">mv spark-defaults.conf.template spark-defaults.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 修改内容, 追加如下内容</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">开启spark的日期记录功能</span></span><br><span class="line">spark.eventLog.enabled 	true</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置spark日志记录的路径</span></span><br><span class="line">spark.eventLog.dir	 hdfs://node1:8020/sparklog/ </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置spark日志是否启动压缩</span></span><br><span class="line">spark.eventLog.compress 	true</span><br></pre></td></tr></table></figure>


<p>配置log4j.properties 文件 [可选配置]</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 改名</span></span><br><span class="line">mv log4j.properties.template log4j.properties</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 修改内容 参考下图</span></span><br></pre></td></tr></table></figure>
<p><img src="/./md%E5%9B%BE/spark.assets/10.jpg"></p>
<blockquote>
<p>这个文件的修改不是必须的,  为什么修改为WARN. 因为Spark是个话痨</p>
<p>会疯狂输出日志, 设置级别为WARN 只输出警告和错误日志, 不要输出一堆废话.</p>
</blockquote>
<h3 id="将Spark安装文件夹-分发到其它的服务器上"><a href="#将Spark安装文件夹-分发到其它的服务器上" class="headerlink" title="将Spark安装文件夹  分发到其它的服务器上"></a>将Spark安装文件夹  分发到其它的服务器上</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r spark-3.1.2-bin-hadoop3.2 node2:/export/server/</span><br><span class="line">scp -r spark-3.1.2-bin-hadoop3.2 node3:/export/server/</span><br></pre></td></tr></table></figure>


<p>不要忘记, 在node2和node3上 给spark安装目录增加软链接</p>
<p><code>ln -s /export/server/spark-3.1.2-bin-hadoop3.2 /export/server/spark</code></p>
<h3 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h3><p>检查每台机器的:</p>
<p>JAVA_HOME</p>
<p>SPARK_HOME</p>
<p>PYSPARK_PYTHON</p>
<p>等等 环境变量是否正常指向正确的目录</p>
<h3 id="启动历史服务器"><a href="#启动历史服务器" class="headerlink" title="启动历史服务器"></a>启动历史服务器</h3><p><code>sbin/start-history-server.sh</code></p>
<h3 id="启动Spark的Master和Worker进程"><a href="#启动Spark的Master和Worker进程" class="headerlink" title="启动Spark的Master和Worker进程"></a>启动Spark的Master和Worker进程</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动全部master和worker</span></span><br><span class="line">sbin/start-all.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者可以一个个启动:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动当前机器的master</span></span><br><span class="line">sbin/start-master.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动当前机器的worker</span></span><br><span class="line">sbin/start-worker.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">停止全部</span></span><br><span class="line">sbin/stop-all.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">停止当前机器的master</span></span><br><span class="line">sbin/stop-master.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">停止当前机器的worker</span></span><br><span class="line">sbin/stop-worker.sh</span><br></pre></td></tr></table></figure>


<h3 id="查看Master的WEB-UI"><a href="#查看Master的WEB-UI" class="headerlink" title="查看Master的WEB UI"></a>查看Master的WEB UI</h3><p>默认端口master我们设置到了8080</p>
<p>如果端口被占用, 会顺延到8081 …;8082… 8083… 直到申请到端口为止</p>
<p>可以在日志中查看, 具体顺延到哪个端口上:</p>
<p><code>Service &#39;MasterUI&#39; could not bind on port 8080. Attempting port 8081.</code><br>​</p>
<p><img src="/./md%E5%9B%BE/spark.assets/11.jpg"></p>
<h3 id="连接到StandAlone集群"><a href="#连接到StandAlone集群" class="headerlink" title="连接到StandAlone集群"></a>连接到StandAlone集群</h3><h4 id="bin-x2F-pyspark-1"><a href="#bin-x2F-pyspark-1" class="headerlink" title="bin&#x2F;pyspark"></a>bin&#x2F;pyspark</h4><p>执行:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/pyspark --master spark://node1:7077</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过--master选项来连接到 StandAlone集群</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果不写--master选项, 默认是<span class="built_in">local</span>模式运行</span></span><br></pre></td></tr></table></figure>
<p><img src="/./md%E5%9B%BE/spark.assets/12.jpg"></p>
<h4 id="bin-x2F-spark-shell"><a href="#bin-x2F-spark-shell" class="headerlink" title="bin&#x2F;spark-shell"></a>bin&#x2F;spark-shell</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master spark://node1:7077</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同样适用--master来连接到集群使用</span></span><br></pre></td></tr></table></figure>


<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 测试代码</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)).map(x=&gt; x + <span class="number">1</span>).collect()</span><br></pre></td></tr></table></figure>


<h4 id="bin-x2F-spark-submit-PI-1"><a href="#bin-x2F-spark-submit-PI-1" class="headerlink" title="bin&#x2F;spark-submit (PI)"></a>bin&#x2F;spark-submit (PI)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同样使用--master来指定将任务提交到集群运行</span></span><br></pre></td></tr></table></figure>


<h3 id="查看历史服务器WEB-UI"><a href="#查看历史服务器WEB-UI" class="headerlink" title="查看历史服务器WEB UI"></a>查看历史服务器WEB UI</h3><p>历史服务器的默认端口是: 18080</p>
<p>我们启动在node1上, 可以在浏览器打开:</p>
<p><code>node1:18080</code>来进入到历史服务器的WEB UI上.<br><img src="/./md%E5%9B%BE/spark.assets/13.jpg"></p>
<h1 id="Spark-StandAlone-HA-环境搭建"><a href="#Spark-StandAlone-HA-环境搭建" class="headerlink" title="Spark StandAlone HA 环境搭建"></a>Spark StandAlone HA 环境搭建</h1><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><blockquote>
<p>前提: 确保Zookeeper 和 HDFS 均已经启动</p>
</blockquote>
<p>先在<code>spark-env.sh</code>中, 删除: <code>SPARK_MASTER_HOST=node1</code></p>
<p>原因: 配置文件中固定master是谁, 那么就无法用到zk的动态切换master功能了.</p>
<p>在<code>spark-env.sh</code>中, 增加:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定Zookeeper的连接地址</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定在Zookeeper中注册临时节点的路径</span></span><br></pre></td></tr></table></figure>


<p>将spark-env.sh 分发到每一台服务器上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp spark-env.sh node2:/export/server/spark/conf/</span><br><span class="line">scp spark-env.sh node3:/export/server/spark/conf/</span><br></pre></td></tr></table></figure>


<p>停止当前StandAlone集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-all.sh</span><br></pre></td></tr></table></figure>


<p>启动集群:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在node1上 启动一个master 和全部worker</span></span><br><span class="line">sbin/start-all.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意, 下面命令在node2上执行</span></span><br><span class="line">sbin/start-master.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在node2上启动一个备用的master进程</span></span><br></pre></td></tr></table></figure>
<p><img src="/./md%E5%9B%BE/spark.assets/14.jpg"><br><img src="/./md%E5%9B%BE/spark.assets/15.jpg"></p>
<h2 id="master主备切换"><a href="#master主备切换" class="headerlink" title="master主备切换"></a>master主备切换</h2><p>提交一个spark任务到当前<code>alive</code>master上:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 1000</span><br></pre></td></tr></table></figure>


<p>在提交成功后, 将alivemaster直接kill掉</p>
<p>不会影响程序运行:<br><img src="/./md%E5%9B%BE/spark.assets/16.jpg"><br>当新的master接收集群后, 程序继续运行, 正常得到结果.</p>
<blockquote>
<p>结论 HA模式下, 主备切换 不会影响到正在运行的程序.</p>
<p>最大的影响是 会让它中断大约30秒左右.</p>
</blockquote>
<h1 id="Spark-On-YARN-环境搭建"><a href="#Spark-On-YARN-环境搭建" class="headerlink" title="Spark On YARN 环境搭建"></a>Spark On YARN 环境搭建</h1><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>确保:</p>
<ul>
<li>HADOOP_CONF_DIR</li>
<li>YARN_CONF_DIR</li>
</ul>
<p>在spark-env.sh 以及 环境变量配置文件中即可<br>​</p>
<h2 id="连接到YARN中"><a href="#连接到YARN中" class="headerlink" title="连接到YARN中"></a>连接到YARN中</h2><h3 id="bin-x2F-pyspark-2"><a href="#bin-x2F-pyspark-2" class="headerlink" title="bin&#x2F;pyspark"></a>bin&#x2F;pyspark</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/pyspark --master yarn --deploy-mode client|cluster</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--deploy-mode 选项是指定部署模式, 默认是 客户端模式</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">client就是客户端模式</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cluster就是集群模式</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--deploy-mode 仅可以用在YARN模式下</span></span><br></pre></td></tr></table></figure>


<blockquote>
<p>注意: 交互式环境 pyspark  和 spark-shell  无法运行 cluster模式</p>
</blockquote>
<h3 id="bin-x2F-spark-shell-1"><a href="#bin-x2F-spark-shell-1" class="headerlink" title="bin&#x2F;spark-shell"></a>bin&#x2F;spark-shell</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master yarn --deploy-mode client|cluster</span><br></pre></td></tr></table></figure>


<blockquote>
<p>注意: 交互式环境 pyspark  和 spark-shell  无法运行 cluster模式</p>
</blockquote>
<h3 id="bin-x2F-spark-submit-PI-2"><a href="#bin-x2F-spark-submit-PI-2" class="headerlink" title="bin&#x2F;spark-submit (PI)"></a>bin&#x2F;spark-submit (PI)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --master yarn --deploy-mode client|cluster /xxx/xxx/xxx.py 参数</span><br></pre></td></tr></table></figure>


<h2 id="spark-submit-和-spark-shell-和-pyspark的相关参数"><a href="#spark-submit-和-spark-shell-和-pyspark的相关参数" class="headerlink" title="spark-submit 和 spark-shell 和 pyspark的相关参数"></a>spark-submit 和 spark-shell 和 pyspark的相关参数</h2><p>参见: 附2<br>​</p>
<h1 id="附1-Anaconda-On-Linux-安装-单台服务器"><a href="#附1-Anaconda-On-Linux-安装-单台服务器" class="headerlink" title="附1 Anaconda On Linux 安装 (单台服务器)"></a>附1 Anaconda On Linux 安装 (单台服务器)</h1><h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><p>上传安装包:</p>
<p>上传: 资料中提供的<code>Anaconda3-2021.05-Linux-x86_64.sh</code>文件到Linux服务器上</p>
<p>安装:</p>
<p><code>sh ./Anaconda3-2021.05-Linux-x86_64.sh</code><br><img src="/./md%E5%9B%BE/spark.assets/17.jpg"><br><img src="/./md%E5%9B%BE/spark.assets/18.jpg"><br><img src="/./md%E5%9B%BE/spark.assets/19.jpg"><br><img src="/./md%E5%9B%BE/spark.assets/20.jpg"><br><img src="/./md%E5%9B%BE/spark.assets/21.jpg"><br>输入yes后就安装完成了.</p>
<p>安装完成后, <code>退出finalshell 重新进来</code>:<br><img src="/./md%E5%9B%BE/spark.assets/22.jpg"></p>
<p>看到这个Base开头表明安装好了.</p>
<p>base是默认的虚拟环境.<br>​</p>
<h2 id="国内源"><a href="#国内源" class="headerlink" title="国内源"></a>国内源</h2><p>如果你安装好后, 没有出现base, 可以打开:&#x2F;root&#x2F;.condarc这个文件, 追加如下内容:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line">default_channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure>


<h1 id="附2-spark-submit和pyspark相关参数"><a href="#附2-spark-submit和pyspark相关参数" class="headerlink" title="附2 spark-submit和pyspark相关参数"></a>附2 spark-submit和pyspark相关参数</h1><p>客户端工具我们可以用的有:</p>
<ul>
<li>bin&#x2F;pyspark: pyspark解释器spark环境</li>
<li>bin&#x2F;spark-shell: scala解释器spark环境</li>
<li>bin&#x2F;spark-submit: 提交jar包或Python文件执行的工具</li>
<li>bin&#x2F;spark-sql: sparksql客户端工具</li>
</ul>
<p>这4个客户端工具的参数基本通用.</p>
<p>以spark-submit 为例:</p>
<p><code>bin/spark-submit --master spark://node1:7077 xxx.py</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]</span><br><span class="line">Usage: spark-submit --kill [submission ID] --master [spark://...]</span><br><span class="line">Usage: spark-submit --status [submission ID] --master [spark://...]</span><br><span class="line">Usage: spark-submit run-example [options] example-class [example args]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,</span><br><span class="line">                              k8s://https://host:port, or local (Default: local[*]).</span><br><span class="line">  --deploy-mode DEPLOY_MODE   部署模式 client 或者 cluster 默认是client</span><br><span class="line">  --class CLASS_NAME          运行java或者scala class(for Java / Scala apps).</span><br><span class="line">  --name NAME                 程序的名字</span><br><span class="line">  --jars JARS                 Comma-separated list of jars to include on the driver</span><br><span class="line">                              and executor classpaths.</span><br><span class="line">  --packages                  Comma-separated list of maven coordinates of jars to include</span><br><span class="line">                              on the driver and executor classpaths. Will search the local</span><br><span class="line">                              maven repo, then maven central and any additional remote</span><br><span class="line">                              repositories given by --repositories. The format for the</span><br><span class="line">                              coordinates should be groupId:artifactId:version.</span><br><span class="line">  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while</span><br><span class="line">                              resolving the dependencies provided in --packages to avoid</span><br><span class="line">                              dependency conflicts.</span><br><span class="line">  --repositories              Comma-separated list of additional remote repositories to</span><br><span class="line">                              search for the maven coordinates given with --packages.</span><br><span class="line">  --py-files PY_FILES         指定Python程序依赖的其它python文件</span><br><span class="line">  --files FILES               Comma-separated list of files to be placed in the working</span><br><span class="line">                              directory of each executor. File paths of these files</span><br><span class="line">                              in executors can be accessed via SparkFiles.get(fileName).</span><br><span class="line">  --archives ARCHIVES         Comma-separated list of archives to be extracted into the</span><br><span class="line">                              working directory of each executor.</span><br><span class="line"></span><br><span class="line">  --conf, -c PROP=VALUE       手动指定配置</span><br><span class="line">  --properties-file FILE      Path to a file from which to load extra properties. If not</span><br><span class="line">                              specified, this will look for conf/spark-defaults.conf.</span><br><span class="line"></span><br><span class="line">  --driver-memory MEM         Driver的可用内存(Default: 1024M).</span><br><span class="line">  --driver-java-options       Driver的一些Java选项</span><br><span class="line">  --driver-library-path       Extra library path entries to pass to the driver.</span><br><span class="line">  --driver-class-path         Extra class path entries to pass to the driver. Note that</span><br><span class="line">                              jars added with --jars are automatically included in the</span><br><span class="line">                              classpath.</span><br><span class="line"></span><br><span class="line">  --executor-memory MEM       Executor的内存 (Default: 1G).</span><br><span class="line"></span><br><span class="line">  --proxy-user NAME           User to impersonate when submitting the application.</span><br><span class="line">                              This argument does not work with --principal / --keytab.</span><br><span class="line"></span><br><span class="line">  --help, -h                  显示帮助文件</span><br><span class="line">  --verbose, -v               Print additional debug output.</span><br><span class="line">  --version,                  打印版本</span><br><span class="line"></span><br><span class="line"> Cluster deploy mode only(集群模式专属):</span><br><span class="line">  --driver-cores NUM          Driver可用的的CPU核数(Default: 1).</span><br><span class="line"></span><br><span class="line"> Spark standalone or Mesos with cluster deploy mode only:</span><br><span class="line">  --supervise                 如果给定, 可以尝试重启Driver</span><br><span class="line"></span><br><span class="line"> Spark standalone, Mesos or K8s with cluster deploy mode only:</span><br><span class="line">  --kill SUBMISSION_ID        指定程序ID kill</span><br><span class="line">  --status SUBMISSION_ID      指定程序ID 查看运行状态</span><br><span class="line"></span><br><span class="line"> Spark standalone, Mesos and Kubernetes only:</span><br><span class="line">  --total-executor-cores NUM  整个任务可以给Executor多少个CPU核心用</span><br><span class="line"></span><br><span class="line"> Spark standalone, YARN and Kubernetes only:</span><br><span class="line">  --executor-cores NUM        单个Executor能使用多少CPU核心</span><br><span class="line"></span><br><span class="line"> Spark on YARN and Kubernetes only(YARN模式下):</span><br><span class="line">  --num-executors NUM         Executor应该开启几个</span><br><span class="line">  --principal PRINCIPAL       Principal to be used to login to KDC.</span><br><span class="line">  --keytab KEYTAB             The full path to the file that contains the keytab for the</span><br><span class="line">                              principal specified above.</span><br><span class="line"></span><br><span class="line"> Spark on YARN only:</span><br><span class="line">  --queue QUEUE_NAME          指定运行的YARN队列(Default: &quot;default&quot;).</span><br></pre></td></tr></table></figure>




<h1 id="附3-Windows系统配置Anaconda"><a href="#附3-Windows系统配置Anaconda" class="headerlink" title="附3 Windows系统配置Anaconda"></a>附3 Windows系统配置Anaconda</h1><h2 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h2><p>打开资料中提供的:Anaconda3-2021.05-Windows-x86_64.exe文件,或者去官网下载:[<a target="_blank" rel="noopener" href="https://www.anaconda.com/products/individual#Downloads]">https://www.anaconda.com/products/individual#Downloads]</a><br>​</p>
<p>打开后,一直点击<code>Next</code>下一步即可:<br><img src="/./md%E5%9B%BE/spark.assets/23.jpg" alt="image.png"><br><img src="/./md%E5%9B%BE/spark.assets/24.jpg" alt="image.png"><br>如果想要修改安装路径, 可以修改<br><img src="/./md%E5%9B%BE/spark.assets/25.jpg" alt="image.png"><br>不必勾选<br><img src="/./md%E5%9B%BE/spark.assets/26.jpg" alt="image.png"><br>最终点击Finish完成安装</p>
<p>打开开始菜单, 搜索Anaconda<br><img src="/./md%E5%9B%BE/spark.assets/27.jpg" alt="image.png"><br>出现如图的程序, 安装成功.</p>
<p>打开 <code>Anaconda Prompt</code>程序:<br><img src="/./md%E5%9B%BE/spark.assets/28.jpg" alt="image.png"><br>出现<code>base</code>说明安装正确.</p>
<h2 id="配置国内源"><a href="#配置国内源" class="headerlink" title="配置国内源"></a>配置国内源</h2><p>Anaconda默认源服务器在国外, 网速比较慢, 配置国内源加速网络下载.<br>​</p>
<p>打开上图中的 <code>Anaconda Prompt</code>程序:<br>执行:<br><code>conda config --set show_channel_urls yes</code><br>​</p>
<p>然后用记事本打开:<br><code>C:\Users\用户名\.condarc</code>文件, 将如下内容替换进文件内,保存即可:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line">default_channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure>


<h2 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建虚拟环境 pyspark, 基于Python 3.8</span></span><br><span class="line">conda create -n pyspark python=3.8</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换到虚拟环境内</span></span><br><span class="line">conda activate pyspark</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在虚拟环境内安装包</span></span><br><span class="line">pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple </span><br></pre></td></tr></table></figure>










      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/Spark%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3/" data-id="clj254b6m000300ur8a398z2q" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Hive3安装" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/Hive3%E5%AE%89%E8%A3%85/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T00:49:49.447Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Hive3安装"><a href="#Hive3安装" class="headerlink" title="Hive3安装"></a>Hive3安装</h1><h2 id="一、Mysql安装"><a href="#一、Mysql安装" class="headerlink" title="一、Mysql安装"></a>一、Mysql安装</h2><ul>
<li><p>卸载Centos7自带的mariadb</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# rpm -qa|grep mariadb</span><br><span class="line">mariadb-libs-5.5.64-1.el7.x86_64</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# rpm -e mariadb-libs-5.5.64-1.el7.x86_64 --nodeps</span><br><span class="line">[root@node1 ~]# rpm -qa|grep mariadb                            </span><br><span class="line">[root@node1 ~]# </span><br></pre></td></tr></table></figure>
</li>
<li><p>安装mysql</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mkdir /export/server/mysql</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar 到上述文件夹下  解压</span></span><br><span class="line">tar xvf mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">执行安装</span></span><br><span class="line">yum -y install libaio</span><br><span class="line"></span><br><span class="line">[root@node1 mysql]rpm -ivh mysql-community-common-5.7.29-1.el7.x86_64.rpm mysql-community-libs-5.7.29-1.el7.x86_64.rpm mysql-community-client-5.7.29-1.el7.x86_64.rpm mysql-community-server-5.7.29-1.el7.x86_64.rpm </span><br><span class="line"></span><br><span class="line">warning: mysql-community-common-5.7.29-1.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEY</span><br><span class="line">Preparing...                          ################################# [100%]</span><br><span class="line">Updating / installing...</span><br><span class="line">   1:mysql-community-common-5.7.29-1.e################################# [ 25%]</span><br><span class="line">   2:mysql-community-libs-5.7.29-1.el7################################# [ 50%]</span><br><span class="line">   3:mysql-community-client-5.7.29-1.e################################# [ 75%]</span><br><span class="line">   4:mysql-community-server-5.7.29-1.e################                  ( 49%)</span><br></pre></td></tr></table></figure>
</li>
<li><p>mysql初始化设置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">初始化</span></span><br><span class="line">mysqld --initialize</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">更改所属组</span></span><br><span class="line">chown mysql:mysql /var/lib/mysql -R</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动mysql</span></span><br><span class="line">systemctl start mysqld.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看生成的临时root密码</span></span><br><span class="line">cat  /var/log/mysqld.log</span><br><span class="line"></span><br><span class="line">[Note] A temporary password is generated for root@localhost: o+TU+KDOm004</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改root密码 授权远程访问 设置开机自启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# mysql -u root -p</span><br><span class="line">Enter password:     #这里输入在日志中生成的临时密码</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 3</span><br><span class="line">Server version: 5.7.29</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"></span><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">更新root密码  设置为hadoop</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">alter user user() identified by <span class="string">&quot;hadoop&quot;</span>;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">授权</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">use mysql;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">GRANT ALL PRIVILEGES ON *.* TO <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED BY <span class="string">&#x27;hadoop&#x27;</span> WITH GRANT OPTION;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">FLUSH PRIVILEGES;</span> </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">mysql的启动和关闭 状态查看 （这几个命令必须记住）</span></span><br><span class="line">systemctl stop mysqld</span><br><span class="line">systemctl status mysqld</span><br><span class="line">systemctl start mysqld</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">建议设置为开机自启动服务</span></span><br><span class="line">[root@node1 ~]# systemctl enable  mysqld                             </span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/mysqld.service to /usr/lib/systemd/system/mysqld.service.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看是否已经设置自启动成功</span></span><br><span class="line">[root@node1 ~]# systemctl list-unit-files | grep mysqld</span><br><span class="line">mysqld.service                                enabled </span><br></pre></td></tr></table></figure>
</li>
<li><p>Centos7 干净卸载mysql 5.7</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">关闭mysql服务</span></span><br><span class="line">systemctl stop mysqld.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查找安装mysql的rpm包</span></span><br><span class="line">[root@node3 ~]# rpm -qa | grep -i mysql      </span><br><span class="line">mysql-community-libs-5.7.29-1.el7.x86_64</span><br><span class="line">mysql-community-common-5.7.29-1.el7.x86_64</span><br><span class="line">mysql-community-client-5.7.29-1.el7.x86_64</span><br><span class="line">mysql-community-server-5.7.29-1.el7.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载</span></span><br><span class="line">[root@node1 ~]# yum remove mysql-community-libs-5.7.29-1.el7.x86_64 mysql-community-common-5.7.29-1.el7.x86_64 mysql-community-client-5.7.29-1.el7.x86_64 mysql-community-server-5.7.29-1.el7.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看是否卸载干净</span></span><br><span class="line">rpm -qa | grep -i mysql</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查找mysql相关目录 删除</span></span><br><span class="line">[root@node1 ~]# find / -name mysql</span><br><span class="line">/var/lib/mysql</span><br><span class="line">/var/lib/mysql/mysql</span><br><span class="line">/usr/share/mysql</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# rm -rf /var/lib/mysql</span><br><span class="line">[root@node1 ~]# rm -rf /var/lib/mysql/mysql</span><br><span class="line">[root@node1 ~]# rm -rf /usr/share/mysql</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">删除默认配置 日志</span></span><br><span class="line">rm -rf /etc/my.cnf </span><br><span class="line">rm -rf /var/log/mysqld.log</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="二、Hive的安装"><a href="#二、Hive的安装" class="headerlink" title="二、Hive的安装"></a>二、Hive的安装</h2><ul>
<li><p>上传安装包 解压</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf apache-hive-3.1.2-bin.tar.gz</span><br><span class="line">ln -s apache-hive-3.1.2-bin hive</span><br></pre></td></tr></table></figure>
</li>
<li><p>解决Hive与Hadoop之间guava版本差异</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive/</span><br><span class="line">rm -rf lib/guava-19.0.jar</span><br><span class="line">cp /export/server/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar ./lib/</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件</p>
<ul>
<li><p>hive-env.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive/conf</span><br><span class="line">mv hive-env.sh.template hive-env.sh</span><br><span class="line"></span><br><span class="line">vim hive-env.sh</span><br><span class="line">export HADOOP_HOME=/export/server/hadoop</span><br><span class="line">export HIVE_CONF_DIR=/export/server/hive/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=/export/server/hive/lib</span><br></pre></td></tr></table></figure>
</li>
<li><p>hive-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hive-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 存储元数据mysql相关配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://node1:3306/hive3?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>useSSL=false<span class="symbol">&amp;amp;</span>useUnicode=true<span class="symbol">&amp;amp;</span>characterEncoding=UTF-8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- H2S运行绑定host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 远程模式部署metastore metastore地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://node1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 关闭元数据存储授权  --&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>上传mysql jdbc驱动到hive安装包lib下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql-connector-java-5.1.32.jar</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化元数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hive/</span><br><span class="line"></span><br><span class="line">bin/schematool -initSchema -dbType mysql -verbos</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">初始化成功会在mysql中创建74张表</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>在hdfs创建hive存储目录（如存在则不用操作）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /tmp</span><br><span class="line">hadoop fs -mkdir -p /user/hive/warehouse</span><br><span class="line">hadoop fs -chmod g+w /tmp</span><br><span class="line">hadoop fs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure>
</li>
<li><p>&#x3D;&#x3D;启动hive&#x3D;&#x3D;</p>
<ul>
<li><p>1、启动metastore服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">前台启动  关闭ctrl+c</span></span><br><span class="line">/export/server/hive/bin/hive --service metastore</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">前台启动开启debug日志</span></span><br><span class="line">/export/server/hive/bin/hive --service metastore --hiveconf hive.root.logger=DEBUG,console  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">后台启动 进程挂起  关闭使用jps+ <span class="built_in">kill</span> -9</span></span><br><span class="line">nohup /export/server/hive/bin/hive --service metastore &amp;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>2、启动hiveserver2服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nohup /export/server/hive/bin/hive --service hiveserver2 &amp;</span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">注意 启动hiveserver2需要一定的时间  不要启动之后立即beeline连接 可能连接不上</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>3、beeline客户端连接</p>
<ul>
<li><p>拷贝node1安装包到beeline客户端机器上（node3）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r /export/server/apache-hive-3.1.2-bin/ root@node3:/export/server/</span><br></pre></td></tr></table></figure>
</li>
<li><p>错误</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: Could not open client transport with JDBC Uri: jdbc:hive2://node1:10000: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: root is not allowed to impersonate root (state=08S01,code=0)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>修改</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">  在hadoop的配置文件core-site.xml中添加如下属性：</span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>连接访问</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/export/server/hive/bin/beeline</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">beeline&gt; </span><span class="language-bash">! connect jdbc:hive2://node1:10000</span></span><br><span class="line"><span class="meta prompt_">beeline&gt; </span><span class="language-bash">root</span></span><br><span class="line"><span class="meta prompt_">beeline&gt; </span><span class="language-bash">直接回车</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>错误解决：&#x3D;&#x3D;Hive3执行insert插入操作 statstask异常&#x3D;&#x3D;</p>
<ul>
<li><p>现象</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在执行insert + values操作的时候  虽然最终执行成功，结果正确。但是在执行日志中会出现如下的错误信息。</span><br></pre></td></tr></table></figure>

<p><img src="/md%E5%9B%BE%5CHive3%E5%AE%89%E8%A3%85.assets/image-20201109144915808.png" alt="image-20201109144915808"></p>
</li>
<li><p>开启hiveserver2执行日志。查看详细信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2020-11-09 00:37:48,963 WARN  [5ce14c58-6b36-476a-bab8-89cba7dd1706 main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. setPartitionColumnStatistics</span><br><span class="line"></span><br><span class="line">ERROR [5ce14c58-6b36-476a-bab8-89cba7dd1706 main] exec.StatsTask: Failed to run stats task</span><br></pre></td></tr></table></figure>

<p><img src="/md%E5%9B%BE%5CHive3%E5%AE%89%E8%A3%85.assets/image-20201109145136486.png" alt="image-20201109145136486"></p>
</li>
<li><p>但是 &#x3D;&#x3D;此错误并不影响最终的插入语句执行成功&#x3D;&#x3D;。</p>
</li>
<li><p>分析原因和解决</p>
<ul>
<li><p>statstask是一个hive中用于统计插入等操作的状态任务  其返回结果如下</p>
<p><img src="/md%E5%9B%BE%5CHive3%E5%AE%89%E8%A3%85.assets/image-20201109145304560.png" alt="image-20201109145304560"></p>
</li>
<li><p>此信息类似于计数器 用于告知用户插入数据的相关信息 但是不影响程序的正常执行。</p>
</li>
<li><p>Hive新版本中 这是一个issues  临时解决方式如下</p>
<p><a target="_blank" rel="noopener" href="https://community.cloudera.com/t5/Support-Questions/Hive-Metastore-Connection-Failure-then-Retry/td-p/151661">https://community.cloudera.com/t5/Support-Questions/Hive-Metastore-Connection-Failure-then-Retry/td-p/151661</a></p>
<p><img src="/md%E5%9B%BE%5CHive3%E5%AE%89%E8%A3%85.assets/image-20201109145621381.png" alt="image-20201109145621381"></p>
</li>
<li><p>&#x3D;&#x3D;在mysql metastore中删除 PART_COL_STATS这张表即可&#x3D;&#x3D;。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="三、hive注释信息中文乱码解决"><a href="#三、hive注释信息中文乱码解决" class="headerlink" title="三、hive注释信息中文乱码解决"></a>三、hive注释信息中文乱码解决</h2><p>–注意 下面sql语句是需要在MySQL中执行  修改Hive存储的元数据信息（metadata）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">use hivenode2;</span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> hivenode2.COLUMNS_V2 modify <span class="keyword">column</span> COMMENT <span class="type">varchar</span>(<span class="number">256</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> hivenode2.TABLE_PARAMS modify <span class="keyword">column</span> PARAM_VALUE <span class="type">varchar</span>(<span class="number">4000</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> hivenode2.PARTITION_PARAMS modify <span class="keyword">column</span> PARAM_VALUE <span class="type">varchar</span>(<span class="number">4000</span>) <span class="type">character</span> <span class="keyword">set</span> utf8 ;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> hivenode2.PARTITION_KEYS modify <span class="keyword">column</span> PKEY_COMMENT <span class="type">varchar</span>(<span class="number">4000</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> hivenode2.INDEX_PARAMS modify <span class="keyword">column</span> PARAM_VALUE <span class="type">varchar</span>(<span class="number">4000</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/Hive3%E5%AE%89%E8%A3%85/" data-id="clj254b6l000200urc0a3fe5j" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-flume" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/flume/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T00:49:49.442Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Flume概述"><a href="#Flume概述" class="headerlink" title="Flume概述"></a>Flume概述</h1><p>Flume是一个进行海量流式（streaming）事件数据采集的分布式系统。Flume多用于对软件系统的日志文件数据的采集，目前成为Apache软件基金会的顶级项目之一。</p>
<p>Flume是的一个<code>分布式、高可用、高可靠</code>的海量<code>日志采集</code>、<code>聚合</code>和<code>传输</code>的系统，支持在日志系统中定制各类数据发送方，用于收集数据，同时提供了对数据进行<code>简单处理</code>并<code>写到</code>各种<code>数据接收方</code>的能力。</p>
<p>Flume的设计原理是基于<code>数据流</code>的，能够将不同数据源的海量日志数据进行高效<code>收集、聚合、移动</code>，最后存储到一个<code>中心化数据存储系统</code>中。 Flume能够做到近似实时的推送，并且可以满足数据量是持续且量级很大的情况。比如它可以收集社交网站日志，并将这些数量庞大的日志数据从网站服务器上汇集起来，存储到HDFS或 HBase分布式数据库中。</p>
<blockquote>
<p>•Flume可以将应用产生的数据存储到任何集中存储器中，比如HDFS,HBase</p>
<p>•数据缓存。当收集数据的速度超过将写入数据的时候，保证其能够在两者之间提供平衡。</p>
<p>•Flume的管道是基于事务，保证了数据在传送和接收时的一致性.</p>
<p>•Flume是可靠的，容错性高的，可升级的，易管理的,并且可定制的</p>
</blockquote>
<p>Flume的应用场景:比如一个<code>电商网站</code>，想从网站访问者中访问一些<code>特定的节点区域</code>来<code>分析消费者</code>的<code>购物意图和行为</code>。为了实现这一点，需要收集到消费者访问的页面以及点击的产品等日志信息，并移交到大数据 Hadoop平台上去分析，可以利用 Flume做到这一点。现在流行的内容推送，比如广告定点投放以及新闻私人定制也是基于这个道理。</p>
<h1 id="Flume架构"><a href="#Flume架构" class="headerlink" title="Flume架构"></a>Flume架构</h1><p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200327112206283.png" alt="image-20200327112206283"></p>
<img src="./md图/flume.assets/image-20230303092506796.png" alt="image-20230303092506796" style="zoom:50%;" />

<p> Flume采集系统以Agent为单位，一个Agent就是一个工作进程。一个完整的Agent由三个组件构成，它们分别是：</p>
<p>(1)Source：用于从<code>数据源接收数据</code>（即采集数据），需要<code>设置数据的来源类型</code>；</p>
<p>(2)Sink：用于<code>传递数据给目的地</code>（即保存数据），需要<code>设置数据的目的地类型</code>；</p>
<p>(3)Channel：用于<code>Source和Sink的连接</code>，并缓存传输的数据，需要<code>设置缓存类型</code>。</p>
<h2 id="1-Event"><a href="#1-Event" class="headerlink" title="1.Event"></a>1.Event</h2><p>事件是Flume内部数据传输的最基本单元，将传输的数据进行<code>封装</code>。事件本身是由一个<code>载有数据的字节数组</code>和<code>可选的headers头部信息</code>构成，如下图所示。Flume以事件的形式将数据从源头传输到最终的目的地。</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200323103129436.png" alt="image-20200323103129436"></p>
<h2 id="2-Agent"><a href="#2-Agent" class="headerlink" title="2.Agent"></a>2.Agent</h2><p>Flume Agent 是一个<code>JVM进程</code>，通过三个组件（<code>source</code>、<code>channel</code>、<code>sink</code>）将事件流从一个外部数据源收集并发送给下一个目的地。</p>
<h3 id="（1）Source"><a href="#（1）Source" class="headerlink" title="（1）Source"></a>（1）Source</h3><p>从<code>数据发生器接收数据</code>，并将数据以Flume的Event格式传递给一个或多个通道（Channel）</p>
<p>支持Source:</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#avro-source">Avro Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#thrift-source">Thrift Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#exec-source">Exec Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#jms-source">JMS Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#spooling-directory-source">Spooling Directory Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#taildir-source">Taildir Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#twitter-1-firehose-source-experimental">Twitter 1% firehose Source (experimental)</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#kafka-source">Kafka Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#netcat-tcp-source">NetCat TCP Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#netcat-udp-source">NetCat UDP Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#sequence-generator-source">Sequence Generator Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#syslog-sources">Syslog Sources</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#http-source">HTTP Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#stress-source">Stress Source</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#legacy-sources">Legacy Sources</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#custom-source">Custom Source</a></li>
</ul>
<p>常用source类型：</p>
<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>类型名称</strong></th>
<th><strong>功   能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><strong>spooldir</strong></td>
<td>数据来源于磁盘文件目录</td>
</tr>
<tr>
<td>2</td>
<td><strong>exec</strong></td>
<td>表明数据来源于Linux命令</td>
</tr>
<tr>
<td>3</td>
<td><strong>taildir</strong></td>
<td>表明数据来源于文件的实时新增内容</td>
</tr>
<tr>
<td>4</td>
<td>avro</td>
<td>表明数据来源于指定IP和端口发送的AVRO消息</td>
</tr>
<tr>
<td>5</td>
<td>thrift</td>
<td>表明数据来源于指定IP和端口发送的THRIFT消息</td>
</tr>
<tr>
<td>6</td>
<td>netcat</td>
<td>表明数据来源于指定IP和端口发送的netcat  TCP消息</td>
</tr>
<tr>
<td>7</td>
<td>netcatudp</td>
<td>表明数据来源于指定IP和端口发送的netcat UDP消息</td>
</tr>
</tbody></table>
<h3 id="（2）Channel"><a href="#（2）Channel" class="headerlink" title="（2）Channel"></a>（2）Channel</h3><p>**一种<code>短暂的存储容器</code>**，位于<code> Source和Sink之间</code>，起着桥梁的作用。 Channel将从Source处接收到的 Event格式的数据<code>缓存</code>起来，当Sink<code>成功</code>地将<code> Events发送</code>到下一跳的Channel或最终<code>目的地</code>后， Events从 Channel<code>移除</code>。Channel是一个完整的事务，这一点保证了数据在收发的时候的一致性。可以把 Channel看成一个<code>FIFO（先进先出）队列</code>，<code>当数据的获取速率超过流出速率时，将Event保存到队列中，再从队中一个个出来</code>。</p>
<p>有以下几种Channel：</p>
<ul>
<li><strong>Memory Channel</strong> 事件存储在可配置容量的内存队列中，队列容量即为可存储最大事件数量，适用于高吞吐量场景，在agent出现错误时有可能会丢失部分数据</li>
<li><strong>File Channel</strong> 基于文件系统的持久化存储</li>
<li>Spillable Memory Channel 内存和文件混合Channel，当内存队列满了之后，新的事件会存储在文件系统，目前处于实验阶段，不建议在生产环境中使用</li>
<li>JDBC Channe 事件存储在持久化的数据库中，目前只支持Derby</li>
<li>Kafka Channel 事件存储在Kafka集群中</li>
<li>Pseudo Transaction Channel 伪事务Channel，仅用于测试，不能在生产环境使用</li>
<li>Custom Channel 自定义Channel</li>
</ul>
<p>常用channel类型</p>
<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>类型名称</strong></th>
<th><strong>功   能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><strong>memory</strong></td>
<td>以内存作为数据的缓存，读写速度快，但数据可能会丢失</td>
</tr>
<tr>
<td>2</td>
<td><strong>file</strong></td>
<td>以磁盘文件作为数据的缓存，读写速度相对慢，但数据不会丢失</td>
</tr>
</tbody></table>
<h3 id="（3）Sink"><a href="#（3）Sink" class="headerlink" title="（3）Sink"></a>（3）Sink</h3><p>获取Channel暂时保存的数据并进行处理。sink从channel中<code>移除事件</code>，并将其<code>发送到下一个agent</code>（简称下一跳）或者事件的<code>最终目的地</code>，比如HDFS。</p>
<p>Sink分类：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#hdfs-sink">HDFS Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#hive-sink">Hive Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#logger-sink">Logger Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#avro-sink">Avro Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#thrift-sink">Thrift Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#irc-sink">IRC Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#file-roll-sink">File Roll Sink</a> 将Events保存在本地文件系统</li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#null-sink">Null Sink</a> 抛弃从Channel接收的所有事件</li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#hbasesinks">HBaseSinks</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#morphlinesolrsink">MorphlineSolrSink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#elasticsearchsink">ElasticSearchSink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#kite-dataset-sink">Kite Dataset Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#kafka-sink">Kafka Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#http-sink">HTTP Sink</a></li>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#custom-sink">Custom Sink</a></li>
</ul>
<p>常用sink类型</p>
<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>类型名称</strong></th>
<th><strong>功能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><strong>hdfs</strong></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td><strong>file_roll</strong></td>
<td>表明数据的目的地是系统的本地目录</td>
</tr>
<tr>
<td>3</td>
<td><strong>KafkaSink</strong></td>
<td>表明数据的目的地是Kafka的生产者</td>
</tr>
<tr>
<td>4</td>
<td><strong>avro</strong></td>
<td>表明采用的是AVRO消息方式传递数据到数据目的地，需指定数据目的地的主机名和端口</td>
</tr>
<tr>
<td>5</td>
<td>hbase</td>
<td>表明数据的目的地是HBase</td>
</tr>
<tr>
<td>6</td>
<td>asynchbase</td>
<td>表明以异步方式写数据到HBase</td>
</tr>
<tr>
<td>7</td>
<td>hive</td>
<td>表明数据的目的地是Hive</td>
</tr>
<tr>
<td>8</td>
<td>elasticsearch</td>
<td>表明数据的目的地是elasticsearch</td>
</tr>
</tbody></table>
<h2 id="3-数据流模型"><a href="#3-数据流模型" class="headerlink" title="3.数据流模型"></a>3.数据流模型</h2><p><img src="/md%E5%9B%BE%5Cflume.assets/UserGuide_image00.png" alt="Agent component diagram"></p>
<p>过程简要说明如下:<br>（1）外部数据源（Web Server）将Flume可识别的 Event发送到 Source<br>（2） Source收到 Event事件后存储到一个或多个Channel通道中。<br>（3）Channel保留 Event直到Sink将其处理完毕。<br>（4）Sink从 Channel中取出数据，并将其传输至外部存储（HDFS）。</p>
<h3 id="4-可靠性"><a href="#4-可靠性" class="headerlink" title="4.可靠性"></a>4.可靠性</h3><p>事件在每个agent的channel中短暂存储，然后事件被发送到下一个agent或者最终目的地。事件只有在存储在下一个channel或者最终存储后才从当前的channel中删除。</p>
<p>Flume使用事务的办法来保证Events的可靠传递。Source和Sink分别被封装在事务中，事务由保存Event的存储或者Channel提供。这就保证了Event在数据流的点对点传输中是可靠的。在多跳的数据流中，上一跳的sink和下一跳的source均运行事务来保证数据被安全地存储到下一跳的channel中。</p>
<h1 id="零、Flume安装"><a href="#零、Flume安装" class="headerlink" title="零、Flume安装"></a>零、Flume安装</h1><p>Flume下载页面：<a target="_blank" rel="noopener" href="http://flume.apache.org/download.html">http://flume.apache.org/download.html</a></p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200323142300139.png" alt="image-20200323142300139"></p>
<p>将<a target="_blank" rel="noopener" href="http://www.apache.org/dyn/closer.lua/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz"> apache-flume-1.9.0-bin.tar.gz</a>下载到CentOS系统中，对其解压</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压命令</span></span><br><span class="line">tar xzf apache-flume-1.9.0-bin.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加软连接</span></span><br><span class="line">ln -s apache-flume-1.9.0-bin flume</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Flume使用需要依赖JDK1.8以上环境，确保已安装</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将Flume安装目录配置到PATH中，方便在任意目录使用</span></span><br><span class="line">vi /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加以下内容</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">FLUME_HOME</span></span><br><span class="line">export FLUME_HOME=/export/server/flume</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">保存成功后刷新</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看是否设置成功</span></span><br><span class="line">echo $FLUME_HOME</span><br></pre></td></tr></table></figure>

<h1 id="一、入门使用示例"><a href="#一、入门使用示例" class="headerlink" title="一、入门使用示例"></a>一、入门使用示例</h1><h2 id="案例说明"><a href="#案例说明" class="headerlink" title="案例说明"></a>案例说明</h2><p>使用Flume监听某个端口，使用Netcat向这个端口发送数据，Flume将接收到的数据打印到控制台。</p>
<p><code>Netcat是一款TCP/UDP测试工具</code>，可以通过以下命令安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nc</span><br></pre></td></tr></table></figure>

<h2 id="使用组件"><a href="#使用组件" class="headerlink" title="使用组件"></a>使用组件</h2><ul>
<li><p><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#netcat-tcp-source">NetCat TCP Source</a></p>
<p>必须属性</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>channels</strong></td>
<td align="left">–</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><strong>type</strong></td>
<td align="left">–</td>
<td align="left"><code>netcat</code></td>
</tr>
<tr>
<td align="left"><strong>bind</strong></td>
<td align="left">–</td>
<td align="left">绑定的主机名或者IP地址</td>
</tr>
<tr>
<td align="left"><strong>port</strong></td>
<td align="left">–</td>
<td align="left">绑定端口</td>
</tr>
</tbody></table>
</li>
<li><p><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#memory-channel">Memory Channel</a></p>
<p>必须属性</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>type</strong></td>
<td align="left">–</td>
<td align="left"><code>memory</code></td>
</tr>
</tbody></table>
</li>
<li><p><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#logger-sink">Logger Sink</a></p>
<p>必须属性</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>channel</strong></td>
<td align="left">–</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><strong>type</strong></td>
<td align="left">–</td>
<td align="left"><code>logger</code></td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="添加配置文件"><a href="#添加配置文件" class="headerlink" title="添加配置文件"></a>添加配置文件</h2><p>在flume&#x2F;myconf目录下添加配置文件netcat-logger.conf</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example1-netcat-logger.conf: 单节点Flume配置</span></span><br><span class="line"><span class="comment"># 定义agent名称为a1</span></span><br><span class="line"><span class="comment"># 设置3个组件的名称</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置source类型为NetCat,监听地址为本机，端口为44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">netcat</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#source和channel关联</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置sink类型为Logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="comment"># 将sink绑定到channel上</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<h2 id="启动flume"><a href="#启动flume" class="headerlink" title="启动flume"></a>启动flume</h2><p>查看Flume使用命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng help</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Usage: /opt/soft/apache-flume-1.9.0-bin/bin/flume-ng &lt;command&gt; [options]...</span><br><span class="line"></span><br><span class="line">commands:</span><br><span class="line">  help                      display this help text</span><br><span class="line">  agent                     run a Flume agent</span><br><span class="line">  avro-client               run an avro Flume client</span><br><span class="line">  version                   show Flume version info</span><br><span class="line"></span><br><span class="line">global options:</span><br><span class="line">  --conf,-c &lt;conf&gt;          use configs in &lt;conf&gt; directory</span><br><span class="line">  --classpath,-C &lt;cp&gt;       append to the classpath</span><br><span class="line">  --dryrun,-d               do not actually start Flume, just print the command</span><br><span class="line">  --plugins-path &lt;dirs&gt;     colon-separated list of plugins.d directories. See the</span><br><span class="line">                            plugins.d section in the user guide for more details.</span><br><span class="line">                            Default: $FLUME_HOME/plugins.d</span><br><span class="line">  -Dproperty=value          sets a Java system property value</span><br><span class="line">  -Xproperty=value          sets a Java -X option</span><br><span class="line"></span><br><span class="line">agent options:</span><br><span class="line">  --name,-n &lt;name&gt;          the name of this agent (required)</span><br><span class="line">  --conf-file,-f &lt;file&gt;     specify a config file (required if -z missing)</span><br><span class="line">  --zkConnString,-z &lt;str&gt;   specify the ZooKeeper connection to use (required if -f missing)</span><br><span class="line">  --zkBasePath,-p &lt;path&gt;    specify the base path in ZooKeeper for agent configs</span><br><span class="line">  --no-reload-conf          do not reload config file if changed</span><br><span class="line">  --help,-h                 display help text</span><br><span class="line"></span><br><span class="line">avro-client options:</span><br><span class="line">  --rpcProps,-P &lt;file&gt;   RPC client properties file with server connection params</span><br><span class="line">  --host,-H &lt;host&gt;       hostname to which events will be sent</span><br><span class="line">  --port,-p &lt;port&gt;       port of the avro source</span><br><span class="line">  --dirname &lt;dir&gt;        directory to stream to avro source</span><br><span class="line">  --filename,-F &lt;file&gt;   text file to stream to avro source (default: std input)</span><br><span class="line">  --headerFile,-R &lt;file&gt; File containing event headers as key/value pairs on each new line</span><br><span class="line">  --help,-h              display help text</span><br><span class="line"></span><br><span class="line">  Either --rpcProps or both --host and --port must be specified.</span><br><span class="line"></span><br><span class="line">Note that if &lt;conf&gt; directory is specified, then it is always included first</span><br><span class="line">in the classpath.</span><br></pre></td></tr></table></figure>

<p>启动agent</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">`flume-ng agent -n a1 -c conf -f example.conf -Dflume.root.logger=INFO,console`</span><br><span class="line"></span><br><span class="line">[root@node1 flume]</span><br><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/example1-netcat-logger.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">在工作环境中的启动命令一般为：</span><br><span class="line">nohup bin/flume-ng agent -n a1 -c conf -f myconf/example1-netcat-logger.conf 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">用 /dev/null 2&gt;&amp;1 这条命令的意思是将标准输出和错误输出全部重定向到/dev/null中,也就是将产生的所有信息丢弃</span><br></pre></td></tr></table></figure>



<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200110174336210.png" alt="image-20200110174336210"></p>
<h2 id="（1）使用Netcat测试"><a href="#（1）使用Netcat测试" class="headerlink" title="（1）使用Netcat测试"></a>（1）使用Netcat测试</h2><p>从另一个终端启动Netcat连接到44444端口，发送一些字符串</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc node1 44444</span><br></pre></td></tr></table></figure>

<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200323153910638.png" alt="image-20200323153910638"></p>
<p>观察agent控制台</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200323154036797.png" alt="image-20200323154036797"></p>
<p>从这里可以看到事件由头部和字节数组组成。</p>
<p><code>如果开启了防火墙，需要添加防火墙规则</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone=public --add-port=44444/tcp --permanent</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure>



<h2 id="（2）使用telnet测试"><a href="#（2）使用telnet测试" class="headerlink" title="（2）使用telnet测试"></a>（2）使用telnet测试</h2><p>如果没有安装telnet，检查源</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum list | grep telnet</span><br></pre></td></tr></table></figure>

<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200110173530605.png" alt="image-20200110173530605"></p>
<p>安装telnet</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install -y telnet.x86_64</span><br><span class="line">yum install -y telnet-server.x86_64</span><br></pre></td></tr></table></figure>

<p>启动telnet</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">telnet node1 44444</span><br></pre></td></tr></table></figure>

<p>在控制台输入内容</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200110174126132.png" alt="image-20200110174126132"></p>
<p>可以在flume窗口查看到消息</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200110174514218.png" alt="image-20200110174514218"></p>
<h1 id="二、exec-source测试"><a href="#二、exec-source测试" class="headerlink" title="二、exec_source测试"></a>二、exec_source测试</h1><p>企业中应用程序部署后会将日志写入到文件中，可以使用Flume从各个日志文件将日志收集到日志中心以便于查找和分析。</p>
<h2 id="工作机制："><a href="#工作机制：" class="headerlink" title="工作机制："></a><strong>工作机制</strong>：</h2><p><code>启动一个用户所指定的linux shell命令</code>；<br>采集这个linux shell命令的<code>标准输出</code>，作为<code>收集到的数据</code>，<code>转为event写入channel</code>；</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230114090311228.png" alt="image-20230114090311228"></p>
<h2 id="参数详解："><a href="#参数详解：" class="headerlink" title="参数详解："></a><strong>参数详解：</strong></h2><table>
<thead>
<tr>
<th><strong>channels</strong></th>
<th>–</th>
<th>本source要发往的channel</th>
</tr>
</thead>
<tbody><tr>
<td><strong>type</strong></td>
<td>–</td>
<td>本source的类别名称：exec</td>
</tr>
<tr>
<td><strong>command</strong></td>
<td>–</td>
<td>本source所要运行的linux命令,比如： tail  -F &#x2F;path&#x2F;file</td>
</tr>
<tr>
<td>shell</td>
<td>–</td>
<td>指定运行上述命令所用shell</td>
</tr>
<tr>
<td>restartThrottle</td>
<td>10000</td>
<td>命令die了以后，重启的时间间隔</td>
</tr>
<tr>
<td>restart</td>
<td>false</td>
<td>命令die了以后，是否要重启</td>
</tr>
<tr>
<td>logStdErr</td>
<td>false</td>
<td>是否收集命令的错误输出stderr</td>
</tr>
<tr>
<td>batchSize</td>
<td>20</td>
<td>提交的event批次大小</td>
</tr>
<tr>
<td>batchTimeout</td>
<td>3000</td>
<td>发往下游没完成前，等待的时间</td>
</tr>
<tr>
<td>selector.type</td>
<td>replicating</td>
<td>指定channel选择器：replicating  or multiplexing</td>
</tr>
<tr>
<td>selector.*</td>
<td></td>
<td>选择器的具体参数</td>
</tr>
<tr>
<td>interceptors</td>
<td>–</td>
<td>指定拦截器</td>
</tr>
<tr>
<td>interceptors.*</td>
<td></td>
<td>指定的拦截器的具体参数</td>
</tr>
</tbody></table>
<h2 id="配置文件："><a href="#配置文件：" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example2-exec-source-logger.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">exec</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.command</span> = <span class="string">tail -F /export/data/flume-example-data/shell/access.log </span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<h2 id="启动测试："><a href="#启动测试：" class="headerlink" title="启动测试："></a><strong>启动测试：</strong></h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.准备一个日志文件</span><br><span class="line">2.写一个脚本模拟往日志文件中持续写入数据</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..10000&#125;; </span><br><span class="line"><span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">$&#123;i&#125;</span> “bigdata <span class="built_in">log</span>”  &gt;&gt;  access.log ; </span><br><span class="line"><span class="built_in">sleep</span> 0.5; </span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">3.创建一个flume自定义配置文件</span><br><span class="line">4.启动flume采集</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf/ -f myconf/example2-exec-source-logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<h1 id="三、spooldir-source测试"><a href="#三、spooldir-source测试" class="headerlink" title="三、spooldir_source测试"></a>三、spooldir_source测试</h1><h2 id="工作机制：-1"><a href="#工作机制：-1" class="headerlink" title="工作机制："></a><strong>工作机制：</strong></h2><p><code>监视一个指定的文件夹</code>，如果文件夹下<code>有没采集过的新文件</code>，则将这些<code>新文件中的数据采集</code>，并<code>转成event写入channel</code>；<br>注意：spooling目录中的文件<code>必须是不可变的</code>（静态的），而且是<code>不能重名</code>的！否则，source会loudly fail！（<code>抛异常</code>）</p>
<h2 id="参数详解：-1"><a href="#参数详解：-1" class="headerlink" title="参数详解："></a><strong>参数详解：</strong></h2><table>
<thead>
<tr>
<th><strong>Property Name</strong></th>
<th><strong>Default</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>channels</strong></td>
<td>–</td>
<td></td>
</tr>
<tr>
<td><strong>type</strong></td>
<td>–</td>
<td>The component type name, needs to be spooldir.</td>
</tr>
<tr>
<td><strong>spoolDir</strong></td>
<td>–</td>
<td>The directory from which to read files from.</td>
</tr>
<tr>
<td>fileSuffix</td>
<td>.COMPLETED</td>
<td>采集完成的文件，添加什么后缀名</td>
</tr>
<tr>
<td>deletePolicy</td>
<td>never</td>
<td>是否删除采完的文件: never or immediate</td>
</tr>
<tr>
<td>fileHeader</td>
<td>false</td>
<td>是否将所采集文件的绝对路径添加到header中</td>
</tr>
<tr>
<td>fileHeaderKey</td>
<td>file</td>
<td>上述header的key名称</td>
</tr>
<tr>
<td>basenameHeader</td>
<td>false</td>
<td>是否将文件名添加到header</td>
</tr>
<tr>
<td>basenameHeaderKey</td>
<td>basename</td>
<td>上述header的key名称</td>
</tr>
<tr>
<td>includePattern</td>
<td>^.*$</td>
<td>指定需要采集的文件名的正则表达式</td>
</tr>
<tr>
<td>ignorePattern</td>
<td>^$</td>
<td>指定要排除的文件名的正则表达式  如果一个文件名即符合includePattern又匹配ignorePattern，则该文件不采</td>
</tr>
<tr>
<td>trackerDir</td>
<td>.flumespool</td>
<td>记录元数据的目录所在路径，可以用绝对路径也可以用相对路径（相对于采集目录）</td>
</tr>
<tr>
<td>trackingPolicy</td>
<td>rename</td>
<td>采集进度跟踪策略，有两种：  “rename”和  “tracker_dir”. 本参数只在deletePolicy&#x3D;never时才生效   “rename”- 采完的文件根据filesuffix重命名   “tracker_dir” - 采完的文件会在trackerDir目录中生成一个同名的空文件</td>
</tr>
<tr>
<td>consumeOrder</td>
<td>oldest</td>
<td>采集顺序： oldest, youngest and random.   oldest和youngest情况下，可能会带来一定效率的损失；（需要对文件夹中所有文件进行一次扫描以寻找最old或最young的）</td>
</tr>
<tr>
<td>pollDelay</td>
<td>500</td>
<td>Delay (in milliseconds) used when polling for new  files.</td>
</tr>
<tr>
<td>recursiveDirectorySearch</td>
<td>false</td>
<td>Whether to monitor sub directories for new files to read.</td>
</tr>
<tr>
<td>maxBackoff</td>
<td>4000</td>
<td>The maximum time (in millis) to wait between  consecutive attempts to write to the channel(s) if the channel is full. The  source will start at a low backoff and increase it exponentially each time  the channel throws a ChannelException, upto the value specified by this  parameter.</td>
</tr>
<tr>
<td>batchSize</td>
<td>100</td>
<td>一次传输到channel的event条数（一批）</td>
</tr>
<tr>
<td>inputCharset</td>
<td>UTF-8</td>
<td>Character set used by deserializers that treat the  input file as text.</td>
</tr>
<tr>
<td>decodeErrorPolicy</td>
<td>FAIL</td>
<td>What to do when we see a non-decodable character in the  input file. FAIL: Throw an exception and fail to parse the  file. REPLACE: Replace the unparseable character with the  “replacement character” char, typically Unicode U+FFFD. IGNORE: Drop the unparseable character sequence.</td>
</tr>
<tr>
<td>deserializer</td>
<td>LINE</td>
<td>Specify the deserializer used to parse the file into  events. Defaults to parsing each line as an event. The class specified must  implementEventDeserializer.Builder.</td>
</tr>
<tr>
<td>deserializer.*</td>
<td></td>
<td>Varies per event deserializer.</td>
</tr>
<tr>
<td>bufferMaxLines</td>
<td>–</td>
<td>(Obselete) This option is now ignored.</td>
</tr>
<tr>
<td>bufferMaxLineLength</td>
<td>5000</td>
<td>(Deprecated) Maximum length of a line in the commit  buffer. Use deserializer.maxLineLength instead.</td>
</tr>
<tr>
<td>selector.type</td>
<td>replicating</td>
<td>replicating or multiplexing</td>
</tr>
<tr>
<td>selector.*</td>
<td></td>
<td>Depends on the selector.type value</td>
</tr>
<tr>
<td>interceptors</td>
<td>–</td>
<td>Space-separated list of interceptors</td>
</tr>
<tr>
<td>interceptors.*</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="配置文件：-1"><a href="#配置文件：-1" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example3-spooldir-source.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">spooldir</span></span><br><span class="line"><span class="attr">a1.sources.r1.spoolDir</span> = <span class="string">/export/data/flume-example-data/weblog </span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<h2 id="启动测试：-1"><a href="#启动测试：-1" class="headerlink" title="启动测试："></a><strong>启动测试：</strong></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/example3-spooldir-source.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>注意：spooldir source 与exec source不同，spooldir source本身是可靠的，会记录崩溃之前的采集位置。</p>
<h1 id="四、taildir-source测试"><a href="#四、taildir-source测试" class="headerlink" title="四、taildir_source测试"></a>四、taildir_source测试</h1><h2 id="工作机制：-2"><a href="#工作机制：-2" class="headerlink" title="工作机制："></a><strong>工作机制：</strong></h2><p><code>监视指定目录下的一批文件</code>，只要某个文件中<code>有新写入的行</code>，则会被<code>tail</code>到<br>它会<code>记录每一个文件所tail到的位置</code>，记录到一个指定的<code>positionfile</code>保存目录中，<code>格式为json</code>（如果需要的时候，可以人为修改，就可以让source从任意指定的位置开始读取数据）<br>所以，这个source真的像官网所吹的，是可靠的reliable！<br>它对采集完成的文件，不会做任何修改（比如重命名，删除…..）</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230114093012740.png" alt="image-20230114093012740"></p>
<p>taildir source会把读到的数据<code>成功写入channel后</code>，<code>再更新记录偏移量</code>，这种机制，能保证数据不会漏采（丢失），但是有<code>可能会产生数据重复</code>。</p>
<h2 id="参数详解：-2"><a href="#参数详解：-2" class="headerlink" title="参数详解："></a><strong>参数详解：</strong></h2><table>
<thead>
<tr>
<th><strong>Property Name</strong></th>
<th><strong>Default</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>channels</strong></td>
<td>–</td>
<td>所要写往的channel</td>
</tr>
<tr>
<td><strong>type</strong></td>
<td>–</td>
<td>本source的别名： TAILDIR.</td>
</tr>
<tr>
<td><strong>filegroups</strong></td>
<td>–</td>
<td>空格分割的组名，每一组代表着一批文件  g1 g2</td>
</tr>
<tr>
<td><strong>filegroups.<filegroupName></strong></td>
<td>–</td>
<td>每个文件组的绝路路径，文件名可用正则表达式</td>
</tr>
<tr>
<td>positionFile</td>
<td>~&#x2F;.flume&#x2F;taildir_position.json</td>
<td>记录偏移量位置的文件所在路径</td>
</tr>
<tr>
<td>headers.<filegroupName>.<headerKey></td>
<td>–</td>
<td>Header value which is  the set with header key. Multiple headers can be specified for one file  group.</td>
</tr>
<tr>
<td>byteOffsetHeader</td>
<td>false</td>
<td>Whether to add the byte  offset of a tailed line to a header called ‘byteoffset’.</td>
</tr>
<tr>
<td>skipToEnd</td>
<td>false</td>
<td>Whether to skip the  position to EOF in the case of files not written on the position file.</td>
</tr>
<tr>
<td>idleTimeout</td>
<td>120000</td>
<td>关闭非活动文件的时延。如果被关闭的这个文件又在某个时间有了新增行,会被此source检测到，并重新打开</td>
</tr>
<tr>
<td>writePosInterval</td>
<td>3000</td>
<td>3s 记录一次偏移量到positionfile</td>
</tr>
<tr>
<td>batchSize</td>
<td>100</td>
<td>提交event到channel的批次最大条数</td>
</tr>
<tr>
<td>maxBatchCount</td>
<td>Long.MAX_VALUE</td>
<td>控制在一个文件上连续读取的最大批次个数（如果某个文件正在被高速写入，那就应该让这个参数调为最大值，以让source可以集中精力专采这个文件）</td>
</tr>
<tr>
<td>backoffSleepIncrement</td>
<td>1000</td>
<td>The increment for time  delay before reattempting to poll for new data, when the last attempt did not  find any new data.</td>
</tr>
<tr>
<td>maxBackoffSleep</td>
<td>5000</td>
<td>The max time delay  between each reattempt to poll for new data, when the last attempt did not  find any new data.</td>
</tr>
<tr>
<td>cachePatternMatching</td>
<td>true</td>
<td>Listing directories and  applying the filename regex pattern may be time consuming for directories  containing thousands of files. Caching the list of matching files can improve  performance. The order in which files are consumed will also be cached.  Requires that the file system keeps track of modification times with at least  a 1-second granularity.</td>
</tr>
<tr>
<td>fileHeader</td>
<td>false</td>
<td>Whether to add a header  storing the absolute path filename.</td>
</tr>
<tr>
<td>fileHeaderKey</td>
<td>file</td>
<td>Header key to use when  appending absolute path filename to event header.</td>
</tr>
</tbody></table>
<h2 id="配置文件：-2"><a href="#配置文件：-2" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example4-taildir-source.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/export/data/flume-example-data/flumedata/taildir_position.json</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">g1 g2</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g1</span> = <span class="string">/export/data/flume-example-data/weblog/web.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g2</span> = <span class="string">/export/data/flume-example-data/wxlog/wx.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeader</span> = <span class="string">true</span></span><br><span class="line"><span class="comment">#动态的header-keys eg：filepath=/../../../</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeaderKey</span> = <span class="string">filepath</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#写死的header-keys（静态的） eg:a1 = aa1</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g1.a1</span> = <span class="string">aa1</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g1.b1</span> = <span class="string">bb1</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g2.a2</span> = <span class="string">aa2</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g2.b2</span> = <span class="string">bb2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.maxBatchCount</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">10000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="启动测试：-2"><a href="#启动测试：-2" class="headerlink" title="启动测试："></a><strong>启动测试：</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf/ -f  myconf/example4-taildir-source.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>经过人为破坏测试，发现， this source还是真正挺reliable的，不会丢失数据，但在极端情况下可能会产生重复数据。</p>
<h1 id="五、avro-source"><a href="#五、avro-source" class="headerlink" title="五、avro source"></a>五、avro source</h1><h2 id="基本介绍："><a href="#基本介绍：" class="headerlink" title="基本介绍："></a><strong>基本介绍：</strong></h2><p>Avro source 是通过<code>监听一个网络端口来接收数据</code>，而且接受的数据必须是使用<code>avro序列化框架</code>序列化后的数据（必须是：avro序列化流）；Avro是一种序列化框架，<code>跨语言的</code>；</p>
<blockquote>
<p>扩展：什么是序列化，什么是序列化框架？</p>
<p>序列化： <code>是将一个有复杂结构的数据块（对象）变成扁平的（线性的）二进制序列</code></p>
<p>序列化框架： 一套现成的软件，可以按照既定策略，将对象转成二进制序列</p>
<p>比如： jdk就有： ObjectOutputStream</p>
<p>​       	 hadoop就有： Writable</p>
<p>​    		跨平台的序列化框架： avro</p>
</blockquote>
<h2 id="工作机制：-3"><a href="#工作机制：-3" class="headerlink" title="工作机制："></a><strong>工作机制：</strong></h2><p><code>启动一个网络服务，监听一个端口，收集端口上收到的avro序列化数据流</code></p>
<p>该source中拥有avro的反序列化器，能够将收到的二进制流进行正确反序列化，并装入一个event写入channel！</p>
<h2 id="参数详解：-3"><a href="#参数详解：-3" class="headerlink" title="参数详解："></a><strong>参数详解：</strong></h2><table>
<thead>
<tr>
<th><strong>Property Name</strong></th>
<th><strong>Default</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>channels</strong></td>
<td>–</td>
<td></td>
</tr>
<tr>
<td><strong>type</strong></td>
<td>–</td>
<td>本source的别名： avro</td>
</tr>
<tr>
<td><strong>bind</strong></td>
<td>–</td>
<td>要绑定的地址</td>
</tr>
<tr>
<td><strong>port</strong></td>
<td>–</td>
<td>要绑定的端口号</td>
</tr>
<tr>
<td><strong>threads</strong></td>
<td>–</td>
<td><strong>服务的最大线程数（最好大于<strong><strong>source</strong></strong>所对接的上游发送者数量）</strong></td>
</tr>
<tr>
<td>selector.type</td>
<td></td>
<td></td>
</tr>
<tr>
<td>selector.*</td>
<td></td>
<td></td>
</tr>
<tr>
<td>interceptors</td>
<td>–</td>
<td>Space-separated list of interceptors</td>
</tr>
<tr>
<td>interceptors.*</td>
<td></td>
<td></td>
</tr>
<tr>
<td>compression-type</td>
<td>none</td>
<td>压缩类型：跟发过来的数据是否压缩要匹配：none | deflate</td>
</tr>
<tr>
<td>ssl</td>
<td>false</td>
<td>Set this to true to enable SSL encryption. If SSL is enabled,  you must also specify a “keystore” and a “keystore-password”, either through  component level parameters (see below) or as global SSL parameters (see <a href="file:///D:/install-pkgs/apache-flume-1.9.0-bin/docs/FlumeUserGuide.html#ssl-tls-support">SSL&#x2F;TLS support</a> section).</td>
</tr>
<tr>
<td>keystore</td>
<td>–</td>
<td>This is the path to a Java keystore file. If not specified here,  then the global keystore will be used (if defined, otherwise configuration  error).</td>
</tr>
<tr>
<td>keystore-password</td>
<td>–</td>
<td>The password for the Java keystore. If not specified here, then  the global keystore password will be used (if defined, otherwise  configuration error).</td>
</tr>
<tr>
<td>keystore-type</td>
<td>JKS</td>
<td>The type of the Java keystore. This can be “JKS” or “PKCS12”. If  not specified here, then the global keystore type will be used (if defined,  otherwise the default is JKS).</td>
</tr>
<tr>
<td>exclude-protocols</td>
<td>SSLv3</td>
<td>Space-separated list of SSL&#x2F;TLS protocols to exclude. SSLv3 will  always be excluded in addition to the protocols specified.</td>
</tr>
<tr>
<td>include-protocols</td>
<td>–</td>
<td>Space-separated list of SSL&#x2F;TLS protocols to include. The  enabled protocols will be the included protocols without the excluded  protocols. If included-protocols is empty, it includes every supported  protocols.</td>
</tr>
<tr>
<td>exclude-cipher-suites</td>
<td>–</td>
<td>Space-separated list of cipher suites to exclude.</td>
</tr>
<tr>
<td>include-cipher-suites</td>
<td>–</td>
<td>Space-separated list of cipher suites to include. The enabled  cipher suites will be the included cipher suites without the excluded cipher  suites. If included-cipher-suites is empty, it includes every supported  cipher suites.</td>
</tr>
<tr>
<td>ipFilter</td>
<td>false</td>
<td>Set this to true to enable ipFiltering for netty</td>
</tr>
<tr>
<td>ipFilterRules</td>
<td>–</td>
<td>Define N netty ipFilter pattern rules with this config.</td>
</tr>
</tbody></table>
<h2 id="配置文件：-3"><a href="#配置文件：-3" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example5-avro-source.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">4141</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">200</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<h2 id="启动测试：-3"><a href="#启动测试：-3" class="headerlink" title="启动测试："></a><strong>启动测试：</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">启动agent：</span><br><span class="line"></span><br><span class="line">bin/flume-ng agent -c conf -f  myconf/example5-avro-source.conf -n a1 -Dflume.root.logger=INFO,console  </span><br><span class="line"></span><br><span class="line">新建avro-log.txt，用一个客户端去给启动好的source发送avro序列化数据：</span><br><span class="line"></span><br><span class="line">bin/flume-ng avro-client --host node1  --port 4141  -F /export/data/flume-example-data/avro-log.txt</span><br></pre></td></tr></table></figure>



<h1 id="六、使用File-Channel实现数据持久化"><a href="#六、使用File-Channel实现数据持久化" class="headerlink" title="六、使用File Channel实现数据持久化"></a>六、使用File Channel实现数据持久化</h1><p>使用组件</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#file-channel">File Channel</a></li>
</ul>
<p>属性设置</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>type</strong></td>
<td align="left">–</td>
<td align="left"><code>file</code></td>
</tr>
<tr>
<td align="left">checkpointDir</td>
<td align="left">~&#x2F;.flume&#x2F;file-channel&#x2F;checkpoint</td>
<td align="left">检查点文件存放路径</td>
</tr>
<tr>
<td align="left">dataDirs</td>
<td align="left">~&#x2F;.flume&#x2F;file-channel&#x2F;data</td>
<td align="left">日志存储路径，多个路径使用逗号分隔. 使用不同的磁盘上的多个路径能提高file channel的性能</td>
</tr>
</tbody></table>
<p>添加配置文件file-channel.conf，添加一个FileChannel</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example6-file-channel.conf</span></span><br><span class="line"><span class="comment"># 定义agent名称为a1</span></span><br><span class="line"><span class="comment"># 设置3个组件的名称</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="comment"># 多个channel使用空格分隔</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1 c2</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置source类型为NetCat,监听地址为本机，端口为44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">netcat</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置sink类型为Logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置FileChannel,checkpointDir为检查点文件存储目录，dataDirs为日志数据存储目录，</span></span><br><span class="line"><span class="attr">a1.channels.c2.type</span> = <span class="string">file</span></span><br><span class="line"><span class="attr">a1.channels.c2.checkpointDir</span> = <span class="string">/export/data/flume-example-data/flumedata/checkpoint_filechannel</span></span><br><span class="line"><span class="attr">a1.channels.c2.dataDirs</span> = <span class="string">/export/data/flume-example-data/flumedata/data_filechannel</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 将source和sink绑定到channel上</span></span><br><span class="line"><span class="comment"># source同时绑定到c1和c2上</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1 c2</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<p>为了方便日志打印，可以将<code>-Dflume.root.logger=INFO,console</code>添加在conf的环境配置中，从模板复制一份配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cp flume-env.sh.template flume-env.sh</span><br><span class="line">vi flume-env.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加JAVA_OPTS</span></span><br><span class="line">export JAVA_OPTS=&quot;-Dflume.root.logger=INFO,console&quot;</span><br></pre></td></tr></table></figure>

<p>启动Flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/example6-file-channel.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>



<p>通过Netcat发送数据，此时发送到c2的数据没有被消费，关闭Flume，修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sink绑定到c2上</span></span><br><span class="line">a1.sinks.k1.channel = c2</span><br></pre></td></tr></table></figure>

<p>重启Flume，可以看到会重新消费c2的数据</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200323164045854.png" alt="image-20200323164045854"></p>
<h1 id="七、利用avro-source和avro-sink实现agent级联"><a href="#七、利用avro-source和avro-sink实现agent级联" class="headerlink" title="七、利用avro source和avro sink实现agent级联"></a>七、利用avro source和avro sink实现agent级联</h1><h2 id="基本介绍：-1"><a href="#基本介绍：-1" class="headerlink" title="基本介绍："></a><strong>基本介绍：</strong></h2><p>级联的场景属于跨网络中转传输</p>
<h2 id="多个agent模型"><a href="#多个agent模型" class="headerlink" title="多个agent模型"></a>多个agent模型</h2><p>可以将多个Flume agent 程序连接在一起，其中一个agent的sink将数据发送到另一个agent的source。Avro文件格式是使用Flume通过网络发送数据的标准方法。</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200324142535996.png" alt="image-20200324142535996"></p>
<p>从多个Web服务器收集日志，发送到一个或多个集中处理的agent，之后再发往日志存储中心：</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200324151344310.png" alt="image-20200324151344310"></p>
<p>同样的日志发送到不同的目的地：</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200324151408108.png" alt="image-20200324151408108"></p>
<h2 id="需求说明："><a href="#需求说明：" class="headerlink" title="需求说明："></a><strong>需求说明：</strong></h2><h3 id="（1）机房跨网段flume中转传输网络示意图："><a href="#（1）机房跨网段flume中转传输网络示意图：" class="headerlink" title="（1）机房跨网段flume中转传输网络示意图："></a>（1）机房跨网段flume中转传输网络示意图：</h3><p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5C%E6%9C%BA%E6%88%BF%E8%B7%A8%E7%BD%91%E6%AE%B5flume%E4%B8%AD%E8%BD%AC%E4%BC%A0%E8%BE%93%E7%BD%91%E7%BB%9C%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="机房跨网段flume中转传输网络示意图"></p>
<h3 id="（2）流量汇聚传输网络示意图："><a href="#（2）流量汇聚传输网络示意图：" class="headerlink" title="（2）流量汇聚传输网络示意图："></a>（2）流量汇聚传输网络示意图：</h3><p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5C%E6%B5%81%E9%87%8F%E6%B1%87%E8%81%9A%E4%BC%A0%E8%BE%93%E7%BD%91%E7%BB%9C%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="流量汇聚传输网络示意图"></p>
<h3 id="（3）app上报日志及flume采集全流程示意图-2023-x2F-1-x2F-17-15-30-19"><a href="#（3）app上报日志及flume采集全流程示意图-2023-x2F-1-x2F-17-15-30-19" class="headerlink" title="（3）app上报日志及flume采集全流程示意图 2023&#x2F;1&#x2F;17 15:30:19"></a>（3）app上报日志及flume采集全流程示意图 2023&#x2F;1&#x2F;17 15:30:19</h3><p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Capp%E4%B8%8A%E6%8A%A5%E6%97%A5%E5%BF%97%E5%8F%8Aflume%E9%87%87%E9%9B%86%E5%85%A8%E6%B5%81%E7%A8%8B%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="app上报日志及flume采集全流程示意图"></p>
<h2 id="配置文件：-4"><a href="#配置文件：-4" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#上游服务器配置 example7-1-taildir-f-avro.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/export/data/flume-example-data/flumedata/taildir_position.json</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">g1 g2</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g1</span> = <span class="string">/export/data/flume-example-data/weblog/web.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g2</span> = <span class="string">/export/data/flume-example-data/wxlog/wx.*</span></span><br><span class="line"><span class="comment">#提高吞吐量</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="comment">#动态的header-keys eg：filepath=/../../../</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeaderKey</span> = <span class="string">filepath</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#拦截器配置，添加header=timestamp</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors</span> = <span class="string">i1</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.type</span> = <span class="string">timestamp</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.headerName</span> = <span class="string">timestamp</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">file</span></span><br><span class="line"><span class="comment">#本机数据汇集检查点、event存储目录</span></span><br><span class="line"><span class="attr">a1.channels.c1.checkpointDir</span> = <span class="string">/export/data/flume-example-data/flumedata/checkpoint</span></span><br><span class="line"><span class="attr">a1.channels.c1.dataDirs</span> = <span class="string">/export/data/flume-example-data/flumedata/data</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">2000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k1.batch-size</span> = <span class="string">1000</span></span><br><span class="line"><span class="comment">#下游目标主机、端口</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = <span class="string">node3</span></span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="string">44444</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下游服务器配置 example7-2-avro-f-hdfs.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#下游数据汇集avro source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.threads</span> = <span class="string">10</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">file</span></span><br><span class="line"><span class="attr">a1.channels.c1.checkpointDir</span> = <span class="string">/export/data/flume-example-data/flumedata/checkpoint</span></span><br><span class="line"><span class="attr">a1.channels.c1.dataDirs</span> = <span class="string">/export/data/flume-example-data/flumedata/data</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">2000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#hdfs sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = <span class="string">hdfs://node1:8020/logdata/%Y-%m-%d/%H/</span></span><br><span class="line"><span class="comment">#eg：文件名 logdata_34438hxfd.log，在滚动时，logdata_34438hxfd.log.tmp</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = <span class="string">logdata_</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileSuffix</span> = <span class="string">.log</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#三个条件没有优先级，谁先达到就进行滚动</span></span><br><span class="line"><span class="comment">#按时间间隔滚动</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="string">0</span></span><br><span class="line"><span class="comment">#按文件大小滚动 256MB</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="string">268435456</span></span><br><span class="line"><span class="comment">#按event条数滚动</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="string">100000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.codeC</span> = <span class="string">gzip</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = <span class="string">CompressedStream</span></span><br></pre></td></tr></table></figure>

<h2 id="级联案例操作手册"><a href="#级联案例操作手册" class="headerlink" title="级联案例操作手册"></a>级联案例操作手册</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">级联案例操作手册</span><br><span class="line"></span><br><span class="line">-- 1. 启动hdfs，并检查工作状态</span><br><span class="line">-- 2. 把案例的上游配置文件，保存到node1,node2上</span><br><span class="line">-- 3. 把案例的下游配置文件，保存到node3上</span><br><span class="line"></span><br><span class="line">-- 4. 启动下游node3上的flume agent</span><br><span class="line">bin/flume-ng agent -n a1 -c conf/ -f myconf/example7-2-avro-f-hdfs.conf -Dflume.root.logger=DEBUG,console</span><br><span class="line"></span><br><span class="line">-- 5. （在node1和node2上）准备两个日志目录来生成模拟日志数据</span><br><span class="line">mkdir /export/data/flume-example-data/weblog/</span><br><span class="line">mkdir /export/data/flume-example-data/wxlog/</span><br><span class="line"></span><br><span class="line">-- 6.（在node1和node2上）利用shell脚本生成日志数据  </span><br><span class="line">vim avro-hdfs.sh</span><br><span class="line"></span><br><span class="line">while true</span><br><span class="line">do</span><br><span class="line">echo webwebwebwebweb &gt;&gt; /export/data/flume-example-data/weblog/web-access.log</span><br><span class="line">echo wxwxwxwxwxwxwx  &gt;&gt; /export/data/flume-example-data/wxlog/wx-access.log </span><br><span class="line">sleep 0.01</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">-- 7.启动node1和node2上的flume agent</span><br><span class="line">nohup bin/flume-ng agent -n a1 -c conf/ -f myconf/example7-1-taildir-f-avro.conf 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>



<h1 id="八、拦截器"><a href="#八、拦截器" class="headerlink" title="八、拦截器"></a>八、拦截器</h1><p>拦截器可以修改或者丢弃事件，Flume支持链式调用拦截器，拦截器定义在source中</p>
<h2 id="（1）Host-Interceptor"><a href="#（1）Host-Interceptor" class="headerlink" title="（1）Host Interceptor"></a>（1）Host Interceptor</h2><p>这个拦截器将运行agent的hostname 或者 IP地址写入到事件的headers中</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>type</strong></td>
<td align="left">–</td>
<td align="left"><code>host</code></td>
</tr>
<tr>
<td align="left">preserveExisting</td>
<td align="left">false</td>
<td align="left">如果header已经存在host, 是否要保留 - true保留原始的，false写入当前机器</td>
</tr>
<tr>
<td align="left">useIP</td>
<td align="left">true</td>
<td align="left">true为IP地址, false为 hostname.</td>
</tr>
<tr>
<td align="left">hostHeader</td>
<td align="left">host</td>
<td align="left">header中key的名称</td>
</tr>
</tbody></table>
<p>在myconf中添加example8-interceptor.conf</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example8-interceptor.conf</span></span><br><span class="line"><span class="comment"># 定义agent名称为a1</span></span><br><span class="line"><span class="comment"># 设置3个组件的名称</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置source类型为NetCat,监听地址为本机，端口为44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">netcat</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="comment"># 配置拦截器为host</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors</span> = <span class="string">i1 </span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.type</span> = <span class="string">host</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置sink类型为Logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 将source和sink绑定到channel上</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<p>启动flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/example8-interceptor.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<h2 id="（2）Timestamp-Interceptor"><a href="#（2）Timestamp-Interceptor" class="headerlink" title="（2）Timestamp Interceptor"></a>（2）Timestamp Interceptor</h2><p>这个拦截器将当前时间写入到事件的headers中</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>type</strong></td>
<td align="left">–</td>
<td align="left"><code>timestamp</code></td>
</tr>
<tr>
<td align="left">headerName</td>
<td align="left">timestamp</td>
<td align="left">header中key的名称</td>
</tr>
<tr>
<td align="left">preserveExisting</td>
<td align="left">false</td>
<td align="left">If the timestamp already exists, should it be preserved - true or false</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1 i2</span><br><span class="line">a1.sources.r1.interceptors.i1.type = host</span><br><span class="line">a1.sources.r1.interceptors.i2.type = timestamp</span><br></pre></td></tr></table></figure>

<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200113212610717.png" alt="image-20200113212610717"></p>
<h2 id="（3）Static-Interceptor"><a href="#（3）Static-Interceptor" class="headerlink" title="（3）Static Interceptor"></a>（3）Static Interceptor</h2><p>运行用户对所有的事件添加固定的header</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>type</strong></td>
<td align="left">–</td>
<td align="left"><code>static</code></td>
</tr>
<tr>
<td align="left">preserveExisting</td>
<td align="left">true</td>
<td align="left">If configured header already exists, should it be preserved - true or false</td>
</tr>
<tr>
<td align="left">key</td>
<td align="left">key</td>
<td align="left">header 中key名称</td>
</tr>
<tr>
<td align="left">value</td>
<td align="left">value</td>
<td align="left">header 中value值</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1 i2 i3</span><br><span class="line">a1.sources.r1.interceptors.i1.type = host</span><br><span class="line">a1.sources.r1.interceptors.i2.type = timestamp</span><br><span class="line">a1.sources.r1.interceptors.i3.type = static</span><br><span class="line">a1.sources.r1.interceptors.i3.key = datacenter</span><br><span class="line">a1.sources.r1.interceptors.i3.value = NEW_YORK</span><br></pre></td></tr></table></figure>

<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200113212850218.png" alt="image-20200113212850218"></p>
<h2 id="（4）UUID-Interceptor"><a href="#（4）UUID-Interceptor" class="headerlink" title="（4）UUID Interceptor"></a>（4）UUID Interceptor</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1 i2 i3 i4</span><br><span class="line">a1.sources.r1.interceptors.i1.type = host</span><br><span class="line">a1.sources.r1.interceptors.i2.type = timestamp</span><br><span class="line">a1.sources.r1.interceptors.i3.type = static</span><br><span class="line">a1.sources.r1.interceptors.i3.key = datacenter</span><br><span class="line">a1.sources.r1.interceptors.i3.value = NEW_YORK</span><br><span class="line">a1.sources.r1.interceptors.i4.type = org.apache.flume.sink.solr.morphline.UUIDInterceptor$Builder</span><br></pre></td></tr></table></figure>

<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200113213451217.png" alt="image-20200113213451217"></p>
<h2 id="（5）Search-and-Replace-Interceptor"><a href="#（5）Search-and-Replace-Interceptor" class="headerlink" title="（5）Search and Replace Interceptor"></a>（5）Search and Replace Interceptor</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1 i2 i3 i4 i5</span><br><span class="line">a1.sources.r1.interceptors.i1.type = host</span><br><span class="line">a1.sources.r1.interceptors.i2.type = timestamp</span><br><span class="line">a1.sources.r1.interceptors.i3.type = static</span><br><span class="line">a1.sources.r1.interceptors.i3.key = datacenter</span><br><span class="line">a1.sources.r1.interceptors.i3.value = NEW_YORK</span><br><span class="line">a1.sources.r1.interceptors.i4.type = org.apache.flume.sink.solr.morphline.UUIDInterceptor$Builder</span><br><span class="line">a1.sources.r1.interceptors.i5.type = search_replace</span><br><span class="line">a1.sources.r1.interceptors.i5.searchPattern = \\d&#123;6&#125;</span><br><span class="line">a1.sources.r1.interceptors.i5.replaceString = ******1234</span><br></pre></td></tr></table></figure>

<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200113220257571.png" alt="image-20200113220257571"></p>
<h2 id="（6）自定义拦截器"><a href="#（6）自定义拦截器" class="headerlink" title="（6）自定义拦截器"></a>（6）自定义拦截器</h2><p>新建工程，添加pom引用</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flume<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flume-ng-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>添加自定义拦截器</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.gson.Gson;</span><br><span class="line"><span class="keyword">import</span> com.google.gson.reflect.TypeToken;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.codec.digest.DigestUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.interceptor.Interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventTimestampInterceptor</span> <span class="keyword">implements</span> <span class="title class_">Interceptor</span> &#123;</span><br><span class="line"></span><br><span class="line">    String timeStampFiledName;</span><br><span class="line">    String toEncryFieldName;</span><br><span class="line">    String keyName;</span><br><span class="line">    Gson gson;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">EventTimestampInterceptor</span><span class="params">(String timeStampFiledName,String toEncryFieldName,String keyName)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.timeStampFiledName = timeStampFiledName;</span><br><span class="line">        <span class="built_in">this</span>.toEncryFieldName = toEncryFieldName;</span><br><span class="line">        <span class="built_in">this</span>.keyName = keyName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化工作所在的方法</span></span><br><span class="line"><span class="comment">     * 在拦截操作之前，会被调用一次</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">()</span> &#123;</span><br><span class="line">        gson = <span class="keyword">new</span> <span class="title class_">Gson</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 拦截操作的具体逻辑所在方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> event</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> Event <span class="title function_">intercept</span><span class="params">(Event event)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">byte</span>[] body = event.getBody();</span><br><span class="line">        <span class="type">String</span> <span class="variable">lineJson</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(body);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取时间戳，放入header</span></span><br><span class="line">        Map&lt;String,Object&gt; map = gson.fromJson(lineJson, <span class="keyword">new</span> <span class="title class_">TypeToken</span>&lt;HashMap&lt;String,Object&gt;&gt;()&#123;&#125;.getType());</span><br><span class="line">        <span class="type">Double</span> <span class="variable">ts</span> <span class="operator">=</span> (Double)map.get(timeStampFiledName);</span><br><span class="line">        event.getHeaders().put(keyName,ts.longValue()+<span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将账号字段进行加密</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> (String) map.get(toEncryFieldName);</span><br><span class="line">        <span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> DigestUtils.md5Hex(s);</span><br><span class="line">        map.put(toEncryFieldName,s1);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将加密处理后的日志内容（map中），重新恢复成json，并set到event的body中</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">newJson</span> <span class="operator">=</span> gson.toJson(map);</span><br><span class="line">        event.setBody(newJson.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> event;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> List&lt;Event&gt; <span class="title function_">intercept</span><span class="params">(List&lt;Event&gt; list)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Event event : list) &#123;</span><br><span class="line">            intercept(event);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * agent关闭时，会调用该方法来做一些清理工作</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">EventTimestampInterceptorBuilder</span> <span class="keyword">implements</span> <span class="title class_">Builder</span>&#123;</span><br><span class="line"></span><br><span class="line">        String timeStampFiledName;</span><br><span class="line">        String toEncryFieldName;</span><br><span class="line">        String keyName;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 构造拦截器实例对象的方法</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">public</span> Interceptor <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">EventTimestampInterceptor</span>(timeStampFiledName,toEncryFieldName,keyName);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 从配置文件中获取配置参数的方法</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">            timeStampFiledName = context.getString(<span class="string">&quot;tsFiledName&quot;</span>);</span><br><span class="line">            toEncryFieldName = context.getString(<span class="string">&quot;toEncryFieldName&quot;</span>);</span><br><span class="line">            keyName = context.getString(<span class="string">&quot;keyName&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>将项目打成jar包后复制到Flume安装目录的lib目录中</p>
<p>修改上游服务器配置 taildir-f-avro.conf为taildir-f-avro-interceptor.conf</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#上游服务器配置example9-1-taildir-f-avro-interceptor.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/export/data/flume-example-data/flumedata/taildir_position.json</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">g1</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g1</span> = <span class="string">/export/data/flume-example-data/app/event.*</span></span><br><span class="line"><span class="comment">#提高吞吐量</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="comment">#动态的header-keys eg：filepath=/../../../</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeaderKey</span> = <span class="string">filepath</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#拦截器配置,添加自定义拦截器</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors</span> = <span class="string">i1</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.type</span> = <span class="string">ccjz.rgzn.flume.EventTimestampInterceptor$EventTimestampInterceptorBuilder</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.tsFiledName</span> = <span class="string">timeStamp</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.keyName</span> = <span class="string">timestamp</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.toEncryFieldName</span> = <span class="string">account</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">file</span></span><br><span class="line"><span class="comment">#本机数据汇集检查点、event存储目录</span></span><br><span class="line"><span class="attr">a1.channels.c1.checkpointDir</span> = <span class="string">/export/data/flume-example-data/flumedata/checkpoint</span></span><br><span class="line"><span class="attr">a1.channels.c1.dataDirs</span> = <span class="string">/export/data/flume-example-data/flumedata/data</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">2000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k1.batch-size</span> = <span class="string">1000</span></span><br><span class="line"><span class="comment">#下游目标主机、端口</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = <span class="string">node3</span></span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="string">44444</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下游服务器配置 example9-2-avro-f-hdfs-interceptor.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#下游数据汇集avro source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.threads</span> = <span class="string">10</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">file</span></span><br><span class="line"><span class="attr">a1.channels.c1.checkpointDir</span> = <span class="string">/export/data/flume-example-data/flumedata/checkpoint</span></span><br><span class="line"><span class="attr">a1.channels.c1.dataDirs</span> = <span class="string">/export/data/flume-example-data/flumedata/data</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">2000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#hdfs sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = <span class="string">hdfs://node1:8020/logdata-interceptor/%Y-%m-%d/%H/</span></span><br><span class="line"><span class="comment">#eg：文件名 logdata_34438hxfd.log，在滚动时，logdata_34438hxfd.log.tmp</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = <span class="string">logdata_</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileSuffix</span> = <span class="string">.log</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">#三个条件没有优先级，谁先达到就进行滚动</span></span><br><span class="line"><span class="comment">#按时间间隔滚动</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="string">0</span></span><br><span class="line"><span class="comment">#按文件大小滚动 256MB</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="string">268435456</span></span><br><span class="line"><span class="comment">#按event条数滚动</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="string">100000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.codeC</span> = <span class="string">gzip</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = <span class="string">CompressedStream</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">自定义拦截器-级联案例操作手册</span><br><span class="line"></span><br><span class="line">-- 1. 启动hdfs，并检查工作状态</span><br><span class="line">-- 2. 把案例的上游配置文件，保存到node1,node2上,并将自定义的拦截器jar包保存到node1和node2flume的lib中</span><br><span class="line">-- 3. 把案例的下游配置文件，保存到node3上</span><br><span class="line"></span><br><span class="line">-- 4. 启动下游node3上的flume agent</span><br><span class="line">bin/flume-ng agent -n a1 -c conf/ -f myconf/example9-2-avro-f-hdfs-interceptor.conf -Dflume.root.logger=DEBUG,console</span><br><span class="line"></span><br><span class="line">-- 5. （在node1和node2上）上传两个日志目录来生成模拟日志数据</span><br><span class="line">mkdir /export/data/flume-example-data/app/</span><br><span class="line">mkdir /export/data/flume-example-data/app/</span><br><span class="line"></span><br><span class="line">-- 6.（在node1和node2上）修改配置文件，加大flume启动内存(选做)</span><br><span class="line">mv flume-env.sh.template flume-env.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">生产环境建议4G，测试环境以本机内存为参考</span></span><br><span class="line">export JAVA_OPTS=&quot;-Xms100m -Xmx2000m -Dcom.sun.management.jmxremote&quot;</span><br><span class="line"></span><br><span class="line">-- 7.启动node1和node2上的flume agent</span><br><span class="line">nohup bin/flume-ng agent -n a1 -c conf/ -f myconf/example9-1-taildir-f-avro-interceptor.conf 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">--8.去hdfs上查看是否采集到数据</span><br><span class="line">hadoop fs -text /logdata-interceptor/../../.. | tail</span><br></pre></td></tr></table></figure>

<h1 id="九、Flume常用组件详解：channel"><a href="#九、Flume常用组件详解：channel" class="headerlink" title="九、Flume常用组件详解：channel"></a>九、Flume常用组件详解：channel</h1><p>channel是agent中用来缓存event的repository（池，仓库）</p>
<p>source往channel中添加event</p>
<p>sink从channel中取并移除event</p>
<p>channel跟事务控制有极大关系；</p>
<p>channel 有容量大小、可靠性级别、事务容量等特性；</p>
<h2 id="（1）memory-channel"><a href="#（1）memory-channel" class="headerlink" title="（1）memory channel"></a>（1）memory channel</h2><h3 id="特性："><a href="#特性：" class="headerlink" title="特性："></a>特性：</h3><p>事件被存储在实现配置好容量的内存（队列）中。速度快，但可靠性较低，有可能会丢失数据</p>
<h3 id="参数："><a href="#参数：" class="headerlink" title="参数："></a>参数：</h3><table>
<thead>
<tr>
<th><strong>Property Name</strong></th>
<th><strong>Default</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>type</strong></td>
<td>–</td>
<td>别名： memory</td>
</tr>
<tr>
<td>capacity</td>
<td>100</td>
<td>能存储的最大事件event数</td>
</tr>
<tr>
<td>transactionCapacity</td>
<td>100</td>
<td>最大事务控制容量</td>
</tr>
<tr>
<td>keep-alive</td>
<td>3</td>
<td>添加或移除event的超时时间</td>
</tr>
<tr>
<td>byteCapacityBufferPercentage</td>
<td>20</td>
<td>除了body以外的字节所能占用的容量百分比</td>
</tr>
<tr>
<td>byteCapacity</td>
<td>see description</td>
<td>channel中最大的总byte数（只计算body）</td>
</tr>
</tbody></table>
<p>配置示例</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">10000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">10000</span></span><br><span class="line"><span class="attr">a1.channels.c1.byteCapacityBufferPercentage</span> = <span class="string">20</span></span><br><span class="line"><span class="attr">a1.channels.c1.byteCapacity</span> = <span class="string">800000</span></span><br></pre></td></tr></table></figure>

<p>MemoryChannel的逻辑相对简单，主要是通过MemoryTransaction中的putList、takeList与MemoryChannel中的queue打交道，这里的queue相当于持久化层，只不过放到了内存中，如果是FileChannel的话，会把这个queue放到本地文件中。下面表示了Event在一个使用了MemoryChannel的agent中数据流向：</p>
<p><strong>source —&gt; putList —&gt; queue —&gt; takeList —&gt; sink</strong></p>
<p>还需要注意的一点是，这里的事务可以嵌套使用，如下图：</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230121151610824.png" alt="image-20230121151610824"></p>
<p>当有两个agent级连时，sink的事务中包含了一个source的事务，这也应证了前面所说的：</p>
<p><strong>在任何时刻，Event至少在一个Channel中是完整有效的</strong></p>
<h2 id="（2）file-channel"><a href="#（2）file-channel" class="headerlink" title="（2）file channel"></a>（2）file channel</h2><h3 id="特性：-1"><a href="#特性：-1" class="headerlink" title="特性："></a>特性：</h3><p>event被缓存在本地磁盘文件中</p>
<p>可靠性高，不会丢失</p>
<p>但在极端情况下可能会重复数据</p>
<h3 id="参数：-1"><a href="#参数：-1" class="headerlink" title="参数："></a>参数：</h3><table>
<thead>
<tr>
<th><strong>Property Name   Default</strong></th>
<th><strong>Description</strong></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td><strong>type</strong></td>
<td>–</td>
<td>别名： file.</td>
</tr>
<tr>
<td>checkpointDir</td>
<td>~&#x2F;.flume&#x2F;file-channel&#x2F;checkpoint</td>
<td>Checkpoint信息保存目录</td>
</tr>
<tr>
<td>useDualCheckpoints</td>
<td>false</td>
<td>Checkpoint是否双重checkpoint机制</td>
</tr>
<tr>
<td>backupCheckpointDir</td>
<td>–</td>
<td>备份checkpoint的保存目录</td>
</tr>
<tr>
<td>dataDirs</td>
<td>~&#x2F;.flume&#x2F;file-channel&#x2F;data</td>
<td>Event数据缓存目录</td>
</tr>
<tr>
<td>transactionCapacity</td>
<td>10000</td>
<td>事务管理容量</td>
</tr>
<tr>
<td>checkpointInterval</td>
<td>30000</td>
<td>记录checkpoint信息的时间间隔</td>
</tr>
<tr>
<td>maxFileSize</td>
<td>2146435071</td>
<td>控制一个数据文件的大小规格</td>
</tr>
<tr>
<td>minimumRequiredSpace</td>
<td>524288000</td>
<td>所需的最低磁盘空间，低于则停止接收新数据</td>
</tr>
<tr>
<td>capacity</td>
<td>1000000</td>
<td>最大event缓存数</td>
</tr>
<tr>
<td>keep-alive</td>
<td>3</td>
<td>等待添加数据的最大时间</td>
</tr>
</tbody></table>
<h3 id="配置示例"><a href="#配置示例" class="headerlink" title="配置示例"></a>配置示例</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/root/taildir_chkp/taildir_position.json</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">f1</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f1</span> = <span class="string">/root/weblog/access.log</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeader</span> = <span class="string">true</span></span><br><span class="line"><span class="attr">a1.sources.ri.maxBatchCount</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">file</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="attr">a1.channels.c1.checkpointDir</span> = <span class="string">/root/flume_chkp</span></span><br><span class="line"><span class="attr">a1.channels.c1.dataDirs</span> = <span class="string">/root/flume_data</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c</span></span><br></pre></td></tr></table></figure>

<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>在使用taildir source 和  file channel的情况下，经过反复各种人为破坏，发现，没有数据丢失的现象发生；</p>
<p>但是，如果时间点掐的比较好(sink 取了一批数据写出，但还没来得及向channel提交事务)，会产生数据重复的现象！</p>
<h1 id="十、Flume常用组件详解：sink"><a href="#十、Flume常用组件详解：sink" class="headerlink" title="十、Flume常用组件详解：sink"></a>十、Flume常用组件详解：sink</h1><p>sink是从channel中获取、移除数据，并输出到下游（可能是下一级agent，也可能是最终目标存储系统）</p>
<h2 id="（1）hdfs-sink"><a href="#（1）hdfs-sink" class="headerlink" title="（1）hdfs sink"></a>（1）hdfs sink</h2><h3 id="特性：-2"><a href="#特性：-2" class="headerlink" title="特性："></a>特性：</h3><p>数据被最终发往hdfs</p>
<p>可以生成text文件或 sequence 文件，而且支持压缩；</p>
<p>支持生成文件的周期性roll机制：基于文件size，或者时间间隔，或者event数量；</p>
<p>目标路径，可以使用动态通配符替换，比如用%D代表当前日期；</p>
<p>当然，它也能从event的header中，取到一些标记来作为通配符替换；</p>
<p>header:{type&#x3D;acb}</p>
<p>&#x2F;weblog&#x2F;%{type}&#x2F;%D&#x2F; 就会被替换成： &#x2F;weblog&#x2F;abc&#x2F;19-06-09&#x2F;</p>
<h3 id="参数：-2"><a href="#参数：-2" class="headerlink" title="参数："></a>参数：</h3><table>
<thead>
<tr>
<th><strong>Name</strong></th>
<th><strong>Default</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>channel</strong></td>
<td>–</td>
<td>从哪个channel取数据</td>
</tr>
<tr>
<td><strong>type</strong></td>
<td>–</td>
<td>别名： hdfs</td>
</tr>
<tr>
<td><strong>hdfs.path</strong></td>
<td>–</td>
<td>目标hdfs存储路径（URI）</td>
</tr>
<tr>
<td>hdfs.filePrefix</td>
<td>FlumeData</td>
<td>指定生成的文件名前缀</td>
</tr>
<tr>
<td>hdfs.fileSuffix</td>
<td>–</td>
<td>后缀</td>
</tr>
<tr>
<td>hdfs.inUsePrefix</td>
<td>–</td>
<td>正在写入的文件的前缀标识</td>
</tr>
<tr>
<td>hdfs.inUseSuffix</td>
<td>.tmp</td>
<td>正在写入的文件的后缀标识</td>
</tr>
<tr>
<td>hdfs.rollInterval</td>
<td>30</td>
<td>切换文件的条件：间隔时间；为0则不生效（秒）</td>
</tr>
<tr>
<td>hdfs.rollSize</td>
<td>134217728</td>
<td>切换文件的条件：文件大小；为0则不生效</td>
</tr>
<tr>
<td>hdfs.rollCount</td>
<td>10</td>
<td>切换文件的条件：event条数；为0则不生效</td>
</tr>
<tr>
<td>hdfs.idleTimeout</td>
<td>0</td>
<td>不活跃文件的关闭超时时长；0则不自动关闭</td>
</tr>
<tr>
<td>hdfs.batchSize</td>
<td>100</td>
<td>从channel中取一批数据的最大大小；</td>
</tr>
<tr>
<td>hdfs.codeC</td>
<td>–</td>
<td>压缩编码: gzip, bzip2, lzo,  lzop, snappy</td>
</tr>
<tr>
<td>hdfs.fileType</td>
<td>SequenceFile</td>
<td>目标文件格式: SequenceFile, DataStream or CompressedStream   注意：DataStream 不能支持压缩  CompressedStream 必须设置压缩编码  SequenceFile 可压缩可不压缩</td>
</tr>
<tr>
<td>hdfs.maxOpenFiles</td>
<td>5000</td>
<td>允许同时最多打开的文件数；如果超出，则会关闭最早打开的</td>
</tr>
<tr>
<td>hdfs.minBlockReplicas</td>
<td>–</td>
<td>目标文件的block副本数</td>
</tr>
<tr>
<td>hdfs.writeFormat</td>
<td>Writable</td>
<td>指定sequence file中的对象类型；支持Text和Writable  同时请使用Text，否则后续数据处理平台可能无法解析</td>
</tr>
<tr>
<td>hdfs.threadsPoolSize</td>
<td>10</td>
<td>操作HDFS时的线程池大小</td>
</tr>
<tr>
<td>hdfs.rollTimerPoolSize</td>
<td>1</td>
<td>检查文件是否需要被roll的线程数</td>
</tr>
<tr>
<td>hdfs.kerberosPrincipal</td>
<td>–</td>
<td>Kerberos user principal for accessing secure HDFS</td>
</tr>
<tr>
<td>hdfs.kerberosKeytab</td>
<td>–</td>
<td>Kerberos keytab for accessing secure HDFS</td>
</tr>
<tr>
<td>hdfs.proxyUser</td>
<td></td>
<td></td>
</tr>
<tr>
<td>hdfs.round</td>
<td>false</td>
<td>目录通配符切换是是否需要切掉尾数</td>
</tr>
<tr>
<td>hdfs.roundValue</td>
<td>10</td>
<td>时间尾数切掉多少</td>
</tr>
<tr>
<td>hdfs.roundUnit</td>
<td>minute</td>
<td>时间尾数切掉大小的单位- second, minute or hour.</td>
</tr>
<tr>
<td>hdfs.timeZone</td>
<td>Local Time</td>
<td>时间通配符所使用的时区</td>
</tr>
<tr>
<td>hdfs.useLocalTimeStamp</td>
<td>false</td>
<td>所用的时间是否要从agent sink本地获取</td>
</tr>
<tr>
<td>hdfs.closeTries</td>
<td>0</td>
<td>重命名已完成文件的重试次数；0则一直尝试重命名</td>
</tr>
<tr>
<td>hdfs.retryInterval</td>
<td>180</td>
<td>关闭一个文件的重试时间间隔</td>
</tr>
<tr>
<td>serializer</td>
<td>TEXT</td>
<td>将channel中的event body解析成什么格式：Text| avro_event ； 也可以使用自定义的序列化器</td>
</tr>
<tr>
<td>serializer.*</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>小  提  示：什么叫做URI</th>
<th><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cclip_image002.jpg" alt="img"></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="配置示例："><a href="#配置示例：" class="headerlink" title="配置示例："></a>配置示例：</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 定义</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">## source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">exec</span></span><br><span class="line"><span class="attr">a1.sources.r1.command</span> = <span class="string">tail -F /root/logs/a.log</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors</span> = <span class="string">i1</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.type</span> = <span class="string">timestamp</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">## channel</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">100000000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">## sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = <span class="string">hdfs://node1:8020/logdata/%&#123;b&#125;/%Y-%m-%d/%H-%M</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.round</span> = <span class="string">true</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.roundValue</span> = <span class="string">10</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.roundUnit</span> = <span class="string">minute</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = <span class="string">doit_</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileSuffix</span> = <span class="string">.log.gz</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="string">102400</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="string">0</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = <span class="string">CompressedStream</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.codeC</span> = <span class="string">gzip</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.writeFormat</span> = <span class="string">Text</span></span><br></pre></td></tr></table></figure>



<h3 id="测试："><a href="#测试：" class="headerlink" title="测试："></a>测试：</h3><ol>
<li>启动hdfs</li>
<li>清除以前的taildirsource产生的偏移量记录文件、filechannel缓存的数据目录和checkpoint目录</li>
<li>启动agent</li>
<li>用for循环脚本往日志文件中不断写入新的数据</li>
<li>到hdfs中观察结果</li>
</ol>
<h2 id="2-avro-sink"><a href="#2-avro-sink" class="headerlink" title="(2)avro sink"></a>(2)avro sink</h2><h3 id="特性：-3"><a href="#特性：-3" class="headerlink" title="特性："></a>特性：</h3><p>avro sink用来向avro source发送avro序列化数据，这样就可以实现agent之间的级联</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230128000603210.png" alt="image-20230128000603210"></p>
<h3 id="参数：-3"><a href="#参数：-3" class="headerlink" title="参数："></a>参数：</h3><table>
<thead>
<tr>
<th><strong>Property Name</strong></th>
<th><strong>Default</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>channel</strong></td>
<td>–</td>
<td></td>
</tr>
<tr>
<td><strong>type</strong></td>
<td>–</td>
<td>The component type name,  needs to be avro.</td>
</tr>
<tr>
<td><strong>hostname</strong></td>
<td>–</td>
<td>目标avro source的主机</td>
</tr>
<tr>
<td><strong>port</strong></td>
<td>–</td>
<td>目标avro source的绑定端口</td>
</tr>
<tr>
<td>batch-size</td>
<td>100</td>
<td>number of event to batch  together for send.</td>
</tr>
<tr>
<td>connect-timeout</td>
<td>20000</td>
<td>连接超时时间</td>
</tr>
<tr>
<td>request-timeout</td>
<td>20000</td>
<td>请求超时时间</td>
</tr>
<tr>
<td>reset-connection-interval</td>
<td>none</td>
<td>Amount of time (s)  before the connection to the next hop is reset. This will force the Avro Sink  to reconnect to the next hop. This will allow the sink to connect to hosts  behind a hardware load-balancer when news hosts are added without having to  restart the agent.</td>
</tr>
<tr>
<td>compression-type</td>
<td>none</td>
<td>This can be “none” or “deflate”. The  compression-type must match the compression-type of matching AvroSource</td>
</tr>
<tr>
<td>compression-level</td>
<td>6</td>
<td>The level of compression  to compress event. 0 &#x3D; no compression and 1-9 is compression. The higher the  number the more compression</td>
</tr>
<tr>
<td>ssl</td>
<td>false</td>
<td>Set to true to enable  SSL for this AvroSink. When configuring SSL, you can optionally set a “truststore”, “truststore-password”, “truststore-type”, and specify whether to “trust-all-certs”.</td>
</tr>
<tr>
<td>trust-all-certs</td>
<td>false</td>
<td>If this is set to true,  SSL server certificates for remote servers (Avro Sources) will not be  checked. This should NOT be used in production because it makes it easier for  an attacker to execute a man-in-the-middle attack and “listen in” on  the encrypted connection.</td>
</tr>
<tr>
<td>truststore</td>
<td>–</td>
<td>The path to a custom  Java truststore file. Flume uses the certificate authority information in  this file to determine whether the remote Avro Source’s SSL authentication credentials should be trusted. If not  specified, then the global keystore will be used. If the global keystore not  specified either, then the default Java JSSE certificate authority files  (typically “jssecacerts” or “cacerts” in the Oracle JRE) will be used.</td>
</tr>
<tr>
<td>truststore-password</td>
<td>–</td>
<td>The password for the  truststore. If not specified, then the global keystore password will be used  (if defined).</td>
</tr>
<tr>
<td>truststore-type</td>
<td>JKS</td>
<td>The type of the Java  truststore. This can be “JKS” or other supported Java truststore type. If not specified, then  the global keystore type will be used (if defined, otherwise the defautl is  JKS).</td>
</tr>
<tr>
<td>exclude-protocols</td>
<td>SSLv3</td>
<td>Space-separated list of  SSL&#x2F;TLS protocols to exclude. SSLv3 will always be excluded in addition to  the protocols specified.</td>
</tr>
<tr>
<td>maxIoWorkers</td>
<td>2 * the number of  available processors in the machine</td>
<td>The maximum number of  I&#x2F;O worker threads. This is configured on the NettyAvroRpcClient  NioClientSocketChannelFactory.</td>
</tr>
</tbody></table>
<h3 id="配置示例：-1"><a href="#配置示例：-1" class="headerlink" title="配置示例："></a>配置示例：</h3><p>级联配置，需要至少两个flume agent来演示</p>
<p>在C703上，配置avro sink 发送者</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## c703 ##</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">s1</span></span><br><span class="line"><span class="attr">a1.sources.s1.type</span> = <span class="string">exec</span></span><br><span class="line"><span class="attr">a1.sources.s1.command</span> = <span class="string">tail -F /root/weblog/access.log</span></span><br><span class="line"><span class="attr">a1.sources.s1.channels</span> = <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = <span class="string">c701</span></span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="string">4545</span></span><br></pre></td></tr></table></figure>



<p>在C701上，配置avro source 接收者</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## c701 ##</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">s1</span></span><br><span class="line"><span class="attr">a1.sources.s1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sources.s1.hostname</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.s1.port</span> = <span class="string">4545</span></span><br><span class="line"><span class="attr">a1.sources.s1.channel</span> = <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>



<h3 id="启动测试：-4"><a href="#启动测试：-4" class="headerlink" title="启动测试："></a>启动测试：</h3><p>先在C701上启动接受者avro source（服务）</p>
<p><em>bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;avro-mem-logger.conf -Dflume.root.logger&#x3D;INFO,console</em></p>
<p>再在C703上启动发送者avro sink（客户端）</p>
<p><em>bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;tail-mem-avro.conf -Dflume.root.logger&#x3D;INFO,console</em></p>
<h1 id="十一、Channel选择器（channel-selector）"><a href="#十一、Channel选择器（channel-selector）" class="headerlink" title="十一、Channel选择器（channel selector）"></a>十一、Channel选择器（channel selector）</h1><p>一个source可以对接多个channel</p>
<p>那么，source的数据如何在多个channel之间传递，就由selector来控制</p>
<p>配置应该挂载到source组件上</p>
<h2 id="1-Replicating-Channel-Selector（复制选择器）"><a href="#1-Replicating-Channel-Selector（复制选择器）" class="headerlink" title="(1)Replicating Channel Selector（复制选择器）"></a>(1)Replicating Channel Selector（复制选择器）</h2><p>replicating selector就是默认的选择器</p>
<p>官网配置参考</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230128000918130.png" alt="image-20230128000918130"></p>
<h3 id="目标场景："><a href="#目标场景：" class="headerlink" title="目标场景："></a>目标场景：</h3><p>selector将event复制，分发给所有下游节点</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230128001034328.png" alt="image-20230128001034328"></p>
<h3 id="可选属性如下"><a href="#可选属性如下" class="headerlink" title="可选属性如下"></a>可选属性如下</h3><table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">selector.type</td>
<td align="left">replicating</td>
<td align="left"><code>replicating</code></td>
</tr>
<tr>
<td align="left">selector.optional</td>
<td align="left">–</td>
<td align="left"><code>optional</code></td>
</tr>
</tbody></table>
<h3 id="使用案例："><a href="#使用案例：" class="headerlink" title="使用案例："></a>使用案例：</h3><p>下面的配置中，c2是一个可选的channel，写入c2失败的话会被忽略，c1没有标记为可选，如果写入c1失败会导致事务的失败</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example10-channel-replicating.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1 c2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">exec</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1 c2</span></span><br><span class="line"><span class="attr">a1.sources.r1.command</span> = <span class="string">tail -F /export/data/flume-example-data/logdata/access.log</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.type</span> = <span class="string">replicating</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.optional</span> = <span class="string">c2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c2.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c2.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c2.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = <span class="string">hdfs://node1:8020/logdata_c1/%Y-%m-%d/%H/</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = <span class="string">logdata_</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileSuffix</span> = <span class="string">.log</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="string">268435456</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = <span class="string">DataStream</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="string">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = <span class="string">c2</span></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.path</span> = <span class="string">hdfs://node1:8020/logdata_c2/%Y-%m-%d/%H/</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.filePrefix</span> = <span class="string">logdata_</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.fileSuffix</span> = <span class="string">.log</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollInterval</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollSize</span> = <span class="string">268435456</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollCount</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.fileType</span> = <span class="string">DataStream</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.useLocalTimeStamp</span> = <span class="string">true</span></span><br></pre></td></tr></table></figure>

<h2 id="（2）Multiplexing-Channel-Selector（多路选择器）"><a href="#（2）Multiplexing-Channel-Selector（多路选择器）" class="headerlink" title="（2）Multiplexing Channel Selector（多路选择器）"></a>（2）Multiplexing Channel Selector（多路选择器）</h2><p>multiplexing selector可以根据event中的一个指定key的value来决定这条消息会写入哪个channel，具体在选择时，需要配置一个映射关系，比如</p>
<p>a1.sources.r1.selector.mapping.CZ&#x3D;c1 ; 就意味着header中的value为CZ的话，这条消息就会被写入c1这个channel</p>
<p>multiplexing selector官方配置参考</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230128003257255.png" alt="image-20230128003257255"></p>
<h3 id="目标场景"><a href="#目标场景" class="headerlink" title="目标场景"></a>目标场景</h3><p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230128003317149.png" alt="image-20230128003317149"></p>
<h3 id="多路channel选择器，可选属性如下"><a href="#多路channel选择器，可选属性如下" class="headerlink" title="多路channel选择器，可选属性如下"></a>多路channel选择器，可选属性如下</h3><table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">selector.type</td>
<td align="left">replicating</td>
<td align="left"><code>multiplexing</code></td>
</tr>
<tr>
<td align="left">selector.header</td>
<td align="left">flume.selector.header</td>
<td align="left">键值Key</td>
</tr>
<tr>
<td align="left">selector.default</td>
<td align="left">–</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">selector.mapping.*</td>
<td align="left">–</td>
<td align="left">路由</td>
</tr>
</tbody></table>
<h3 id="使用案例：-1"><a href="#使用案例：-1" class="headerlink" title="使用案例："></a>使用案例：</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example11-channel-Multiplexing.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1 c2</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1 c2</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/export/data/flume-example-data/flumedata/taildir_position.json</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">g1 g2</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g1</span> = <span class="string">/export/data/flume-example-data/weblog/web.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g2</span> = <span class="string">/export/data/flume-example-data/wxlog/wx.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g1.logtype</span> = <span class="string">web</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g2.logtype</span> = <span class="string">wx</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.selector.type</span> = <span class="string">multiplexing</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.header</span> = <span class="string">logtype</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.mapping.web</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.mapping.wx</span> = <span class="string">c2</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.default</span> = <span class="string">c2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c2.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c2.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c2.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = <span class="string">hdfs://node1:8020/%&#123;logtype&#125;/%Y-%m-%d/%H/</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = <span class="string">logdata_</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileSuffix</span> = <span class="string">.log</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="string">268435456</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = <span class="string">DataStream</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="string">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = <span class="string">c2</span></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.path</span> = <span class="string">hdfs://node1:8020/%&#123;logtype&#125;/%Y-%m-%d/%H/</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.filePrefix</span> = <span class="string">logdata_</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.fileSuffix</span> = <span class="string">.log</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollInterval</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollSize</span> = <span class="string">268435456</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollCount</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.fileType</span> = <span class="string">DataStream</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.useLocalTimeStamp</span> = <span class="string">true</span></span><br></pre></td></tr></table></figure>

<p><strong>这里通过事件的header值来判断将事件发送到哪个channel，还可以配合拦截器一起使用。</strong></p>
<h1 id="十二、Sink处理器（sink-processor）"><a href="#十二、Sink处理器（sink-processor）" class="headerlink" title="十二、Sink处理器（sink processor）"></a>十二、Sink处理器（sink processor）</h1><p>一个agent中，多个sink可以被组装到一个sink组，而数据在组内多个sink之间发送，由sink processor来决定</p>
<p>Sink processor在flume中有3种：</p>
<p>第一种： 默认的，不需要专门去配置的；相当于负载均衡，但是sink不需要创建group；</p>
<p>第二种： failover sink processor 自动失败切换，需要将多个sink创建成group</p>
<p>第三种： load_balance sink processor 负载均衡，需要将多个sink创建成group</p>
<p>可以将多个sink放入到一个组中，Sink处理器能够对一个组中所有的sink进行负载均衡，在一个sink出现临时错误时进行故障转移。</p>
<p>必须设置属性：</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>sinks</strong></td>
<td align="left">–</td>
<td align="left">组中多个sink使用空格分隔</td>
</tr>
<tr>
<td align="left"><strong>processor.type</strong></td>
<td align="left"><code>default</code></td>
<td align="left"><code>default</code>, <code>failover</code> 或<code>load_balance</code></td>
</tr>
</tbody></table>
<p>举例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinkgroups.g1.processor.type = failover</span><br></pre></td></tr></table></figure>

<h2 id="（1）Default-Sink-Processor"><a href="#（1）Default-Sink-Processor" class="headerlink" title="（1）Default Sink Processor"></a>（1）Default Sink Processor</h2><p>默认的Sink处理器只支持单个Sink</p>
<h2 id="（2）Failover-Sink-Processor"><a href="#（2）Failover-Sink-Processor" class="headerlink" title="（2）Failover Sink Processor"></a>（2）Failover Sink Processor</h2><p>一组中只有优先级高的那个sink在工作，另一个是等待中</p>
<p>如果高优先级的sink发送数据失败，则专用低优先级的sink去工作，并且，<strong>在配置时间penalty之后，还会尝试用高优先级的去发送数据。</strong></p>
<p>故障转移处理器维护了一个带有优先级的sink列表，故障转移机制将失败的sink放入到一个冷却池中，如果sink成功发送了事件，将其放入到活跃池中，sink可以设置优先级，数字越高，优先级越高，如果一个sink发送事件失败，下一个有更高优先级的sink将被用来发送事件，比如，<strong>优先级100的比优先级80的先被使用，如果没有设置优先级，按配置文件中配置的顺序决定。</strong>设置属性如下：</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>sinks</strong></td>
<td align="left">–</td>
<td align="left">组内多个sinks空格分隔</td>
</tr>
<tr>
<td align="left"><strong>processor.type</strong></td>
<td align="left"><code>default</code></td>
<td align="left"><code>failover</code></td>
</tr>
<tr>
<td align="left"><strong>processor.priority.</strong></td>
<td align="left">–</td>
<td align="left">优先级</td>
</tr>
<tr>
<td align="left">processor.maxpenalty</td>
<td align="left">30000</td>
<td align="left">失败sink的最大冷却时间</td>
</tr>
</tbody></table>
<p>示例如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinkgroups.g1.processor.type = failover</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 对两个sink分配不同的优先级</span></span></span><br><span class="line">a1.sinkgroups.g1.processor.priority.k1 = 200</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k2 = 100</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 主sink失败后，停用惩罚时间</span></span></span><br><span class="line">a1.sinkgroups.g1.processor.maxpenalty = 5000</span><br></pre></td></tr></table></figure>

<p>优先级高的sink如果失败，则processor会激活优先级第二的sink；</p>
<p>然后经过指定惩罚时间后，processor会再次尝试激活优先级高的sink；</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130103523537.png" alt="image-20230130103523537"></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130103553408.png" alt="image-20230130103553408"></p>
<h3 id="实例："><a href="#实例：" class="headerlink" title="实例："></a>实例：</h3><h4 id="（1）上游flume配置（node1）"><a href="#（1）上游flume配置（node1）" class="headerlink" title="（1）上游flume配置（node1）"></a>（1）上游flume配置（node1）</h4><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example12-1-sink-failover.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">exec</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.command</span> = <span class="string">tail -F /export/data/flume-example-data/logdata/access.log</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = <span class="string">node2</span></span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sinks.k1.batch-size</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hostname</span> = <span class="string">node3</span></span><br><span class="line"><span class="attr">a1.sinks.k2.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sinks.k2.batch-size</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinkgroups</span> = <span class="string">g1</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.type</span> = <span class="string">failover</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.priority.k1</span> = <span class="string">200</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.priority.k2</span> = <span class="string">100</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.maxpenalty</span> = <span class="string">5000</span></span><br></pre></td></tr></table></figure>

<h4 id="（2）下游flume配置（node2-node3）"><a href="#（2）下游flume配置（node2-node3）" class="headerlink" title="（2）下游flume配置（node2 node3）"></a>（2）下游flume配置（node2 node3）</h4><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example12-2-sink-failover.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.threads</span> = <span class="string">10</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>



<h2 id="（3）Load-balancing-Sink-Processor"><a href="#（3）Load-balancing-Sink-Processor" class="headerlink" title="（3）Load balancing Sink Processor"></a>（3）Load balancing Sink Processor</h2><p>允许channel中的数据在一组sink中的多个sink之间进行交替，交替策略有：</p>
<p><strong>round_robin</strong>（轮询算法）</p>
<p><strong>random</strong>（随机）</p>
<p>负载均衡处理器，可以通过轮询或者随机的方式进行负载均衡，也可以通过继承AbstractSinkSelector 自定义负载均衡，设置属性如下：</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>processor.sinks</strong></td>
<td align="left">–</td>
<td align="left">组内多个sinks空格分隔</td>
</tr>
<tr>
<td align="left"><strong>processor.type</strong></td>
<td align="left"><code>default</code></td>
<td align="left"><code>load_balance</code></td>
</tr>
<tr>
<td align="left">processor.backoff</td>
<td align="left">false</td>
<td align="left">是否将失败的sink加入黑名单</td>
</tr>
<tr>
<td align="left">processor.selector</td>
<td align="left"><code>round_robin</code></td>
<td align="left">轮询机制:<code>round_robin</code>, <code>random</code> 或者自定义</td>
</tr>
<tr>
<td align="left">processor.selector.maxTimeOut</td>
<td align="left">30000</td>
<td align="left">黑名单有效时间（单位毫秒）</td>
</tr>
</tbody></table>
<p>示例如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinkgroups.g1.processor.type = load_balance</span><br><span class="line">a1.sinkgroups.g1.processor.backoff = true</span><br><span class="line">a1.sinkgroups.g1.processor.selector = round_robin</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130111311611.png" alt="image-20230130111311611"></p>
<h3 id="实例：-1"><a href="#实例：-1" class="headerlink" title="实例："></a>实例：</h3><h4 id="（1）上游flume配置（node1）-1"><a href="#（1）上游flume配置（node1）-1" class="headerlink" title="（1）上游flume配置（node1）"></a>（1）上游flume配置（node1）</h4><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example13-1-sink-loadbalance.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">exec</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.command</span> = <span class="string">tail -F /export/data/flume-example-data/logdata/access.log</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = <span class="string">node2</span></span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sinks.k1.batch-size</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hostname</span> = <span class="string">node3</span></span><br><span class="line"><span class="attr">a1.sinks.k2.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sinks.k2.batch-size</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinkgroups</span> = <span class="string">g1</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.type</span> = <span class="string">load_balance</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.backoff</span> = <span class="string">true </span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.selector</span> = <span class="string">round_robin</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="（2）下游flume配置（node2-node3）-1"><a href="#（2）下游flume配置（node2-node3）-1" class="headerlink" title="（2）下游flume配置（node2 node3）"></a>（2）下游flume配置（node2 node3）</h4><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example13-2-sink-loadbalance.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.threads</span> = <span class="string">10</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>



<h1 id="十三、flume进阶"><a href="#十三、flume进阶" class="headerlink" title="十三、flume进阶"></a>十三、flume进阶</h1><h2 id="（1）flume-事务机制"><a href="#（1）flume-事务机制" class="headerlink" title="（1）flume 事务机制"></a>（1）flume 事务机制</h2><p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130164206781.png" alt="image-20230130164206781"></p>
<p>二、Delivery 保证</p>
<p>认识 Flume 对事件投递的可靠性保证是非常重要的，它往往是我们是否使用 Flume 来解决问题的决定因素之一。</p>
<p>消息投递的可靠保证有三种：</p>
<ul>
<li>At-least-once</li>
<li>At-most-once</li>
<li>Exactly-once</li>
</ul>
<p>基本上所有工具的使用用户都希望工具框架能保证消息 Exactly-once ，这样就不必在设计实现上考虑消息的丢失或者重复的处理场景。但是事实上很少有工具和框架能做到这一点，真正能做到这一点所付出的成本往往很大，或者带来的额外影响反而让你觉得不值得。假设 Flume 真的做到了 Exactly-once ，那势必降低了稳定性和吞吐量，所以 Flume 选择的策略是 At-least-once 。</p>
<p>当然这里的 At-least-once 需要加上引号，并不是说用上 Flume 的随便哪个组件组成一个实例，运行过程中就能保存消息不会丢失。事实上 At-least-once 原则只是说的是 Source 、 Channel 和 Sink 三者之间上下投递消息的保证。而当你选择 MemoryChannel 时，实例如果异常挂了再重启，在 channel 中的未被 sink 所消费的残留数据也就丢失了，从而没办法保证整条链路的 At-least-once。</p>
<p>Flume 的 At-least-once 保证的实现基础是建立了自身的 Transaction 机制。</p>
<p>Flume 的 Transaction 有4个生命周期函数，分别是 start、 commit、rollback 和 close。</p>
<p>当 Source 往 Channel 批量投递事件时首先调用 start 开启事务,批量</p>
<p>put 完事件后通过 commit 来提交事务，如果 commit 异常则 rollback ，然后 close 事务，最后 Source 将刚才提交的一批消息事件向源服务 ack（比如 kafka 提交新的 offset ）。Sink 消费 Channel 也是相同的模式，唯一的区别就是 Sink 需要在向目标源完成写入之后才对事务进行 commit。</p>
<p>两个组件的相同做法都是只有向下游成功投递了消息才会向上游 ack，从而保证了数据能 At-least-once 向下投递。</p>
<h2 id="（2）flume-agent-内部机制"><a href="#（2）flume-agent-内部机制" class="headerlink" title="（2）flume agent 内部机制"></a>（2）flume agent 内部机制</h2><p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130164421179.png" alt="image-20230130164421179"></p>
<p>组件：</p>
<p>1、ChannelSelector</p>
<p>ChannelSelector 的作用就是选出 Event 将要被发往哪个 Channel。其共有两种类型，分别是 Replicating（复制）和 Multiplexing（多路复用）。 ReplicatingSelector 会将同一个 Event 发往所有的 Channel，Multiplexing 会根据相应的原则，将不同的 Event 发往不同的 Channel。</p>
<p>2、SinkProcessor</p>
<p>(1) SinkProcessor 共 有 三 种 类 型 ， 分 别 是 DefaultSinkProcessor 、    LoadBalancingSinkProcessor 和 FailoverSinkProcessor。</p>
<p>(2) DefaultSinkProcessor 对应的是单个的 Sink，<br>LoadBalancingSinkProcessor 和 FailoverSinkProcessor 对应的是 Sink Group。</p>
<p>(3) LoadBalancingSinkProcessor 可以实现负载均衡的功能，FailoverSinkProcessor 可以实现故障转移的功能。</p>
<h2 id="（3）flume监控及ganglia监控"><a href="#（3）flume监控及ganglia监控" class="headerlink" title="（3）flume监控及ganglia监控"></a>（3）flume监控及ganglia监控</h2><h3 id="1）flume监控"><a href="#1）flume监控" class="headerlink" title="1）flume监控"></a>1）flume监控</h3><p>FLUME在运行时，状态是否正常，吞吐量是否正常，需要监控</p>
<p>Flume自身具有向外提交状态数据的功能；<strong>但是它本身没有一个完善的监控平台；</strong></p>
<p>开启内置监控功能，<strong>启动时加入参数：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Dflume.monitoring.type=http -Dflume.monitoring.port=34545</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230131134112881.png" alt="image-20230131134112881"></p>
<h3 id="2）ganglia监控"><a href="#2）ganglia监控" class="headerlink" title="2）ganglia监控"></a>2）ganglia监控</h3><p>将监控数据发往<strong>ganglia</strong>进行展现</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Dflume.monitoring.type=ganglia -Dflume.monitoring.port=34890</span><br></pre></td></tr></table></figure>

<p>Ganglia是一个通用的集群运维监控系统；</p>
<p>它在各台需要监控状态信息的机器上安装“探针”，然后这些“探针”会收集所在机器上的各种状态信息<strong>（cpu负载，内存负载，磁盘IO负载，网络IO负载，以及各类应用软件的状态信息）</strong>，然后汇聚到它的中心汇聚点，并提供<strong>web页面进行图形可视化查看</strong></p>
<p><em><strong>各种应用软件的态，是不会被ganglia的“探针”获取到的；而是由应用软件自身开发相应功能，将自身需要被监控的状态数据，提交给ganglia；</strong></em></p>
<p>Ganglia是UC Berkeley发起的一个开源集群监视项目，设计用于测量数以千计的节点。Ganglia的核心包含<strong>gmond（监控守护进程）</strong>、<strong>gmetad（元数据守护进程）</strong>以及一个<strong>Web前端</strong>。主要是用来监控系统性能，如：cpu 、mem、硬盘利用率， I&#x2F;O负载、网络流量情况等，通过曲线很容易见到每个节点的工作状态，对合理调整、分配系统资源，提高系统整体性能起到重要作用。</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130171701412.png" alt="image-20230130171701412"></p>
<h3 id="3）Ganglia安装"><a href="#3）Ganglia安装" class="headerlink" title="3）Ganglia安装"></a>3）Ganglia安装</h3><p><strong>中心节点的安装</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- epel包的安装：yum install -y epel-release(解决不能yum安装某些安装包的问题)</span><br><span class="line">- gmetad的安装：yum install -y ganglia-gmetad</span><br><span class="line">- gmond的安装：yum install -y ganglia-gmond</span><br><span class="line">- rrdtool的安装：yum install -y rrdtool</span><br><span class="line">- httpd服务器的安装：yum install -y httpd</span><br><span class="line">- ganglia-web及php安装：yum install -y ganglia-web php</span><br></pre></td></tr></table></figure>

<p><strong>被监测节点的安装</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- epel包的安装：yum install -y epel-release(解决不能yum安装某些安装包的问题)</span><br><span class="line">- gmond的安装：yum install -y gmond(提示找不到，感觉应该换成上面那个yum install -y ganglia-gmond)</span><br></pre></td></tr></table></figure>

<h3 id="4）Ganglia配置"><a href="#4）Ganglia配置" class="headerlink" title="4）Ganglia配置"></a>4）Ganglia配置</h3><p><strong>中心节点的配置</strong><br>安装目录说明</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- ganglia配置文件目录：/etc/ganglia</span><br><span class="line">- rrd数据库存放目录：/var/lib/ganglia/rrds</span><br><span class="line">- ganglia-web安装目录：/usr/share/ganglia</span><br><span class="line">- ganglia-web配置目录：/etc/httpd/conf.d/ganglia.conf</span><br></pre></td></tr></table></figure>

<p>相关配置文件修改<br>将ganglia-web的站点目录连接到httpd主站点目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> <span class="built_in">ln</span> -s /usr/share/ganglia /var/www/html</span></span><br></pre></td></tr></table></figure>

<p>修改httpd主站点目录下ganglia站点目录的访问权限<br>将ganglia站点目录访问权限改为apache:apache，否则会报错</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> <span class="built_in">chown</span> -R apache:apache /var/www/html/ganglia</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> <span class="built_in">chmod</span> -R 755 /var/www/html/ganglia</span></span><br></pre></td></tr></table></figure>

<p>修改rrd数据库存放目录访问权限<br>将rrd数据库存放目录访问权限改为nobody:nobody,否则会报错</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> <span class="built_in">chown</span> -R nobody:nobody /var/lib/ganglia/rrds</span></span><br></pre></td></tr></table></figure>

<p>修改ganglia-web的访问权限：<br>修改&#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;ganglia.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Alias /ganglia /usr/share/ganglia</span><br><span class="line">&lt;Location /ganglia&gt; </span><br><span class="line"> Require all granted</span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash">Require ip 10.1.2.3</span></span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash">Require host example.org</span></span><br><span class="line">&lt;/Location&gt;</span><br></pre></td></tr></table></figure>

<p>修改dwoo下面的权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 /var/lib/ganglia/dwoo/compiled</span><br><span class="line">chmod 777 /var/lib/ganglia/dwoo/cache</span><br></pre></td></tr></table></figure>

<p>配置&#x2F;etc&#x2F;ganglia&#x2F;gmetad.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_source  &quot;my cluster&quot; 192.168.88.161:8649(注意是所有节点都加上，如master:8649 slave0x:8649)</span><br><span class="line"> </span><br><span class="line">setuid_username nobody</span><br></pre></td></tr></table></figure>

<p>配置&#x2F;etc&#x2F;ganglia&#x2F;gmond.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cluster &#123; </span><br><span class="line">  name = &quot;node1&quot;</span><br><span class="line">  ... </span><br><span class="line">&#125; </span><br><span class="line">udp_send_channel &#123; </span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">the host <span class="built_in">who</span> gather this cluster<span class="string">&#x27;s monitoring data and send these data   to gmetad node</span></span></span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash"><span class="string">注释掉多播模式的,以下出现这个都要注释掉</span></span></span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash"><span class="string">mcast_join = 239.2.11.71</span></span></span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash"><span class="string">添加单播模式的</span></span></span><br><span class="line"> host = 192.168.88.161</span><br><span class="line"> port = 8649 </span><br><span class="line">&#125; </span><br><span class="line">udp_recv_channel &#123; </span><br><span class="line">  bind = 192.168.88.161</span><br><span class="line">  port = 8649 </span><br><span class="line">&#125; </span><br><span class="line">tcp_accept_channel &#123; </span><br><span class="line">  port = 8649 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>被监测节点的配置</strong><br>配置&#x2F;etc&#x2F;ganglia&#x2F;gmond.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cluster &#123; </span><br><span class="line">  name = &quot;hadoop cluster&quot;</span><br><span class="line">  ... </span><br><span class="line">&#125; </span><br><span class="line">udp_send_channel &#123; </span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">the host <span class="built_in">who</span> gather this cluster<span class="string">&#x27;s monitoring data and send these data   to gmetad node</span></span></span><br><span class="line"> host = 192.168.88.161  </span><br><span class="line"> port = 8649 </span><br><span class="line">&#125; </span><br><span class="line">udp_recv_channel &#123; </span><br><span class="line">  port = 8649 </span><br><span class="line">&#125; </span><br><span class="line">tcp_accept_channel &#123; </span><br><span class="line">  port = 8649 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5）Ganglia启动"><a href="#5）Ganglia启动" class="headerlink" title="5）Ganglia启动"></a>5）Ganglia启动</h3><p><strong>中心节点的启动</strong><br>start httpd, gmetad, gmond</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start httpd.service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start gmetad.service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start gmond.service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl <span class="built_in">enable</span> httpd.service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl <span class="built_in">enable</span> gmetad.service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl <span class="built_in">enable</span> gmond.service</span></span><br></pre></td></tr></table></figure>

<p><strong>被监测节点的启动</strong><br>start gmond</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start gmond.service</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl <span class="built_in">enable</span> gmond.service</span></span><br></pre></td></tr></table></figure>

<p><strong>关闭selinux</strong></p>
<p>vi &#x2F;etc&#x2F;selinux&#x2F;config，把SELINUX&#x3D;enforcing改成SELINUX&#x3D;disable；该方法需要重启机器。<br>可以使用命令setenforce 0来关闭selinux而不需要重启，刷新页面，即可访问；不过此法只是权宜之计，如果想永久修改selinux设置，还是要使用第一种方法</p>
<p><strong>开启防火墙</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone=public --add-port=80/tcp --permanent</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure>

<p><strong>访问网页</strong><br>浏览器访问 {namenode的ip}&#x2F;ganglia即可 </p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200326103901392.png" alt="image-20200326103901392"></p>
<h3 id="6）添加Flume监控"><a href="#6）添加Flume监控" class="headerlink" title="6）添加Flume监控"></a>6）添加Flume监控</h3><p>修改flume-env.sh配置，添加虚拟机选项</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dflume.monitoring.type=ganglia -Dflume.monitoring.hosts=192.168.88.161:8649 -Xms100m -Xmx200m&quot;</span><br></pre></td></tr></table></figure>

<p>启动flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c conf -f example.conf -Dflume.monitoring.type=ganglia -Dflume.monitoring.hosts=192.168.88.161:8649</span><br></pre></td></tr></table></figure>

<p>查看ganglia页面</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200326111609055.png" alt="image-20200326111609055"></p>
<table>
<thead>
<tr>
<th>字段（图表名称）</th>
<th>字段含义</th>
</tr>
</thead>
<tbody><tr>
<td>EventPutAttemptCount</td>
<td>source尝试写入channel的事件总数量</td>
</tr>
<tr>
<td>EventPutSuccessCount</td>
<td>成功写入channel且提交的事件总数量</td>
</tr>
<tr>
<td>EventTakeAttemptCount</td>
<td>sink尝试从channel拉取事件的总数量。这不意味着每次事件都被返回，因为sink拉取的时候channel可能没有任何数据。</td>
</tr>
<tr>
<td>EventTakeSuccessCount</td>
<td>sink成功读取的事件的总数量</td>
</tr>
<tr>
<td>StartTime</td>
<td>channel启动的时间（毫秒）</td>
</tr>
<tr>
<td>StopTime</td>
<td>channel停止的时间（毫秒）</td>
</tr>
<tr>
<td>ChannelSize</td>
<td>目前channel中事件的总数量</td>
</tr>
<tr>
<td>ChannelFillPercentage</td>
<td>channel占用百分比</td>
</tr>
<tr>
<td>ChannelCapacity</td>
<td>channel的容量</td>
</tr>
</tbody></table>
<h2 id="（4）flume调优"><a href="#（4）flume调优" class="headerlink" title="（4）flume调优"></a>（4）flume调优</h2><p>flume-ng agent包括source、channel、sink三个部分，这三部分都运行在JVM上，而JVM运行在linux操作系统之上。因此，对于flume的性能调优，就是对这三部分及影响因素调优。</p>
<h3 id="1）source的配置"><a href="#1）source的配置" class="headerlink" title="1）source的配置"></a>1）source的配置</h3><p>项目中采用的是 taildir source，他的读取速度能够跟上命令行写入日志的速度，故并未做特殊的处理。</p>
<h3 id="2）channel的配置"><a href="#2）channel的配置" class="headerlink" title="2）channel的配置"></a>2）channel的配置</h3><p>可选的channel配置一般有两种，一是memory channel，二是file channel。</p>
<p>建议在内存足够的情况下，优先选择memory channel。</p>
<p>尝试过相同配置下使用file channel和memory channel，file channel明显速度较慢，并且会生成log的文件，应该是用作缓存，当source已经接收但是还未写入sink时的event都会存在这个文件中。这样的好处是保证数据不会丢失，所以当对数据的丢失情况非常敏感且对实时性没有太大要求的时候，还是使用file memory吧。</p>
<p>一开始的memory channel配置用的是默认的，然后控制台报出了如下警告：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARN：The channel is full or unexpected failure. The <span class="built_in">source</span> will try again after 1000 ms</span><br></pre></td></tr></table></figure>

<p>这个是因为当前被采集的文件过大，可以通过增大keep-alive的值解决。深层的原因是文件采集的速度和sink的速度没有匹配好。</p>
<p>所以memory channel有三个比较重要的参数需要配置：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#channel中最多缓存多少</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">5000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#channel一次最多吐给sink多少</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">2000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#event的活跃时间</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.keep-alive</span> = <span class="string">10</span></span><br></pre></td></tr></table></figure>

<h3 id="3）sink的配置"><a href="#3）sink的配置" class="headerlink" title="3）sink的配置"></a>3）sink的配置</h3><p>可以通过压缩来节省空间和网络流量，但是会增加cpu的消耗。</p>
<p>batch：size越大性能越好，但是太大会影响时效性，一般batch size和源数据端的大小相同。</p>
<h3 id="4）java内存的配置"><a href="#4）java内存的配置" class="headerlink" title="4）java内存的配置"></a>4）java内存的配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_OPTS=<span class="string">&quot;-Xms512m -Xmx2048m&quot;</span></span><br></pre></td></tr></table></figure>

<p>主要涉及Xms和Xmx两个参数，可以根据实际的服务器的内存大小进行设计。</p>
<h3 id="5）OS内核参数的配置"><a href="#5）OS内核参数的配置" class="headerlink" title="5）OS内核参数的配置"></a>5）OS内核参数的配置</h3><p>如果单台服务器启动的flume agent过多的话，默认的内核参数设置偏小，需要调整。（待补充，暂时还未涉及）。</p>
<h3 id="6）调优实战案例"><a href="#6）调优实战案例" class="headerlink" title="6）调优实战案例"></a>6）调优实战案例</h3><p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130172232611.png" alt="image-20230130172232611"></p>
<h4 id="agent层的调试数据"><a href="#agent层的调试数据" class="headerlink" title="agent层的调试数据"></a><strong>agent</strong>层的调试数据</h4><table>
<thead>
<tr>
<th align="center">优化方法</th>
<th align="center">java环境</th>
<th align="center">channel类型</th>
<th align="center">sink类型与个数</th>
<th align="center">压缩</th>
<th align="center">source接收到条数&amp;速度</th>
<th align="center">channel已写入 &amp;channel占用率</th>
<th align="center">sink输出量</th>
<th align="center">sink输出速度</th>
<th align="center">cpu占用</th>
<th align="center">内存占用</th>
<th align="center">总结</th>
</tr>
</thead>
<tbody><tr>
<td align="center">无</td>
<td align="center">默认</td>
<td align="center">file 100w</td>
<td align="center">负载均衡 2个avro  sink</td>
<td align="center">否</td>
<td align="center">2472192 1373&#x2F;s</td>
<td align="center">2473728 0.02%</td>
<td align="center">2360100</td>
<td align="center">1311&#x2F;s</td>
<td align="center">约35%</td>
<td align="center">8.6G</td>
<td align="center">传输效率很低</td>
</tr>
<tr>
<td align="center">优化java配置,启用2G内存</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 100w</td>
<td align="center">负载均衡 2个avro  sink</td>
<td align="center">否</td>
<td align="center">6226688 3459&#x2F;s</td>
<td align="center">6227712 99.90%</td>
<td align="center">5228000</td>
<td align="center">2904&#x2F;s</td>
<td align="center">约30%</td>
<td align="center">8.6G</td>
<td align="center">传输效率有较大提升</td>
</tr>
<tr>
<td align="center">avro压缩传输</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 100w</td>
<td align="center">负载均衡 2个avro  sink</td>
<td align="center">是</td>
<td align="center">5076224 2820&#x2F;s</td>
<td align="center">5077504 99.90%</td>
<td align="center">4077800</td>
<td align="center">2265&#x2F;s</td>
<td align="center">约47%</td>
<td align="center">10.4G</td>
<td align="center">传输效率不升反降</td>
</tr>
<tr>
<td align="center">采用memory channel</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">memory 100w</td>
<td align="center">负载均衡 2个avro  sink</td>
<td align="center">是</td>
<td align="center">6767104 3759&#x2F;s</td>
<td align="center">6771968 99.90%</td>
<td align="center">5772200</td>
<td align="center">3207&#x2F;s</td>
<td align="center">100%-200%</td>
<td align="center">10.4G</td>
<td align="center">传输效率有少量提升，但是cpu压力很大</td>
</tr>
<tr>
<td align="center">数据不传输到L2，直接sink到本地</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 100w</td>
<td align="center">负载均衡 2个file  sink</td>
<td align="center">否</td>
<td align="center">5761280 3201&#x2F;s</td>
<td align="center">5762816 0.00%</td>
<td align="center">5761662</td>
<td align="center">3201&#x2F;s</td>
<td align="center">10%-50%</td>
<td align="center">10.4G</td>
<td align="center">channel无堆积，但是传输量无明显提升</td>
</tr>
<tr>
<td align="center">将数据传给8个Sink组成的L2</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 100w</td>
<td align="center">负载均衡 8个avro  sink</td>
<td align="center">否</td>
<td align="center">1423616 791&#x2F;s</td>
<td align="center">1393664 99.90%</td>
<td align="center">393700</td>
<td align="center">218&#x2F;s</td>
<td align="center">5%</td>
<td align="center">10.4G</td>
<td align="center">传输效率极低</td>
</tr>
<tr>
<td align="center">优化avro-avro传输，avro sink配置maxIoWorkers128，L2的avro source threads设为1000</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 100w</td>
<td align="center">负载均衡 2个file  sink</td>
<td align="center">否</td>
<td align="center">2971392 1651&#x2F;s</td>
<td align="center">2972416 99.90%</td>
<td align="center">1972500</td>
<td align="center">1095&#x2F;s</td>
<td align="center">5%-20%</td>
<td align="center">10.4G</td>
<td align="center">传输效率不升反降</td>
</tr>
<tr>
<td align="center">将L2数据sink到本地</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 100w</td>
<td align="center">负载均衡 2个avro  sink</td>
<td align="center">否</td>
<td align="center">6279168 3488&#x2F;s</td>
<td align="center">6280448 99.90%</td>
<td align="center">5280500</td>
<td align="center">2934&#x2F;s</td>
<td align="center">约30%</td>
<td align="center">10.4G</td>
<td align="center">传输效率无明显提升</td>
</tr>
<tr>
<td align="center">增大java内存 增大avro sink batchsize 启用压缩 启用memorychannel</td>
<td align="center">Xms8g Xmx8g Xss256k Xmn3g</td>
<td align="center">memory 100w</td>
<td align="center">负载均衡 2个avro  sink</td>
<td align="center">是</td>
<td align="center">5640704 3134&#x2F;s</td>
<td align="center">5643776 99.90%</td>
<td align="center">4644000</td>
<td align="center">2580&#x2F;s</td>
<td align="center">30%</td>
<td align="center">16.5G</td>
<td align="center">传输效率无明显提升</td>
</tr>
<tr>
<td align="center">增加jvm内存到8G，filechannel设为1000w容量</td>
<td align="center">Xms8g Xmx8g Xss256k Xmn3g</td>
<td align="center">file 1000w</td>
<td align="center">负载均衡 2个file  sink</td>
<td align="center">否</td>
<td align="center">7330816 4073&#x2F;s</td>
<td align="center">7332096 48%</td>
<td align="center">2519000</td>
<td align="center">1399&#x2F;s</td>
<td align="center">2%-16%</td>
<td align="center">16.5G</td>
<td align="center">传输效率不升反降</td>
</tr>
<tr>
<td align="center">在上一种方法的基础上增加avro batchsize为2000</td>
<td align="center">Xms8g Xmx8g Xss256k Xmn3g</td>
<td align="center">file 2000w</td>
<td align="center">负载均衡 2个avro  sink</td>
<td align="center">否</td>
<td align="center">8168960 4538&#x2F;s</td>
<td align="center">8170496 69%</td>
<td align="center">1270000</td>
<td align="center">706&#x2F;s</td>
<td align="center">10%-20%</td>
<td align="center">16.5G</td>
<td align="center">传输效率极低</td>
</tr>
<tr>
<td align="center">4个sink无组策略</td>
<td align="center">Xms8g Xmx8g Xss256k Xmn3g</td>
<td align="center">file 2000w</td>
<td align="center">无组策略 4个avro  sink</td>
<td align="center">否</td>
<td align="center">7222272 4012&#x2F;s</td>
<td align="center">7223808 0.02%</td>
<td align="center">7222272</td>
<td align="center">4012&#x2F;s</td>
<td align="center">30%-50%</td>
<td align="center">16.6G</td>
<td align="center">取消负载均衡，效率有较大提升666</td>
</tr>
<tr>
<td align="center">8个sink无组策略</td>
<td align="center">Xms8g Xmx8g Xss256k Xmn3g</td>
<td align="center">file 2000w</td>
<td align="center">无组策略 8个avro  sink</td>
<td align="center">否</td>
<td align="center">7034624 3908&#x2F;s</td>
<td align="center">7035648 0.03614%</td>
<td align="center">7032034</td>
<td align="center">3906&#x2F;s</td>
<td align="center">30%-50%</td>
<td align="center">16.6G</td>
<td align="center">无组策略的情况下，8个sink和4个sink效率无差</td>
</tr>
<tr>
<td align="center">4个sink无组策略  memrorychannel</td>
<td align="center">Xms8g Xmx8g Xss256k Xmn3g</td>
<td align="center">memory 100w</td>
<td align="center">无组策略 4个avro  sink</td>
<td align="center">否</td>
<td align="center">17435648 9686&#x2F;s</td>
<td align="center">17441536 47.56%</td>
<td align="center">12678000</td>
<td align="center">7043&#x2F;s</td>
<td align="center">100%-500%</td>
<td align="center">16.6G</td>
<td align="center">cpu压力很大</td>
</tr>
<tr>
<td align="center">2个sink无组策略  memrorychannel L2的内存channel扩大到1亿</td>
<td align="center">Xms8g Xmx8g Xss256k Xmn3g</td>
<td align="center">memory 100w</td>
<td align="center">无组策略 4个avro  sink</td>
<td align="center">否</td>
<td align="center">18679438 10337&#x2F;s</td>
<td align="center">18684778 0.00256%</td>
<td align="center">18683444</td>
<td align="center">10448&#x2F;s</td>
<td align="center">10%-20%</td>
<td align="center">16.6G</td>
<td align="center">此为目前传输最快的方案</td>
</tr>
<tr>
<td align="center">8个sink无组策略，2G内存</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 2000w</td>
<td align="center">无组策略 8个avro  sink</td>
<td align="center">否</td>
<td align="center">7067392 3926&#x2F;s</td>
<td align="center">7068416 0.00256%</td>
<td align="center">7067212</td>
<td align="center">3926&#x2F;s</td>
<td align="center">30%-40%</td>
<td align="center">10.8G</td>
<td align="center">jvm2G内存已经够用</td>
</tr>
<tr>
<td align="center">8个sink无组策略，2G内存,压缩</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 2000w</td>
<td align="center">无组策略 8个avro  sink</td>
<td align="center">是</td>
<td align="center">7362048 4090&#x2F;s</td>
<td align="center">7363072 0.0055%</td>
<td align="center">7361995</td>
<td align="center">4090&#x2F;s</td>
<td align="center">50%-100%</td>
<td align="center">10.6G</td>
<td align="center">L1到L2压缩对传输速度无太大提升，增大了CPU负担</td>
</tr>
<tr>
<td align="center">4个sink无组策略，2G内存,压缩</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 2000w</td>
<td align="center">无组策略 4个avro  sink</td>
<td align="center">是</td>
<td align="center">7501056 4167&#x2F;s</td>
<td align="center">7502592 0.01664</td>
<td align="center">8036352</td>
<td align="center">4464&#x2F;s</td>
<td align="center">40%-50%</td>
<td align="center">10.5G</td>
<td align="center">从channel获取的数量大于channel写入的数量，说明此时的瓶颈在channel写入</td>
</tr>
<tr>
<td align="center">4个sink无组策略，2G内存,不压缩</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 2000w</td>
<td align="center">无组策略 4个avro  sink</td>
<td align="center">否</td>
<td align="center">7745792 4303&#x2F;s</td>
<td align="center">7747328 0.02688</td>
<td align="center">7741952</td>
<td align="center">4301&#x2F;s</td>
<td align="center">50%-100%</td>
<td align="center">10.5G</td>
<td align="center">L1到L2压缩对传输速度无太大提升，增大了CPU负担</td>
</tr>
<tr>
<td align="center">8个sink无组策略，发送到4个L2，每个L2有两个source，两个channel</td>
<td align="center">Xms2g Xmx2g Xss256k Xmn1g</td>
<td align="center">file 2000w</td>
<td align="center">无组策略 8个avro  sink</td>
<td align="center">否</td>
<td align="center">6734336 3741&#x2F;s</td>
<td align="center">6735360 0.00177</td>
<td align="center">6735006</td>
<td align="center">3742&#x2F;s</td>
<td align="center">30%-50%</td>
<td align="center">10.8G</td>
<td align="center">发给同一机器的两个avro source无性能提升</td>
</tr>
</tbody></table>
<h4 id="collector层的调试数据"><a href="#collector层的调试数据" class="headerlink" title="collector层的调试数据"></a>collector层的调试数据</h4><table>
<thead>
<tr>
<th align="center">优化方法</th>
<th align="center">java环境</th>
<th align="center">channel类型</th>
<th align="center">sink类型与个数</th>
<th>压缩</th>
<th align="center">source接收到条数&amp;速度</th>
<th align="center">channel已写入 &amp;channel占用率</th>
<th align="center">sink输出量</th>
<th align="center">sink输出速度</th>
<th align="center">cpu占用</th>
<th align="center">内存占用</th>
<th align="center">总结</th>
</tr>
</thead>
<tbody><tr>
<td align="center">正常传输</td>
<td align="center">Xms20g Xmx20g Xss256k Xmn8g</td>
<td align="center">file 100w</td>
<td align="center">无组策略 1个kafka  sink</td>
<td>否</td>
<td align="center">3099048 1722&#x2F;s</td>
<td align="center">3095238 99.90%</td>
<td align="center">2144761</td>
<td align="center">1192&#x2F;s</td>
<td align="center">2%-5%</td>
<td align="center">25.6G</td>
<td align="center">输出速度  不够</td>
</tr>
<tr>
<td align="center">增加到4个sink，filechannel容量扩大</td>
<td align="center">Xms20g Xmx20g Xss256k Xmn8g</td>
<td align="center">file 1亿</td>
<td align="center">无组策略 4个kafka  sink</td>
<td>否</td>
<td align="center">18850000 10472&#x2F;s</td>
<td align="center">18850000 9.86%</td>
<td align="center">8970971</td>
<td align="center">4984&#x2F;s</td>
<td align="center">50%-100%</td>
<td align="center">25.6G</td>
<td align="center">速度提升  约4倍</td>
</tr>
<tr>
<td align="center">使用memory channel</td>
<td align="center">Xms20g Xmx20g Xss256k Xmn8g</td>
<td align="center">memory 1000w</td>
<td align="center">无组策略 4个kafka  sink</td>
<td>否</td>
<td align="center">17794000 9886&#x2F;s</td>
<td align="center">17744000 99.95%</td>
<td align="center">7745000</td>
<td align="center">4303&#x2F;s</td>
<td align="center">100%-800%</td>
<td align="center">25.6G</td>
<td align="center">相比使用file channel无性能提升</td>
</tr>
<tr>
<td align="center">增加到8个sink</td>
<td align="center">Xms20g Xmx20g Xss256k Xmn8g</td>
<td align="center">file 1亿</td>
<td align="center">无组策略 8个kafka  sink</td>
<td>否</td>
<td align="center">19251655 10695&#x2F;s</td>
<td align="center">19249668 2%</td>
<td align="center">17148675</td>
<td align="center">9527&#x2F;s</td>
<td align="center">100%-150%</td>
<td align="center">26.8G</td>
<td align="center">8个sink传输比1个速度提升约8倍</td>
</tr>
</tbody></table>
<h5 id="agent到collector启用zlib压缩前后的网络带宽情况"><a href="#agent到collector启用zlib压缩前后的网络带宽情况" class="headerlink" title="agent到collector启用zlib压缩前后的网络带宽情况"></a>agent到collector启用zlib压缩前后的网络带宽情况</h5><p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130173816550.png" alt="image-20230130173816550"></p>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a><strong>总结：</strong></h4><p>1、默认jvm环境只使用了20m内存，需要调整，扩大到2G基本够用，不需要过大； </p>
<p>2、collector到kafka，启用的sink越多，传输越快； </p>
<p>3、如果collector到kafka通路受阻，使数据堆积在channel中，如果channel堆满，则会影响agent到collector的传输； </p>
<p>4、agent到collector如果配置了组策略（sink group），则一个组策略只启动一个传输线程，多个sink成一组则传输效率远不如sink各传各的，一个sink相当于一个传输线程； </p>
<p>5、通路不受阻的情况下，memoryChannel传输效率比fileChannel高很多，不过对cpu、内存的要求会很高； </p>
<p>6、avro压缩传输对传输效率没有太大提升，反而增大cpu负担,但是会大大降低网络带宽； </p>
<p>7、在网络带宽受限的情况下，增加sink、改用memory channel等方法都不能增加传输效率； </p>
<p>8、影响flume传输性能的<strong>主要因素有，jvm内存、网络带宽、channel类型、sink个数、是否压缩、机器硬件性能</strong>，各条件需要做一个综合的性能平衡，某一个环节出现瓶颈就会影响整个系统的传输性能。</p>
<h1 id="十四、使用Flume导入数据到HDFS"><a href="#十四、使用Flume导入数据到HDFS" class="headerlink" title="十四、使用Flume导入数据到HDFS"></a>十四、使用Flume导入数据到HDFS</h1><p>数据导出到HDFS需要使用HDFS Sink，需要配置属性如下：</p>
<table>
<thead>
<tr>
<th align="left">属性名</th>
<th align="left">默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>channel</strong></td>
<td align="left">–</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><strong>type</strong></td>
<td align="left">–</td>
<td align="left"><code>hdfs</code></td>
</tr>
<tr>
<td align="left"><strong>hdfs.path</strong></td>
<td align="left">–</td>
<td align="left">HDFS 文件路径 (例如 hdfs:&#x2F;&#x2F;namenode&#x2F;flume&#x2F;webdata&#x2F;)</td>
</tr>
<tr>
<td align="left">hdfs.fileType</td>
<td align="left">SequenceFile</td>
<td align="left">文件格式:  <code>SequenceFile</code>, <code>DataStream</code> or <code>CompressedStream</code> (1)DataStream 不会压缩输出文件且不用设置 codeC (2)CompressedStream 需要设置 hdfs.codeC</td>
</tr>
<tr>
<td align="left">hdfs.codeC</td>
<td align="left"></td>
<td align="left">压缩格式 : gzip, bzip2, lzo, lzop, snappy</td>
</tr>
</tbody></table>
<p>注：使用HDFS Sink需要用到Hadoop的多个包，可以在装有Hadoop的主机上运行Flume，如果是单独部署的Flume，可以通过多个Agent的形式将单独部署的Flume Agent 日志数据发送到装有Hadoop的Flume Agent上。</p>
<p>创建hdfs.conf </p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义agent名称为a1</span></span><br><span class="line"><span class="comment"># 设置3个组件的名称</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置source类型为NetCat,监听地址为本机，端口为44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">netcat</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">localhost</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置sink类型为hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = <span class="string">hdfs://node01:9000/user/flume/logs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = <span class="string">DataStream</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 将source和sink绑定到channel上</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<p>启动flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent --conf conf/ --conf-file conf/hdfs.conf -Dfile.root.logger=debug,info,console --name hdfs</span><br></pre></td></tr></table></figure>

<p>注：如果出现<code>com.google.common.base.Preconditions.checkArgument</code> 查看下<code>flume/lib</code>目录下</p>
<p>的<code>guava.jar</code>版本是否与<code>hadoop/share/hadoop/common/lib</code>中的版本是否一致，不一致拷贝新版</p>
<p>重新运行</p>
<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200112212041558.png" alt="image-20200112212041558"></p>
<p>在后台查看</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /user/flume/messages/flume-.1578835130630</span><br></pre></td></tr></table></figure>



<p><img src="/md%E5%9B%BE%5Cflume.assets/image-20200112212150353.png" alt="image-20200112212150353"></p>
<h1 id="十五、Flume-SDK"><a href="#十五、Flume-SDK" class="headerlink" title="十五、Flume SDK"></a>十五、Flume SDK</h1><h2 id="（1）自定义Source"><a href="#（1）自定义Source" class="headerlink" title="（1）自定义Source"></a>（1）自定义Source</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySource</span> <span class="keyword">extends</span> <span class="title class_">AbstractSource</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span>, PollableSource &#123;</span><br><span class="line">  <span class="keyword">private</span> String myProp;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">myProp</span> <span class="operator">=</span> context.getString(<span class="string">&quot;myProp&quot;</span>, <span class="string">&quot;defaultValue&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Process the myProp value (e.g. validation, convert to another type, ...)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Store myProp for later retrieval by process() method</span></span><br><span class="line">    <span class="built_in">this</span>.myProp = myProp;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// Initialize the connection to the external client</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">stop</span> <span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// Disconnect from external client and do any additional cleanup</span></span><br><span class="line">    <span class="comment">// (e.g. releasing resources or nulling-out field values) ..</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line">    <span class="type">Status</span> <span class="variable">status</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// This try clause includes whatever Channel/Event operations you want to do</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// Receive new data</span></span><br><span class="line">      <span class="type">Event</span> <span class="variable">e</span> <span class="operator">=</span> getSomeData();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Store the Event into this Source&#x27;s associated Channel(s)</span></span><br><span class="line">      getChannelProcessor().processEvent(e);</span><br><span class="line"></span><br><span class="line">      status = Status.READY;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">      <span class="comment">// Log exception, handle individual exceptions as needed</span></span><br><span class="line"></span><br><span class="line">      status = Status.BACKOFF;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// re-throw all Errors</span></span><br><span class="line">      <span class="keyword">if</span> (t <span class="keyword">instanceof</span> Error) &#123;</span><br><span class="line">        <span class="keyword">throw</span> (Error)t;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      txn.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> status;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="添加MySource"><a href="#添加MySource" class="headerlink" title="添加MySource"></a>添加MySource</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.itheima.flume.source;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.Event;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.EventDeliveryException;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.PollableSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.conf.Configurable;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.event.SimpleEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.source.AbstractSource;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySource</span> <span class="keyword">extends</span> <span class="title class_">AbstractSource</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span>, PollableSource &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 处理数据</span></span><br><span class="line">    <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line">        <span class="type">Status</span> <span class="variable">status</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 接收新数据</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">                <span class="type">Event</span> <span class="variable">e</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SimpleEvent</span>();</span><br><span class="line">                e.setBody((<span class="string">&quot;data:&quot;</span>+i).getBytes());</span><br><span class="line">                <span class="comment">// 将数据存储到与Source关联的Channel中</span></span><br><span class="line">                getChannelProcessor().processEvent(e);</span><br><span class="line">                status = Status.READY;</span><br><span class="line">            &#125;</span><br><span class="line">            Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            <span class="comment">// 打印日志</span></span><br><span class="line">            status = Status.BACKOFF;</span><br><span class="line">            <span class="comment">// 抛出异常</span></span><br><span class="line">            <span class="keyword">if</span> (t <span class="keyword">instanceof</span> Error) &#123;</span><br><span class="line">                <span class="keyword">throw</span> (Error)t;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getBackOffSleepIncrement</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getMaxBackOffSleepInterval</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="添加mySourceAgent-conf"><a href="#添加mySourceAgent-conf" class="headerlink" title="添加mySourceAgent.conf"></a>添加mySourceAgent.conf</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">定义agent名称为a1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置3个组件的名称</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置<span class="built_in">source</span>类型为mysource</span></span><br><span class="line">a1.sources.r1.type = com.itheima.flume.source.MySource</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置sink类型为Logger</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置channel类型为内存，内存队列最大容量为1000，一个事务中从<span class="built_in">source</span>接收的Events数量或者发送给sink的Events数量最大为100</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将<span class="built_in">source</span>和sink绑定到channel上</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<h3 id="启动Flume"><a href="#启动Flume" class="headerlink" title="启动Flume"></a>启动Flume</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -n a1 -c conf -f mySourceAgent.conf</span><br></pre></td></tr></table></figure>



<h2 id="（2）自定义Sink"><a href="#（2）自定义Sink" class="headerlink" title="（2）自定义Sink"></a>（2）自定义Sink</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySink</span> <span class="keyword">extends</span> <span class="title class_">AbstractSink</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> String myProp;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">myProp</span> <span class="operator">=</span> context.getString(<span class="string">&quot;myProp&quot;</span>, <span class="string">&quot;defaultValue&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Process the myProp value (e.g. validation)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Store myProp for later retrieval by process() method</span></span><br><span class="line">    <span class="built_in">this</span>.myProp = myProp;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// Initialize the connection to the external repository (e.g. HDFS) that</span></span><br><span class="line">    <span class="comment">// this Sink will forward Events to ..</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">stop</span> <span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// Disconnect from the external respository and do any</span></span><br><span class="line">    <span class="comment">// additional cleanup (e.g. releasing resources or nulling-out</span></span><br><span class="line">    <span class="comment">// field values) ..</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line">    <span class="type">Status</span> <span class="variable">status</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start transaction</span></span><br><span class="line">    <span class="type">Channel</span> <span class="variable">ch</span> <span class="operator">=</span> getChannel();</span><br><span class="line">    <span class="type">Transaction</span> <span class="variable">txn</span> <span class="operator">=</span> ch.getTransaction();</span><br><span class="line">    txn.begin();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// This try clause includes whatever Channel operations you want to do</span></span><br><span class="line"></span><br><span class="line">      <span class="type">Event</span> <span class="variable">event</span> <span class="operator">=</span> ch.take();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Send the Event to the external repository.</span></span><br><span class="line">      <span class="comment">// storeSomeData(e);</span></span><br><span class="line"></span><br><span class="line">      txn.commit();</span><br><span class="line">      status = Status.READY;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">      txn.rollback();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Log exception, handle individual exceptions as needed</span></span><br><span class="line"></span><br><span class="line">      status = Status.BACKOFF;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// re-throw all Errors</span></span><br><span class="line">      <span class="keyword">if</span> (t <span class="keyword">instanceof</span> Error) &#123;</span><br><span class="line">        <span class="keyword">throw</span> (Error)t;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> status;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="添加MySink，可以参考LoggerSink"><a href="#添加MySink，可以参考LoggerSink" class="headerlink" title="添加MySink，可以参考LoggerSink"></a>添加MySink，可以参考LoggerSink</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.itheima.flume.sink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flume.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.conf.Configurable;</span><br><span class="line"><span class="keyword">import</span> org.apache.flume.sink.AbstractSink;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySink</span> <span class="keyword">extends</span> <span class="title class_">AbstractSink</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Logger</span> <span class="variable">logger</span> <span class="operator">=</span> LoggerFactory</span><br><span class="line">            .getLogger(MySink.class);</span><br><span class="line">    <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line">        <span class="type">Status</span> <span class="variable">status</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="comment">// 开启事务</span></span><br><span class="line">        <span class="type">Channel</span> <span class="variable">ch</span> <span class="operator">=</span> getChannel();</span><br><span class="line">        <span class="type">Transaction</span> <span class="variable">txn</span> <span class="operator">=</span> ch.getTransaction();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            txn.begin();</span><br><span class="line">            <span class="comment">// 从channel中获取数据</span></span><br><span class="line">            <span class="type">Event</span> <span class="variable">event</span> <span class="operator">=</span> ch.take();</span><br><span class="line">            <span class="keyword">if</span>(event==<span class="literal">null</span>)&#123;</span><br><span class="line">                status = Status.BACKOFF;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 将事件发送到外部存储</span></span><br><span class="line">            <span class="comment">// storeSomeData(e);</span></span><br><span class="line">            <span class="comment">// 打印事件</span></span><br><span class="line">            logger.info(<span class="keyword">new</span> <span class="title class_">String</span>(event.getBody()));</span><br><span class="line">            <span class="comment">// 提交事务</span></span><br><span class="line">            txn.commit();</span><br><span class="line">            status = Status.READY;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            txn.rollback();</span><br><span class="line">            <span class="comment">// 打印异常日志</span></span><br><span class="line">            status = Status.BACKOFF;</span><br><span class="line">            <span class="comment">// 抛出异常</span></span><br><span class="line">            <span class="keyword">if</span> (t <span class="keyword">instanceof</span> Error) &#123;</span><br><span class="line">                <span class="keyword">throw</span> (Error)t;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            txn.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="修改上面的mySourceAgent-conf"><a href="#修改上面的mySourceAgent-conf" class="headerlink" title="修改上面的mySourceAgent.conf"></a>修改上面的mySourceAgent.conf</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">定义agent名称为a1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置3个组件的名称</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置<span class="built_in">source</span>类型为mysource</span></span><br><span class="line">a1.sources.r1.type = com.itheima.flume.source.MySource</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置sink类型为MySink</span></span><br><span class="line">a1.sinks.k1.type = com.itheima.flume.sink.MySink</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置channel类型为内存，内存队列最大容量为1000，一个事务中从<span class="built_in">source</span>接收的Events数量或者发送给sink的Events数量最大为100</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将<span class="built_in">source</span>和sink绑定到channel上</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>



<h1 id="十六、Flume-综合实战案例"><a href="#十六、Flume-综合实战案例" class="headerlink" title="十六、Flume 综合实战案例"></a>十六、Flume 综合实战案例</h1><h2 id="（1）案例场景"><a href="#（1）案例场景" class="headerlink" title="（1）案例场景"></a>（1）案例场景</h2><p>A、B、C等日志服务机器实时生产日志，日志的内容分为多种类型：</p>
<p>  APP端用户行为日志</p>
<p>  微信小程序端用户行为日志</p>
<p>  PC端用户行为日志</p>
<h3 id="需求："><a href="#需求：" class="headerlink" title="需求："></a><strong>需求：</strong></h3><p>把日志服务器中的各类日志数据采集汇总到一个中转agent上，然后分类写入hdfs中。</p>
<p>在hdfs中要求的目录为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/source/logs/app_log/20160101/**</span><br><span class="line"></span><br><span class="line">/source/logs/wxapp_log/20160101/**</span><br><span class="line"></span><br><span class="line">/source/logs/pcweb_log/20160101/**</span><br></pre></td></tr></table></figure>

<p><em><strong>并要求可以按指定的字段名，将对应字段内容加密！</strong></em></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230130235444507.png" alt="image-20230130235444507"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">linux命令操作替换jar包中的文件：</span><br><span class="line"></span><br><span class="line">显示jar中的文件列表：  jar -tvf xx.jar</span><br><span class="line"></span><br><span class="line">解压jar中的指定文件：  jar -xvf xx.jar yy.properties</span><br><span class="line"></span><br><span class="line">更新jar中的指定文件：  jar -uvf xx.jar yy.properties</span><br></pre></td></tr></table></figure>

<h2 id="（2）实现思路"><a href="#（2）实现思路" class="headerlink" title="（2）实现思路"></a>（2）实现思路</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1. 每台日志服务器上部署一个flume agent - - -&gt; 上游，每个agent配置2个source对应2类数据</span><br><span class="line"></span><br><span class="line">2. 上游的agent在采集数据时，添加一个header，指定数据的类别</span><br><span class="line"></span><br><span class="line">3. 上游的agent要配置两个avro sink，各自对接一个下级的agent</span><br><span class="line"></span><br><span class="line">4. 上游还要配置sink processor，fail over sink processor，控制两个sink中只有一个avro sink在工作，如果失败再切换到另一个avro sink</span><br><span class="line"></span><br><span class="line">5. 上游还要配置字段加密拦截器</span><br><span class="line"></span><br><span class="line">6. 下游配置两个flume agent，使用avro source接收数据</span><br><span class="line"></span><br><span class="line">7. 下游的hdfs sink，目录配置使用动态通配符，取到event中的类别header，以便于将不同类别数据写入不同hdfs目录 </span><br></pre></td></tr></table></figure>

<h2 id="（3）操作步骤"><a href="#（3）操作步骤" class="headerlink" title="（3）操作步骤"></a>（3）操作步骤</h2><h3 id="1）部署行为日志生产模拟器"><a href="#1）部署行为日志生产模拟器" class="headerlink" title="1）部署行为日志生产模拟器"></a>1）部署行为日志生产模拟器</h3><p><strong>1.准备一个mysql服务器，并创建一个库：realtimedw</strong></p>
<img src=".\md图\flume.assets\image-20230201000514636.png" alt="image-20230201000514636" style="zoom:80%;" />

<p><strong>2.将realtimedw.sql这个脚本，导入到realtimedw库中</strong></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230201005947135.png" alt="image-20230201005947135"></p>
<p><strong>3.将t_md_areas.sql这个脚本，导入到realtimedw库中</strong></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230201010005829.png" alt="image-20230201010005829"></p>
<p><strong>4.准备其他数据文件目录</strong></p>
<p>新建目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/export/data/flume-example-data/loginit</span><br></pre></td></tr></table></figure>

<img src=".\md图\flume.assets\image-20230201010138833.png" alt="image-20230201010138833" style="zoom:80%;" />

<p><strong>5.修改jar包中的配置文件</strong></p>
<p><strong>log_gen_app.jar包中的配置文件修改</strong></p>
<ul>
<li>other.properties</li>
</ul>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#logger,kafka</span></span><br><span class="line"><span class="attr">sink.type</span>=<span class="string">logger</span></span><br><span class="line"><span class="comment">#roll console dayroll</span></span><br><span class="line"><span class="attr">logger.type</span>=<span class="string">dayroll</span></span><br><span class="line"></span><br><span class="line"><span class="attr">initdata.releasechannel</span>=<span class="string">/export/data/flume-example-data/loginit/releasechannel.txt</span></span><br><span class="line"><span class="attr">initdata.phoneinfo</span>=<span class="string">/export/data/flume-example-data/loginit/phoneinfo.txt</span></span><br><span class="line"><span class="attr">initdata.eventIds</span>=<span class="string">/export/data/flume-example-data/loginit/eventIds.txt</span></span><br><span class="line"><span class="attr">init.user.area</span>=<span class="string">/export/data/flume-example-data/loginit/area.txt</span></span><br><span class="line"></span><br><span class="line"><span class="attr">db.url</span>=<span class="string">jdbc:mysql://127.0.0.1:3306/realtimedw?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false</span></span><br><span class="line"><span class="attr">db.user</span>=<span class="string">root</span></span><br><span class="line"><span class="attr">db.password</span>=<span class="string">hadoop</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># max concurrent accessor amount</span></span><br><span class="line"><span class="attr">online.max.num</span>=<span class="string">1000</span></span><br></pre></td></tr></table></figure>

<ul>
<li>log4j.properties</li>
</ul>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">INFO,trace</span></span><br><span class="line"></span><br><span class="line"><span class="attr">log4j.appender.trace</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.trace.Threshold</span>=<span class="string">DEBUG</span></span><br><span class="line"><span class="attr">log4j.appender.trace.ImmediateFlush</span>=<span class="string">true</span></span><br><span class="line"><span class="attr">log4j.appender.trace.Target</span>=<span class="string">System.out</span></span><br><span class="line"><span class="attr">log4j.appender.trace.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.trace.layout.ConversionPattern</span>=<span class="string">[%-5p] %d(%r) --&gt; [%t] %l: %m %x %n</span></span><br><span class="line"></span><br><span class="line"><span class="attr">log4j.logger.console</span> = <span class="string">INFO,console</span></span><br><span class="line"><span class="attr">log4j.additivity.console</span>=<span class="string">false</span></span><br><span class="line"><span class="attr">log4j.appender.console</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.console.Threshold</span>=<span class="string">DEBUG</span></span><br><span class="line"><span class="attr">log4j.appender.console.ImmediateFlush</span>=<span class="string">true</span></span><br><span class="line"><span class="attr">log4j.appender.console.Target</span>=<span class="string">System.out</span></span><br><span class="line"><span class="attr">log4j.appender.console.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.console.layout.ConversionPattern</span>=<span class="string">%m%n</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># log4j.logger.roll = INFO,rollingFile</span></span><br><span class="line"><span class="comment"># log4j.additivity.roll=false</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile=org.apache.log4j.RollingFileAppender</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile.Threshold=DEBUG</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile.ImmediateFlush=true</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile.Append=true</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile.File=/loggen/logdata/wx/event.log</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile.MaxFileSize=120MB</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile.MaxBackupIndex=50</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile.layout=org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="comment"># log4j.appender.rollingFile.layout.ConversionPattern=%m%n</span></span><br><span class="line"></span><br><span class="line"><span class="attr">log4j.logger.dayroll</span> = <span class="string">INFO,DailyRolling</span></span><br><span class="line"><span class="attr">log4j.additivity.dayroll</span>=<span class="string">false</span></span><br><span class="line"><span class="attr">log4j.appender.DailyRolling</span>=<span class="string">org.apache.log4j.DailyRollingFileAppender</span></span><br><span class="line"><span class="attr">log4j.appender.DailyRolling.File</span>=<span class="string">/export/data/flume-example-data/gen_logdata/event_log_app</span></span><br><span class="line"><span class="attr">log4j.appender.DailyRolling.DatePattern</span>=<span class="string">yyyy-MM-dd&#x27;.log&#x27;</span></span><br><span class="line"><span class="attr">log4j.appender.DailyRolling.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.DailyRolling.layout.ConversionPattern</span>=<span class="string">%m%n</span></span><br></pre></td></tr></table></figure>

<p><strong>log_gen_wx.jar包中的配置文件修改</strong></p>
<ul>
<li><p>other.properties与上文一致</p>
</li>
<li><p>log4j.properties 其中一行修改为</p>
</li>
</ul>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log4j.appender.DailyRolling.File</span>=<span class="string">/export/data/flume-example-data/gen_logdata/event_log_wx</span></span><br></pre></td></tr></table></figure>

<p><strong>6.上传jar包，执行启动命令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在/export/data/flume-example-data/loginit 中添加shell文件用以启动日志生成器</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim genapplog.sh</span><br><span class="line"></span><br><span class="line">java -Xss102400k -<span class="built_in">cp</span> log_gen_app.jar cn.doitedu.loggen.entry.GenAppLog 1 &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim genwxlog.sh</span><br><span class="line"></span><br><span class="line">java -Xss102400k -<span class="built_in">cp</span> log_gen_wx.jar cn.doitedu.loggen.entry.GenWxAppLog 1 &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sh genapplog.sh</span><br><span class="line"></span><br><span class="line">sh genwxlog.sh</span><br></pre></td></tr></table></figure>

<img src=".\md图\flume.assets\image-20230201010312246.png" alt="image-20230201010312246" style="zoom: 67%;" />

<p><strong>7.查看日志文件生成效果</strong></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230201010531192.png" alt="image-20230201010531192"></p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230201010622186.png" alt="image-20230201010622186"></p>
<h3 id="2）上游配置文件：-node1-node2"><a href="#2）上游配置文件：-node1-node2" class="headerlink" title="2）上游配置文件：(node1 node2)"></a>2）上游配置文件：(node1 node2)</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example14-1-Comprehensive-practical.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/export/data/flume-example-data/flumedata/taildir_position.json</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">g1</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g1</span> =  <span class="string">/export/data/flume-example-data/gen_logdata/event_.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors</span> = <span class="string">i1 i2 i3</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.type</span> = <span class="string">ccjz.rgzn.flume.EncryptSpecifiedFieldInterceptor$EncryptInterceptorBuilder</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.toEncryFieldName</span> = <span class="string">account</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i2.type</span> = <span class="string">ccjz.rgzn.flume.EventTimeStampExtractInterceptor$EventTimestampInterceptorBuilder</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i2.tsFiledName</span> = <span class="string">timeStamp</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i2.keyName</span> = <span class="string">timestamp</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#拥有openid的是wx小程序用户日志</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i3.type</span> = <span class="string">ccjz.rgzn.flume.LogTypeInterceptor$LogTypeInterceptorBuilder</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i3.flag.fieldname</span> = <span class="string">openid</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i3.headerKey</span> = <span class="string">logtype</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">file</span></span><br><span class="line"><span class="attr">a1.channels.c1.checkpointDir</span> =  <span class="string">/export/data/flume-example-data/flumedata/checkpoint</span></span><br><span class="line"><span class="attr">a1.channels.c1.dataDirs</span> =  <span class="string">/export/data/flume-example-data/flumedata/data</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">2000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = <span class="string">node2</span></span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sinks.k1.batch-size</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hostname</span> = <span class="string">node3</span></span><br><span class="line"><span class="attr">a1.sinks.k2.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sinks.k2.batch-size</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinkgroups</span> = <span class="string">g1</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.type</span> = <span class="string">failover</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.priority.k1</span> = <span class="string">200</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.priority.k2</span> = <span class="string">100</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.maxpenalty</span> = <span class="string">5000</span></span><br></pre></td></tr></table></figure>

<h3 id="3）下游配置文件-node2-node3"><a href="#3）下游配置文件-node2-node3" class="headerlink" title="3）下游配置文件(node2 node3)"></a>3）下游配置文件(node2 node3)</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#example14-2-Comprehensive-practical.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.threads</span> = <span class="string">10</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">file</span></span><br><span class="line"><span class="attr">a1.channels.c1.checkpointDir</span> =  <span class="string">/export/data/flume-example-data/flumedata_2/checkpoint</span></span><br><span class="line"><span class="attr">a1.channels.c1.dataDirs</span> =  <span class="string">/export/data/flume-example-data/flumedata_2/data</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">2000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = <span class="string">hdfs://node1:8020/gen_logdata/%&#123;logtype&#125;/%Y-%m-%d/</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = <span class="string">logdata_</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileSuffix</span> = <span class="string">.log</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="string">300</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="string">268435456</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.batchSize</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.codeC</span> = <span class="string">gzip</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = <span class="string">CompressedStream</span></span><br></pre></td></tr></table></figure>



<h2 id="（4）启动测试"><a href="#（4）启动测试" class="headerlink" title="（4）启动测试"></a>（4）启动测试</h2><ol>
<li><p>先把自定义拦截器代码jar包放入上游（node1）flume的lib目录中；</p>
</li>
<li><p>将各台机器上之前的一些checkpoint、缓存等目录清除；</p>
</li>
<li><p>启动下游的两个agent（node2、node3上）；</p>
</li>
<li><p>在上游的机器上，创建日志数据目录，并写脚本模拟往3类日志中写入日志：</p>
<p><img src="/.%5Cmd%E5%9B%BE%5Cflume.assets%5Cimage-20230131000318670.png" alt="image-20230131000318670"></p>
</li>
<li><p>在上游的所有机器上启动flume agent</p>
</li>
<li><p>到hdfs上观察结果</p>
</li>
<li><p>尝试kill掉下游node2的 agent，看是否能够故障切换</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/flume/" data-id="clj254b6q000700urghds8f0d" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Docker实用篇" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/19/Docker%E5%AE%9E%E7%94%A8%E7%AF%87/" class="article-date">
  <time class="dt-published" datetime="2023-06-19T00:49:49.439Z" itemprop="datePublished">2023-06-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Docker实用篇"><a href="#Docker实用篇" class="headerlink" title="Docker实用篇"></a>Docker实用篇</h1><h1 id="1-初识Docker"><a href="#1-初识Docker" class="headerlink" title="1.初识Docker"></a>1.初识Docker</h1><h2 id="1-1-什么是Docker"><a href="#1-1-什么是Docker" class="headerlink" title="1.1.什么是Docker"></a>1.1.什么是Docker</h2><p><code>微服务</code>虽然具备各种各样的优势，但<code>服务的拆分通用</code>给<code>部署</code>带来了很大的麻烦。</p>
<blockquote>
<p><code>微服务</code>是一种<code>基于服务架构</code>的<code>软件开发模式</code>，它将应用程序拆分成一组<code>小型、自治的服务</code>，每个服务只负责完成特定的业务功能。每个服务都可以<code>独立部署、升级、扩展和替换</code>，服务之间通过轻量级的通信机制进行通信，如REST（Representational State Transfer）、RPC（Remote Procedure Call）等。</p>
<p>微服务的目标是提高应用程序的可伸缩性、可维护性和可重用性，使团队能够更快地开发、测试和部署应用程序。微服务架构还可以帮助企业实现更快的创新和更好的业务灵活性，因为它可以让企业更容易地在不同的技术栈之间切换，更容易地实现新功能和新服务。</p>
</blockquote>
<ul>
<li>分布式系统中，依赖的组件非常多，<code>不同组件之间部署时往往会产生一些冲突</code>。</li>
<li><code>在数百上千台服务中重复部署，环境不一定一致，会遇到各种问题</code></li>
</ul>
<img src=".\assets\image-20230204231611871.png" alt="image-20230204231611871" style="zoom:80%;" />

<p><img src="/.%5Cassets%5Cimage-20230203163959671.png" alt="image-20230203163959671"></p>
<ul>
<li>Docker 是一个开源的<code>应用容器引擎</code></li>
<li>诞生于2013 年初，基于<code>Go 语言</code>实现，dotCloud 公司出品（后改名为Docker Inc）</li>
<li><strong>Docker 可以让开发者<code>打包</code>他们的<code>应用以及依赖</code>包到一个<code>轻量级、可移植的容器</code>中，然后<code>发布到任何流行的Linux 机器上</code>。</strong></li>
<li>容器是完全使用<code>沙箱机制，相互隔离</code></li>
<li>容器<code>性能开销极低</code>。</li>
<li>Docker 从<code>17.03 版本</code>之后分为<code>CE（Community Edition: 社区版）</code>和<code>EE（Enterprise Edition: 企业版）</code></li>
</ul>
<h3 id="1-1-1-应用部署的环境问题"><a href="#1-1-1-应用部署的环境问题" class="headerlink" title="1.1.1.应用部署的环境问题"></a>1.1.1.应用部署的环境问题</h3><p>大型项目组件较多，运行环境也较为复杂，部署时会碰到一些问题：</p>
<ul>
<li><p>依赖关系复杂，容易出现兼容性问题</p>
</li>
<li><p>开发、测试、生产环境有差异</p>
</li>
</ul>
<img src="assets/image-20210731141907366.png" alt="image-20210731141907366"  />

<p>例如一个项目中，部署时需要依赖于node.js、Redis、RabbitMQ、MySQL等，这些服务部署时所需要的函数库、依赖项各不相同，甚至会有冲突。给部署带来了极大的困难。</p>
<p><strong>软件跨环境迁移的问题</strong></p>
<p><img src="/.%5Cassets%5Cimage-20230203162944320.png" alt="image-20230203162944320"></p>
<p><img src="/.%5Cassets%5Cimage-20230204232834835.png" alt="image-20230204232834835"></p>
<h3 id="1-1-2-Docker解决依赖兼容问题"><a href="#1-1-2-Docker解决依赖兼容问题" class="headerlink" title="1.1.2.Docker解决依赖兼容问题"></a>1.1.2.Docker解决依赖兼容问题</h3><p>而Docker确巧妙的解决了这些问题，Docker是如何实现的呢？</p>
<p>Docker为了<code>解决依赖的兼容问题</code>的，采用了<code>两个手段</code>：</p>
<ul>
<li><p>将应用的<code>Libs（函数库）</code>、<code>Deps（依赖）</code>、<code>配置</code>与<code>应用一起打包</code></p>
</li>
<li><p>将每个应用放到一个隔离**&#x3D;&#x3D;容器&#x3D;&#x3D;**去运行，<code>避免互相干扰</code></p>
</li>
</ul>
<p><img src="/assets/image-20210731142219735.png" alt="image-20210731142219735"></p>
<p>这样<code>打包好的应用包中</code>，<code>既包含应用本身</code>，也保护应用<code>所需要的Libs、Deps</code>，无需再在操作系统上安装这些，自然就<code>不存在不同应用之间的兼容问题了</code>。</p>
<p>虽然解决了不同应用的兼容问题，但是<code>开发、测试等环境会存在差异</code>，<code>操作系统版本也会有差异</code>，怎么解决这些问题呢？</p>
<h3 id="1-1-3-Docker解决操作系统环境差异"><a href="#1-1-3-Docker解决操作系统环境差异" class="headerlink" title="1.1.3.Docker解决操作系统环境差异"></a>1.1.3.Docker解决操作系统环境差异</h3><p>要解决不同操作系统环境差异问题，必须先了解操作系统结构。以一个Ubuntu操作系统为例，结构如下：</p>
<p><img src="/assets/image-20210731143401460.png" alt="image-20210731143401460"></p>
<p>结构包括：</p>
<ul>
<li><code>计算机硬件</code>：例如CPU、内存、磁盘等</li>
<li><code>系统内核</code>：所有<code>Linux发行版的内核都是Linux</code>，例如<code>CentOS、Ubuntu、Fedora等</code>。内核可以与计算机硬件交互，对外提供&#x3D;&#x3D;<strong>内核指令</strong>&#x3D;&#x3D;，用于操作计算机硬件。</li>
<li><code>系统应用</code>：操作系统本身提供的应用、函数库。这些函数库是对内核指令的封装，使用更加方便。</li>
</ul>
<p>应用于计算机交互的流程如下：</p>
<p>1）<code>应用</code>&#x3D;&#x3D;调用&#x3D;&#x3D;<code>操作系统应用（函数库）</code>，实现各种功能</p>
<p>2）<code>系统函数库</code>是对<code>内核指令集的封装</code>，会&#x3D;&#x3D;调用&#x3D;&#x3D;<code>内核指令</code></p>
<p>3）<code>内核指令</code>&#x3D;&#x3D;操作&#x3D;&#x3D;<code>计算机硬件</code></p>
<p>Ubuntu和CentOS都是基于Linux内核，无非是<code>系统应用不同</code>，提供的函数库有差异：</p>
<img src="assets/image-20210731144304990.png" alt="image-20210731144304990"  />



<p>此时，如果<code>将一个Ubuntu版本</code>的<code>MySQL应用安装到CentOS系统</code>，<code>MySQL在调用Ubuntu函数库时</code>，会发现<code>找不到或者不匹配</code>，就会报错了：</p>
<img src="assets/image-20210731144458680.png" alt="image-20210731144458680"  />



<p>Docker如何解决不同系统环境的问题？</p>
<ul>
<li>Docker将<code>用户程序</code>与<code>所需要调用的系统(比如Ubuntu)函数库</code>&#x3D;&#x3D;一起打包&#x3D;&#x3D;</li>
<li>Docker<code>运行到不同操作系统时</code>，直接<code>基于打包的函数库</code>，借助于操作系统的Linux内核来运行</li>
</ul>
<p>如图：</p>
<img src="assets/image-20210731144820638.png" alt="image-20210731144820638"  />



<h3 id="1-1-4-小结"><a href="#1-1-4-小结" class="headerlink" title="1.1.4.小结"></a>1.1.4.小结</h3><p>Docker如何解决大型项目依赖关系复杂，不同组件依赖的兼容性问题？</p>
<ul>
<li>Docker允许开发中将应用、依赖、函数库、配置一起<strong>打包</strong>，形成可移植镜像</li>
<li>Docker应用运行在容器中，使用沙箱机制，相互<strong>隔离</strong></li>
</ul>
<p>Docker如何解决开发、测试、生产环境有差异的问题？</p>
<ul>
<li>Docker镜像中包含完整运行环境，包括系统函数库，仅依赖系统的Linux内核，因此可以在任意Linux操作系统上运行</li>
</ul>
<p>Docker是一个快速交付应用、运行应用的技术，具备下列优势：</p>
<ul>
<li>可以将程序及其依赖、运行环境一起打包为一个镜像，可以迁移到任意Linux操作系统</li>
<li>运行时利用沙箱机制形成隔离容器，各个应用互不干扰</li>
<li>启动、移除都可以通过一行命令完成，方便快捷</li>
</ul>
<h2 id="1-2-Docker和虚拟机的区别"><a href="#1-2-Docker和虚拟机的区别" class="headerlink" title="1.2.Docker和虚拟机的区别"></a>1.2.Docker和虚拟机的区别</h2><p>Docker可以让一个<code>应用在任何操作系统中非常方便的运行</code>。而以前我们接触的虚拟机，也能在一个操作系统中，运行另外一个操作系统，保护系统中的任何应用。</p>
<p><code>两者有什么差异呢？</code></p>
<p><strong><code>虚拟机</code><strong>（virtual machine）是在操作系统中</strong><code>模拟</code></strong><code>硬件设备</code>，然后运行另一个操作系统，比如在 Windows 系统里面运行 Ubuntu 系统，这样就可以运行任意的Ubuntu应用了。</p>
<p>**<code>Docker</code>**仅仅是封装函数库，<code>并没有模拟完整的操作系统</code>，如图：</p>
<img src="assets/image-20210731145914960.png" alt="image-20210731145914960" style="zoom: 25%;" />

<p>对比来看：</p>
<img src=".\assets\image-20230204232020530.png" alt="image-20230204232020530" style="zoom: 67%;" />



<p>小结：</p>
<p>Docker和虚拟机的差异：</p>
<ul>
<li><p>docker是一个系统进程；虚拟机是在操作系统中的操作系统</p>
</li>
<li><p>docker体积小、启动速度快、性能好；虚拟机体积大、启动速度慢、性能一般</p>
</li>
</ul>
<h2 id="1-3-Docker架构"><a href="#1-3-Docker架构" class="headerlink" title="1.3.Docker架构"></a>1.3.Docker架构</h2><h3 id="1-3-1-镜像和容器"><a href="#1-3-1-镜像和容器" class="headerlink" title="1.3.1.镜像和容器"></a>1.3.1.镜像和容器</h3><img src=".\assets\image-20230203164559342.png" alt="image-20230203164559342" style="zoom:80%;" />

<p>Docker中有几个重要的概念：</p>
<ul>
<li>**<code>镜像（Image）</code>**：Docker<code>将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起</code>，称为镜像。就相当于是一个root 文件系统。比如官方镜像ubuntu:16.04 就包含了完整的一套Ubuntu16.04 最小系统的root 文件系统。</li>
<li>**<code>容器（Container）</code><strong>：<code>镜像中的应用程序运行后形成的进程就是</code></strong><code>容器</code>**，只是Docker会给容器进程做隔离，对外不可见。镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和对象一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。</li>
<li>**<code>仓库（Repository）</code>**：仓库可看成一个<code>代码控制中心</code>，用来保存镜像。</li>
</ul>
<p>一切应用最终都是代码组成，都是硬盘中的一个个的字节形成的<strong>文件</strong>。只有运行时，才会加载到内存，形成进程。</p>
<p>而**<code>镜像</code>**，就是把一个应用在硬盘上的文件、及其运行环境、部分系统函数库文件一起打包形成的文件包。这个文件包是只读的。</p>
<p>**<code>容器</code>**呢，就是将这些文件中编写的程序、函数加载到内存中允许，形成进程，只不过要隔离起来。因此一个镜像可以启动多次，形成多个容器进程。</p>
<img src="assets/image-20210731153059464.png" alt="image-20210731153059464" style="zoom:25%;" />



<p>例如你下载了一个QQ，如果我们将QQ在磁盘上的运行<strong>文件</strong>及其运行的操作系统依赖打包，形成QQ镜像。然后你可以启动多次，双开、甚至三开QQ，跟多人聊天。</p>
<h3 id="1-3-2-DockerHub"><a href="#1-3-2-DockerHub" class="headerlink" title="1.3.2.DockerHub"></a>1.3.2.DockerHub</h3><p>开源应用程序非常多，打包这些应用往往是重复的劳动。为了避免这些重复劳动，人们就会将自己打包的应用镜像，例如Redis、MySQL镜像放到网络上，共享使用，就像GitHub的代码共享一样。</p>
<ul>
<li><p>DockerHub：DockerHub是一个官方的Docker镜像的托管平台。这样的平台称为Docker Registry。</p>
</li>
<li><p>国内也有类似于DockerHub 的公开服务，比如 <a target="_blank" rel="noopener" href="https://c.163yun.com/hub">网易云镜像服务</a>、<a target="_blank" rel="noopener" href="https://cr.console.aliyun.com/">阿里云镜像库</a>等。</p>
</li>
</ul>
<p>我们一方面可以将自己的镜像共享到DockerHub，另一方面也可以从DockerHub拉取镜像：</p>
<img src="assets/image-20210731153743354.png" alt="image-20210731153743354"  />

<p>默认情况下，将来从docker hub（<a target="_blank" rel="noopener" href="https://hub.docker.com/%EF%BC%89%E4%B8%8A%E4%B8%8B%E8%BD%BDdocker%E9%95%9C%E5%83%8F%EF%BC%8C%E5%A4%AA%E6%85%A2%E3%80%82%E4%B8%80%E8%88%AC%E9%83%BD%E4%BC%9A%E9%85%8D%E7%BD%AE%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F%E5%99%A8%EF%BC%9A">https://hub.docker.com/）上下载docker镜像，太慢。一般都会配置镜像加速器：</a></p>
<ul>
<li>USTC：中科大镜像加速器（<a target="_blank" rel="noopener" href="https://docker.mirrors.ustc.edu.cn)/">https://docker.mirrors.ustc.edu.cn）</a></li>
<li>阿里云</li>
<li>网易云</li>
<li>腾讯云</li>
</ul>
<h3 id="1-3-3-Docker架构"><a href="#1-3-3-Docker架构" class="headerlink" title="1.3.3.Docker架构"></a>1.3.3.Docker架构</h3><p>我们要使用Docker来操作镜像、容器，就必须要安装Docker。</p>
<p>Docker是一个CS架构的程序，由两部分组成：</p>
<ul>
<li><p>服务端(server)：Docker守护进程，负责处理Docker指令，管理镜像、容器等</p>
</li>
<li><p>客户端(client)：通过命令或RestAPI向Docker服务端发送指令。可以在本地或远程向服务端发送指令。</p>
</li>
</ul>
<p>如图：</p>
<p><img src="/assets/image-20210731154257653.png" alt="image-20210731154257653"></p>
<h3 id="1-3-4-小结"><a href="#1-3-4-小结" class="headerlink" title="1.3.4.小结"></a>1.3.4.小结</h3><p>镜像：</p>
<ul>
<li>将应用程序及其依赖、环境、配置打包在一起</li>
</ul>
<p>容器：</p>
<ul>
<li>镜像运行起来就是容器，一个镜像可以运行多个容器</li>
</ul>
<p>Docker结构：</p>
<ul>
<li><p>服务端：接收命令或远程请求，操作镜像或容器</p>
</li>
<li><p>客户端：发送命令或者请求到Docker服务端</p>
</li>
</ul>
<p>DockerHub：</p>
<ul>
<li>一个镜像托管的服务器，类似的还有阿里云镜像服务，统称为DockerRegistry</li>
</ul>
<h2 id="1-4-安装Docker"><a href="#1-4-安装Docker" class="headerlink" title="1.4.安装Docker"></a>1.4.安装Docker</h2><p><strong>Docker Engine是C&#x2F;S架构的</strong></p>
<img src=".\assets\image-20230204233058255.png" alt="image-20230204233058255" style="zoom:67%;" />

<h3 id="1-4-1Docker由以下几个部件组成："><a href="#1-4-1Docker由以下几个部件组成：" class="headerlink" title="1.4.1Docker由以下几个部件组成："></a>1.4.1<strong>Docker由以下几个部件组成：</strong></h3><h4 id="（1）Docker-Daemon"><a href="#（1）Docker-Daemon" class="headerlink" title="（1）Docker Daemon"></a>（1）Docker Daemon</h4><p>安装使用Docker，得先运行Docker Daemon进程，用于管理docker，如:</p>
<ul>
<li>镜像 images</li>
<li>容器 containers</li>
<li>网络 network</li>
<li>数据卷 Data Volumes</li>
</ul>
<h4 id="（2）Rest接口"><a href="#（2）Rest接口" class="headerlink" title="（2）Rest接口"></a>（2）Rest接口</h4><p>提供和Daemon交互的API接口</p>
<h4 id="（3）Docker-Client"><a href="#（3）Docker-Client" class="headerlink" title="（3）Docker Client"></a>（3）Docker Client</h4><p>客户端使用REST API和Docker Daemon进行访问</p>
<h3 id="1-4-2-Docker平台组成"><a href="#1-4-2-Docker平台组成" class="headerlink" title="1.4.2 Docker平台组成"></a>1.4.2 Docker平台组成</h3><img src=".\assets\image-20230204233350282.png" alt="image-20230204233350282" style="zoom:67%;" />

<h4 id="（1）Images"><a href="#（1）Images" class="headerlink" title="（1）Images"></a>（1）Images</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">镜像是一个只读模板，用于创建容器，也可以通过Dockerfile文本描述镜像的内容。</span><br><span class="line"></span><br><span class="line">镜像的概念类似于编程开发里面向对象的类，从一个基类开始(基础镜像Base lmage)</span><br><span class="line">构建容器的过程，就是运行镜像，生成容器实例。</span><br><span class="line"></span><br><span class="line">Docker镜像的描述文件是Dockerfile，包含了如下的指令</span><br><span class="line"></span><br><span class="line">- FROM 定义基础镜像</span><br><span class="line">- MAINTAINER 作者</span><br><span class="line">- RUN 运行Linux命令</span><br><span class="line">- ADD 添加文件/目录</span><br><span class="line">- ENV 环境变量</span><br><span class="line">- CMD 运行进程</span><br></pre></td></tr></table></figure>

<h4 id="（2）Container"><a href="#（2）Container" class="headerlink" title="（2）Container"></a>（2）Container</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">容器是一个镜像的运行实例，镜像 &gt; 容器</span><br><span class="line">创建容器的过程</span><br><span class="line"></span><br><span class="line">- 获取镜像，如 docker pull centos ,从镜像仓库拉取</span><br><span class="line">- 使用镜像创建容器</span><br><span class="line">- 分配文件系统，挂载一个读写层，在读写层加载镜像分配网络/网桥接口，创建一个网络接口，让容器和宿主机通信</span><br><span class="line">- 容器获取IP地址</span><br><span class="line">- 执行容器命令，如/bin/bash</span><br><span class="line">- 反馈容器启动结果。</span><br></pre></td></tr></table></figure>

<h4 id="（3）Registry"><a href="#（3）Registry" class="headerlink" title="（3）Registry"></a>（3）Registry</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Docker镜像需要进行管理，docker提供了Registry仓库，其实它也是一个容器。可以用于可以基于该容器运行私有仓库。</span><br><span class="line">也可以使用Docker Hub互联网公有镜像仓库</span><br></pre></td></tr></table></figure>





<h3 id="1-4-3-CentOS安装Docker"><a href="#1-4-3-CentOS安装Docker" class="headerlink" title="1.4.3 CentOS安装Docker"></a>1.4.3 CentOS安装Docker</h3><h4 id="（1）版本管理"><a href="#（1）版本管理" class="headerlink" title="（1）版本管理"></a>（1）版本管理</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Docker 分为 CE 和 EE 两大版本。CE 即社区版（免费，支持周期 7 个月），EE 即企业版，强调安全，付费使用，支持周期 24 个月。</span><br><span class="line"></span><br><span class="line">每个季度(1-3,4-6,7-9,10-12)，企业版和社区版都会发布一个稳定版本(Stable)。社区版本会提供 4 个月的支持，而企业版本会提供 12个月的支持</span><br><span class="line"></span><br><span class="line">每个月社区版还会通过 Edge 方式发布月度版</span><br><span class="line"></span><br><span class="line">从2017 年第一季度开始，Docker 版本号遵循 YY.MM-xx 格式，类似于 Ubuntu 等项目。例如，2018 年6 月第一次发布的社区版本为18.06.0-ce</span><br><span class="line"></span><br><span class="line">Docker CE 分为 `stable` `test` 和 `nightly` 三个更新频道。</span><br><span class="line"></span><br><span class="line">官方网站上有各种环境下的 [安装指南](https://docs.docker.com/install/)，这里主要介绍 Docker CE 在 CentOS上的安装。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Docker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10， CentOS 7 满足最低内核的要求，所以我们在CentOS 7安装Docker。</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cassets%5Cimage-20230204234218336.png" alt="image-20230204234218336"></p>
<h4 id="（2）机器环境初始化"><a href="#（2）机器环境初始化" class="headerlink" title="（2）机器环境初始化"></a>（2）机器环境初始化</h4><h5 id="1-卸载（可选）"><a href="#1-卸载（可选）" class="headerlink" title="1.卸载（可选）"></a>1.卸载（可选）</h5><p>如果之前安装过旧版本的Docker，可以使用下面命令卸载：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-selinux \</span><br><span class="line">                  docker-engine-selinux \</span><br><span class="line">                  docker-engine \</span><br><span class="line">                  docker-ce</span><br></pre></td></tr></table></figure>

<h5 id="2-yum源配置"><a href="#2-yum源配置" class="headerlink" title="2.yum源配置"></a>2.yum源配置</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">备份配置文件</span></span><br><span class="line">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line"></span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"></span><br><span class="line">wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo</span><br><span class="line"></span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">可选操作</span></span><br><span class="line">yum install -y bash-completion vim lrzsz wget expect net-tools nc nmap treedos2unix htop iftop iotop unzip telnet sl psmisc nethogs glances bc ntpdate openldap-devel</span><br></pre></td></tr></table></figure>



<h4 id="（3）安装docker"><a href="#（3）安装docker" class="headerlink" title="（3）安装docker"></a>（3）安装docker</h4><h5 id="1-首先需要虚拟机联网，安装yum工具"><a href="#1-首先需要虚拟机联网，安装yum工具" class="headerlink" title="1.首先需要虚拟机联网，安装yum工具"></a>1.首先需要虚拟机联网，安装yum工具</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils \</span><br><span class="line">           device-mapper-persistent-data \</span><br><span class="line">           lvm2 --skip-broken</span><br></pre></td></tr></table></figure>

<h5 id="2-配置网卡转发"><a href="#2-配置网卡转发" class="headerlink" title="2.配置网卡转发"></a>2.配置网卡转发</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1.docker必须安装在centos7平台，内核版本不低于3.10在centos平台运行docker可能会遇见些告警信息，修改内核配置参数，打开内核转发功能</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">写入</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/docker.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.conf.default.rp_filter = 0</span><br><span class="line">net.ipv4.conf.all.rp_filter = 0</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2.重新加载内核参数</span></span><br><span class="line">modprobe br_netfilter</span><br><span class="line">sysctl -p /etc/sysctl.d/docker.conf</span><br></pre></td></tr></table></figure>

<h5 id="3-利用yum进行docker安装"><a href="#3-利用yum进行docker安装" class="headerlink" title="3.利用yum进行docker安装"></a>3.利用yum进行docker安装</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提前配置好yum仓库</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1.阿里云自带仓库 2.阿里云提供的docker专属repo仓库</span></span><br><span class="line"></span><br><span class="line">curl -o /etc/yum.repos.d/docker-ce.repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">curl -o /etc/yum.repos.d/Centos-7.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">更新yum缓存</span></span><br><span class="line">yum clean all &amp;&amp; yum makecache</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">可以直接yum安装docker了</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 查看源中可用版本</span></span></span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># yum安装</span></span></span><br><span class="line">yum install docker-ce -y</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 如果需要安装旧版本</span></span></span><br><span class="line">yum install -y docker-ce-20.10.6</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#查看docker版本，验证是否验证成功</span></span></span><br><span class="line">docker -v</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#如果要卸载</span></span></span><br><span class="line">yum remove -y docker-ce-xxx</span><br></pre></td></tr></table></figure>

<h5 id="4-配置镜像加速器"><a href="#4-配置镜像加速器" class="headerlink" title="4.配置镜像加速器"></a>4.配置镜像加速器</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">用于加速镜像文件下载,选用阿里云镜像站</span></span><br><span class="line">mkdir -p /etc/docker</span><br><span class="line">touch /etc/docker/daemon.json</span><br><span class="line">vim /etc/docker/daemon.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">&quot;registry-mirrors&quot; : [</span><br><span class="line">&quot;https://8xpk5wnt.mirror.aliyuncs.com&quot;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="5-启动docker"><a href="#5-启动docker" class="headerlink" title="5.启动docker"></a>5.启动docker</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动docker前，一定要关闭防火墙后！！</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">禁止开机启动防火墙</span></span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#通过命令启动docker：</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">systemctl start docker  <span class="comment"># 启动docker服务</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">systemctl stop docker  <span class="comment"># 停止docker服务</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">systemctl restart docker  <span class="comment"># 重启docker服务</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">我们使用如下命令进行docker启动</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#docker配置文件重新加载</span></span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#设置开启自启动</span></span></span><br><span class="line">systemctl enable docker</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动docker</span></span><br><span class="line">systemctl start docker</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 查看docker信息</span></span></span><br><span class="line">docker info</span><br><span class="line">docker ps</span><br><span class="line">docker images</span><br><span class="line">docker version</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># docker-client</span></span></span><br><span class="line">which docker</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># docker daemon</span></span></span><br><span class="line">ps aux |grep docker</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># containerd</span></span></span><br><span class="line">ps aux|grep containerd</span><br><span class="line">systemctl status containerd</span><br></pre></td></tr></table></figure>



<h5 id="或者这样安装"><a href="#或者这样安装" class="headerlink" title="***.或者这样安装"></a>***.或者这样安装</h5><p>更新本地镜像源：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置docker镜像源</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">    </span><br><span class="line">sed -i &#x27;s/download.docker.com/mirrors.aliyun.com\/docker-ce/g&#x27; /etc/yum.repos.d/docker-ce.repo</span><br><span class="line"></span><br><span class="line">yum makecache fast</span><br></pre></td></tr></table></figure>

<p>然后输入命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y docker-ce</span><br></pre></td></tr></table></figure>

<p>docker-ce为社区免费版本。稍等片刻，docker即可安装成功。</p>
<h1 id="2-Docker的基本操作"><a href="#2-Docker的基本操作" class="headerlink" title="2.Docker的基本操作"></a>2.Docker的基本操作</h1><h2 id="2-0-docker初体验"><a href="#2-0-docker初体验" class="headerlink" title="2.0 docker初体验"></a>2.0 docker初体验</h2><h3 id="（1）docker快速体验"><a href="#（1）docker快速体验" class="headerlink" title="（1）docker快速体验"></a>（1）docker快速体验</h3><p>心中有数</p>
<p><img src="/.%5Cassets%5Cimage-20230205224930726.png" alt="image-20230205224930726"></p>
<p>启动第一个docker容器</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.获取镜像	</span></span><br><span class="line"><span class="comment">#2.运行镜像，生成容器，你想要的容器，就运行在容器中</span></span><br></pre></td></tr></table></figure>

<p>Nginx web服务器，运行一个80端口的网站</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在宿主机上，运行Nginx</span></span><br><span class="line">1.开启服务器</span><br><span class="line">2.在服务器上安装好运行nginx所需的依赖关系</span><br><span class="line">3.安装nginx yum install nginx -y</span><br><span class="line">4.修改nginx配置文件</span><br><span class="line">5.启动nginx</span><br><span class="line">6.客户端去访问nginx</span><br><span class="line"></span><br><span class="line">比较耗时</span><br></pre></td></tr></table></figure>

<p>如果使用docker运行，该如何做？</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.查看本地的docker镜像有哪些</span></span><br><span class="line">docker image <span class="built_in">ls</span> 或 docker images</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.可选择删除旧版本</span></span><br><span class="line">docker rmi 镜像<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#3.搜索一下远程仓库中的镜像文件是否存在</span></span><br><span class="line">docker search nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.拉取，下载镜像</span></span><br><span class="line">docerk pull nginx</span><br><span class="line">[root@node3 yum.repos.d]<span class="comment"># docker pull nginx</span></span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/nginx</span><br><span class="line">a2abf6c4d29d: Pull complete </span><br><span class="line">a9edb18cadd1: Pull complete </span><br><span class="line">589b7251471a: Pull complete </span><br><span class="line">186b1aaa4aa6: Pull complete </span><br><span class="line">b4df32aa5a72: Pull complete </span><br><span class="line">a0bcbecc962e: Pull complete </span><br><span class="line">Digest: sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> nginx:latest</span><br><span class="line">docker.io/library/nginx:latest</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.再次查看镜像</span></span><br><span class="line">docker images</span><br><span class="line">REPOSITORY   TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">nginx        latest    605c77e624dd   13 months ago   141MB</span><br><span class="line"></span><br><span class="line"><span class="comment">#6.运行镜像，运行出具体内容，在容器中就跑着一个nginx服务</span></span><br><span class="line">docker run 参数 镜像的名字/id</span><br><span class="line"><span class="comment">#-d 后台运行容器</span></span><br><span class="line"><span class="comment">#-p 80:80 端口映射，宿主机端口：容器内端口，访问宿主机的80端口，也就访问到容器中的80端口</span></span><br><span class="line">docker run -d -p 80:80 nginx</span><br><span class="line"><span class="comment">#会返回一个容器的id</span></span><br><span class="line">[root@node3 ~]<span class="comment"># docker run -d -p 80:80 nginx</span></span><br><span class="line">199b29ec5a2732e9c87b6557fa8aed66c4b0f5ef45bd91dd04a38510a7be55ca</span><br><span class="line"></span><br><span class="line"><span class="comment">#7.查看容器是否在运行</span></span><br><span class="line">docker ps</span><br><span class="line">[root@node3 ~]<span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID   IMAGE     COMMAND                   CREATED          STATUS          PORTS                               NAMES</span><br><span class="line">199b29ec5a27   nginx     <span class="string">&quot;/docker-entrypoint.…&quot;</span>   14 seconds ago   Up 13 seconds   0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp   affectionate_panini</span><br><span class="line"></span><br><span class="line"><span class="comment">#8.访问网站</span></span><br><span class="line">192.168.88.163:80</span><br><span class="line"></span><br><span class="line"><span class="comment">#9.停止容器</span></span><br><span class="line">docker stop 容器<span class="built_in">id</span></span><br><span class="line">docker stop 199b29ec5a27</span><br><span class="line">[root@node3 ~]<span class="comment"># docker stop 199b29ec5a27</span></span><br><span class="line">199b29ec5a27</span><br><span class="line"></span><br><span class="line"><span class="comment">#10.恢复容器</span></span><br><span class="line">docker start 199b29ec5a27</span><br></pre></td></tr></table></figure>

<img src=".\assets\image-20230206000042136.png" alt="image-20230206000042136" style="zoom: 67%;" />

<h3 id="（2）docker生命周期"><a href="#（2）docker生命周期" class="headerlink" title="（2）docker生命周期"></a>（2）<strong>docker生命周期</strong></h3><p><img src="/.%5Cassets%5Cimage-20230206134540197.png" alt="image-20230206134540197"></p>
<h3 id="（3）彻底学明白docker镜像的原理"><a href="#（3）彻底学明白docker镜像的原理" class="headerlink" title="（3）彻底学明白docker镜像的原理"></a>（3）彻底学明白docker镜像的原理</h3><h4 id="1-我们用的centos7系统长什么样"><a href="#1-我们用的centos7系统长什么样" class="headerlink" title="1.我们用的centos7系统长什么样?"></a>1.我们用的centos7系统长什么样?</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">我们一直以来，使用vmware虚拟机，安装的系统，是一个完整的系统文件，包括2部分。</span><br><span class="line"></span><br><span class="line">-linux内核，作用是提供操作系统的基本功能，和机器硬件交互，读取磁盘数据，管理网络。（硬件交互）</span><br><span class="line"></span><br><span class="line">-centos7发行版，作用是提供软件功能，例如yum安装包管理等（软件交互）</span><br><span class="line"></span><br><span class="line">因此，linux内核+centos发行版，就组成了一个系统，让我们用户使用</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cassets%5Cimage-20230206140401819.png" alt="image-20230206140401819"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看发行版</span></span><br><span class="line"><span class="built_in">cat</span> /etc/redhat-release</span><br><span class="line">[root@node3 ~]<span class="comment"># cat /etc/redhat-release </span></span><br><span class="line">CentOS Linux release 7.9.2009 (Core)</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看内核</span></span><br><span class="line"><span class="built_in">uname</span> -r</span><br><span class="line">[root@node3 ~]<span class="comment"># uname -r</span></span><br><span class="line">3.10.0-1160.el7.x86_64</span><br><span class="line"></span><br><span class="line">是否有一个办法，可以灵活的替换发行版，让我们使用不同的[系统]?</span><br><span class="line"></span><br><span class="line"><span class="comment">##答：内核使用宿主机的内核，上行发行版可以自有替换--》这就是docker</span></span><br><span class="line"></span><br><span class="line">那么docker就实现了这个功能，技术手段就是dockerimages</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cassets%5Cimage-20230206141146364.png" alt="image-20230206141146364"></p>
<h4 id="2-快速实践，使用docker切换不同发行版，内核都是宿主机内核"><a href="#2-快速实践，使用docker切换不同发行版，内核都是宿主机内核" class="headerlink" title="2.快速实践，使用docker切换不同发行版，内核都是宿主机内核"></a>2.快速实践，使用docker切换不同发行版，内核都是宿主机内核</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.利用docker获取不同的发行版镜像</span></span><br><span class="line">docker pull centos:7.8.2003</span><br><span class="line">docker pull ubuntu</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.确认当前宿主机的发行版</span></span><br><span class="line"><span class="built_in">cat</span> /etc/redhat-release</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.运行centos:7.8.2003发行版本</span></span><br><span class="line"><span class="comment">#运行容器，且进入容器内部</span></span><br><span class="line"><span class="comment">#参数解释，-i 交互式命令操作 -t 开启一个终端 bash 进入容器后执行的命令</span></span><br><span class="line">docker run -it 镜像<span class="built_in">id</span> bash</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.查看容器内的发行版</span></span><br><span class="line"><span class="built_in">cat</span> /etc/redhat-release</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.退出容器空间</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#6.如果想切换至Ubuntu</span></span><br><span class="line">docker run -it ubuntu bash</span><br><span class="line"><span class="built_in">cat</span> /etc/lsb-release</span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#小结：</span></span><br><span class="line">1.一个完整的系统，是由linux的内核+发行版，才组成了一个可以使用的完整的系统</span><br><span class="line">2.利用docker容器，可以获取不同的发行版镜像，然后基于该镜像，运行出各种容器去使用</span><br></pre></td></tr></table></figure>

<h4 id="3-docker具体解决问题实例"><a href="#3-docker具体解决问题实例" class="headerlink" title="3.docker具体解决问题实例"></a>3.docker具体解决问题实例</h4><p>一个开发老王，写代码，mysql，etcd，redis，elk，等等等。。。</p>
<p>在机器上，直接安装这些工具，win，mac</p>
<p><img src="/.%5Cassets%5Cimage-20230206150021008.png" alt="image-20230206150021008"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">如果你直接在宿主机上，安装这些工具，那受限于宿主机的环境</span><br><span class="line">可能有哪些麻烦</span><br><span class="line">1.环境不兼容，比如软件需要运行在linux下，但是你是indows，只能去安装一个vmware虚拟机，或者再去买一个云服务器，安装</span><br><span class="line">2.会将你当前系统的环境，搞的一团糟</span><br><span class="line">3.比如你想卸载这些工具。。麻烦了，不会卸载。。</span><br><span class="line">docker彻底解决了老王的问题，以后可以不加班了。</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cassets%5Cimage-20230206150131475.png" alt="image-20230206150131475"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.解决了环境的兼容问题，在容器中运行linux发行版，以及各种软件， [windows+docker+容器1 centos)+容器2(ubuntu)]</span><br><span class="line">2.环境很干净，你安装的所有内容，都在容器里，不想要了，就直接删除容器，不影响你宿主机</span><br><span class="line">3.比如你想把mysal容器内的数据，配置，全部迁移到服务器上，只需要提交该容器，生成镜像，镜像放到服务器上，docker run，就运行了!</span><br></pre></td></tr></table></figure>



<h4 id="4-docker镜像原理-1"><a href="#4-docker镜像原理-1" class="headerlink" title="4.docker镜像原理(1)"></a>4.docker镜像原理(1)</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#docker images搜索地址</span></span><br><span class="line"><span class="comment">#https://hub.docker.com/_/centos?tab=tags&amp;page=1&amp;ordering=last_updated</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##我们在获取redis镜像的时候，发现下载了多行信息，最终仅得到了一个完整的镜像文件</span></span><br><span class="line"></span><br><span class="line">[root@node3 ~]<span class="comment"># docker pull redis</span></span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/redis</span><br><span class="line">a2abf6c4d29d: Already exists </span><br><span class="line">c7a4e4382001: Pull complete </span><br><span class="line">4044b9ba67c9: Pull complete </span><br><span class="line">c8388a79482f: Pull complete </span><br><span class="line">413c8bb60be2: Pull complete </span><br><span class="line">1abfd3011519: Pull complete </span><br><span class="line">Digest: sha256:db485f2e245b5b3329fdc7eff4eb00f913e09d8feb9ca720788059fdc2ed8339</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> redis:latest</span><br><span class="line">docker.io/library/redis:latest</span><br><span class="line"></span><br><span class="line">[root@node3 ~]<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY   TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">nginx        latest    605c77e624dd   13 months ago   141MB</span><br><span class="line">redis        latest    7614ae9453d1   13 months ago   113MB</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>dockerfile 去构建这个镜像 特点就是一层一层的构建</strong></p>
<p><img src="/.%5Cassets%5Cimage-20230206153010970.png" alt="image-20230206153010970"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Union File System</span></span><br><span class="line"><span class="comment">#docker通过联合文件系统，将上述的不同的每一层，整合为一个文件系统,为用户隐藏了多层的视角</span></span><br><span class="line"><span class="comment">#docker iamges</span></span><br><span class="line"><span class="comment">#docker run 镜像id</span></span><br><span class="line"></span><br><span class="line">小结:</span><br><span class="line">1.当通过一个image启动容器时，docker会在该image最顶层，添加一个读写文件系统作为容器，然后运行该容器</span><br><span class="line">2.docker镜像本质是基于UnionFS管理的分层文件系统</span><br><span class="line">3.docker镜像为什么才几百兆?</span><br><span class="line">答:因为docker镜像只有rootfs和其他镜像层，共用宿主机的linux内核 (bootfs)，因此很小!</span><br><span class="line">4.为什么下载一个docker的nginx镜像，需要133MB? nginx安装包不是才几兆吗?</span><br><span class="line">答:因为docker的nginx镜像是分层的，nginx安装包的确就几M，但是一个用于运行nginx的像文件，依赖于父镜像(上一层)，和基础像(发行版)，所以下载的nginx镜像有一百多兆</span><br><span class="line"></span><br><span class="line"><span class="comment">#eg：基于nginx镜像，运行处一个nginx的容器nginx是一个软件，必须依赖于操作系统才能运行</span></span><br><span class="line"><span class="comment">#1.用的是 windows 宿主机，但是提供了内核</span></span><br><span class="line"><span class="comment">#2.利用 docker 下载镜像，(镜像提供了发行版，centos)</span></span><br><span class="line"><span class="comment">#3.该nginx就可以运行在该 centos 发行版环境中了</span></span><br><span class="line"><span class="comment">#因此这个结构形式是 win+ [docker+centos+nginx]</span></span><br></pre></td></tr></table></figure>

<h4 id="5-docker镜像原理-2"><a href="#5-docker镜像原理-2" class="headerlink" title="5.docker镜像原理(2)"></a>5.docker镜像原理(2)</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#我们如果自定义镜像，刚才已经讲过，docker镜像不包含linux内核，和宿主机共用。</span></span><br><span class="line"><span class="comment">#我们如果想要定义一个mysql5.6镜像，我们会这么做</span></span><br><span class="line">- 获取基础镜像，选择一个发行版平台 (ubutu，centos)</span><br><span class="line">- 在centos镜像中安装mysql5.6软件</span><br><span class="line"></span><br><span class="line">导出镜像，可以命名为mysql:5.6镜像文件</span><br><span class="line">从这个过程，我们可以感觉出这是一层一层的添加的，docker镜像的层级概念就出来了，底层是centos镜像，上层是mysql镜像，centos镜像层属于父镜像。</span><br></pre></td></tr></table></figure>

<p><img src="/.%5Cassets%5Cimage-20230206170048363.png" alt="image-20230206170048363"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Docker镜像是在基础镜像之后，然后安装软件，配置软件添加新的层，构建出来。</span><br><span class="line">这种现象在学习dockerfile构建时候，更为清晰。</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#实例</span></span><br><span class="line"><span class="comment">#进入正在运行的容器内，命令式docker exec</span></span><br><span class="line">docker <span class="built_in">exec</span> -it 容器<span class="built_in">id</span> bash</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> /etc/os-release</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="（1）docker为什么要分层镜像"><a href="#（1）docker为什么要分层镜像" class="headerlink" title="（1）docker为什么要分层镜像"></a>（1）docker为什么要分层镜像</h5><p>镜像分享一大好处就是共享资源，例如有多个镜像都来自于同一个base镜像，那么在docker host只需要存储一份base镜像。</p>
<p>内存里也只需要加载一份host，即可为多个容器服务</p>
<p>即使多个容器共享一个base镜像，某个容器修改了base镜像的内容，例如修改&#x2F;etc&#x2F;下配置文件，其他容器的&#x2F;etc&#x2F;下内容是不会被修改的，修改动作只限制在单个容器内，这就是容器的写入时复制特性 (Copy-on-write)</p>
<p><img src="/.%5Cassets%5Cimage-20230206171151486.png" alt="image-20230206171151486"></p>
<h5 id="（2）可写的容器层和只读的镜像层"><a href="#（2）可写的容器层和只读的镜像层" class="headerlink" title="（2）可写的容器层和只读的镜像层"></a>（2）可写的容器层和只读的镜像层</h5><p>当容器启动后，一个新的可写层被加载到镜像的顶部，这一层通常被称为 容器层，容器层下的都称为 镜像层。</p>
<img src=".\assets\image-20230206171324713.png" alt="image-20230206171324713" style="zoom:67%;" />

<p>所有对容器的修改动作，都只会发生在 容器层 里，只有 容器层 是可写的，其余 镜像层 都是只读的。</p>
<p><img src="/.%5Cassets%5Cimage-20230206171404547.png" alt="image-20230206171404547"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。</span><br><span class="line">这样就解释了我们前面提出的问题: 容器层记录对镜像的修改，所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。</span><br></pre></td></tr></table></figure>

<h5 id="（3）docker镜像的内容"><a href="#（3）docker镜像的内容" class="headerlink" title="（3）docker镜像的内容"></a>（3）docker镜像的内容</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker镜像层级管理的方式大大便捷了Docker镜像的分发和存储。</span><br><span class="line"><span class="comment">#Docker hub是为全世界的镜像仓库。</span></span><br><span class="line">-Docker镜像代表一个容器的文件系统内容</span><br><span class="line">-镜像层级技术属于 联合文件系统</span><br><span class="line">-容器是一个动态的环境，每一层镜像里的文件都属于静态内容。 </span><br><span class="line">  -dockerfile里的ENV、VOLUME、CMD等内容都会落实到容器环境里</span><br></pre></td></tr></table></figure>

<h5 id="（4）UnionFS"><a href="#（4）UnionFS" class="headerlink" title="（4）UnionFS"></a>（4）UnionFS</h5><img src="assets\image-20230206171659108.png" alt="image-20230206171659108" style="zoom:67%;" />

<h2 id="2-1-镜像操作"><a href="#2-1-镜像操作" class="headerlink" title="2.1.镜像操作"></a>2.1.镜像操作</h2><h3 id="2-1-1-镜像名称"><a href="#2-1-1-镜像名称" class="headerlink" title="2.1.1.镜像名称"></a>2.1.1.镜像名称</h3><p>首先来看下镜像的名称组成：</p>
<ul>
<li>镜名称一般分两部分组成：[repository]:[tag]。</li>
<li>在没有指定tag时，默认是latest，代表最新版本的镜像</li>
</ul>
<p>如图：</p>
<img src="assets/image-20210731155141362.png" alt="image-20210731155141362" style="zoom: 33%;" />

<p>这里的<code>mysql就是repository</code>，<code>5.7就是tag</code>，合一起就是镜像名称，代表5.7版本的MySQL镜像。</p>
<p><img src="/assets/image-20210731155649535.png" alt="image-20210731155649535"></p>
<h3 id="2-1-2-获取镜像"><a href="#2-1-2-获取镜像" class="headerlink" title="2.1.2 获取镜像"></a>2.1.2 获取镜像</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.从dockerhub获取镜像</span><br><span class="line">2.本地镜像导入导出</span><br><span class="line">3.私有的docker仓库</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.获取镜像，镜像托管仓库，好比yum源一样</span></span><br><span class="line"><span class="comment"># 默认的docker仓库是，dockerhub ，有大量的优质的镜像，以及用户自己上传的镜像 centos容器 vim nginx 。。提交为镜像，上传到dockehub</span></span><br><span class="line"></span><br><span class="line">docker search 镜像名:tag tag就是具体的标签版本</span><br><span class="line">docker search centos</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.查看本地的镜像文件有哪些</span></span><br><span class="line"> docker images </span><br><span class="line"> docker image <span class="built_in">ls</span></span><br><span class="line"><span class="comment">#3.下载docker镜像</span></span><br><span class="line">docker pull centos <span class="comment"># 默认的是 centos:latest</span></span><br><span class="line">docker pull centos:7.8.2003</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.查看docker镜像的存储路径</span></span><br><span class="line">docker info |grep Root</span><br><span class="line"><span class="comment">#Docker Root Dir: /var/lib/docker</span></span><br><span class="line"><span class="comment">#具体位置</span></span><br><span class="line"><span class="built_in">ls</span> /var/lib/docker/image/overlay2/imagedb/content/sha256</span><br><span class="line"></span><br><span class="line">[root@node3 ~]<span class="comment"># ls /var/lib/docker/image/overlay2/imagedb/content/sha256</span></span><br><span class="line">5d9483f9a7b21c87e0f5b9776c3e06567603c28c0062013eda127c968175f5e8</span><br><span class="line">605c77e624ddb75e6110f997c58876baa13f8754486b461117934b24a9dc3a85</span><br><span class="line">7614ae9453d1d87e740a2056257a6de7135c84037c367e1fffa92ae922784631</span><br><span class="line"></span><br><span class="line">[root@node3 ~]<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY   TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">nginx        latest    605c77e624dd   13 months ago   141MB</span><br><span class="line">redis        latest    7614ae9453d1   13 months ago   113MB</span><br><span class="line">mysql        5.7.29    5d9483f9a7b2   2 years ago     455MB</span><br><span class="line"><span class="comment">#5.该文件作用是</span></span><br><span class="line">记录 镜像 和容器的配置关系</span><br><span class="line"><span class="comment"># 使用不同的镜像，生成容器# -it 开启一个交互式的终端--rm 容器退出时删除该容器</span></span><br><span class="line"><span class="comment">#再运行一个7.8centos</span></span><br><span class="line">docker run -it --<span class="built_in">rm</span> centos bash</span><br></pre></td></tr></table></figure>

<h3 id="2-1-3-查看镜像"><a href="#2-1-3-查看镜像" class="headerlink" title="2.1.3 查看镜像"></a>2.1.3 查看镜像</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.查看所有镜像</span></span><br><span class="line">docker images</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.查看具体镜像</span></span><br><span class="line">docker images nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.指定tag查看</span></span><br><span class="line">docker images centos:7.8.2003</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.只列出镜像id</span></span><br><span class="line">-q --quiet 只列出<span class="built_in">id</span></span><br><span class="line">docker images -q</span><br><span class="line">[root@node3 ~]<span class="comment"># docker images -q</span></span><br><span class="line">605c77e624dd</span><br><span class="line">7614ae9453d1</span><br><span class="line">5d9483f9a7b2</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.格式化显示镜像</span></span><br><span class="line"><span class="comment"># 这是docker的模板语言，--format</span></span><br><span class="line">docker images --format <span class="string">&quot;&#123;&#123;.ID&#125;&#125;--&#123;&#123;.Repository&#125;&#125;&quot;</span></span><br><span class="line">[root@node3 ~]<span class="comment"># docker images --format &quot;&#123;&#123;.ID&#125;&#125;--&#123;&#123;.Repository&#125;&#125;&quot;</span></span><br><span class="line">605c77e624dd--nginx</span><br><span class="line">7614ae9453d1--redis</span><br><span class="line">5d9483f9a7b2--mysql</span><br><span class="line"></span><br><span class="line"><span class="comment">#6.搜索镜像</span></span><br><span class="line">docker search 镜像名</span><br></pre></td></tr></table></figure>

<h3 id="2-1-4-删除镜像"><a href="#2-1-4-删除镜像" class="headerlink" title="2.1.4 删除镜像"></a>2.1.4 删除镜像</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.如果觉得docker下载速度较慢，可使用下面命令更换docker加速器</span></span><br><span class="line"><span class="comment"># curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io</span></span><br><span class="line"></span><br><span class="line">docker version &gt;= 1.12</span><br><span class="line">&#123;<span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;http://f1361db2.m.daocloud.io&quot;</span>]&#125;</span><br><span class="line">Success.</span><br><span class="line">You need to restart docker to take effect: sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line">systemctl restart docker</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.下载 体积较小的hello-world镜像进行验证</span></span><br><span class="line">docker pull hello-world</span><br><span class="line"><span class="comment">#根据镜像的 id，名字，摘要等</span></span><br><span class="line"><span class="comment">#被删除的镜像，不得有依赖的容器记录docker rmi hello-world</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#3.删除容器记录</span></span><br><span class="line">docker <span class="built_in">rm</span> 容器<span class="built_in">id</span></span><br><span class="line"><span class="comment">#4.指定id的前三位即可</span></span><br><span class="line">docker rmi 镜像<span class="built_in">id</span></span><br></pre></td></tr></table></figure>

<h3 id="2-1-5-镜像管理"><a href="#2-1-5-镜像管理" class="headerlink" title="2.1.5 镜像管理"></a>2.1.5 镜像管理</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1.批量删除镜像，慎用</span></span><br><span class="line">docker rmi &#x27;docker images -aq&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2.批量删除容器</span></span><br><span class="line">docker rm &#x27;docker ps -aq&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">3.导出镜像</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">比如默认运行的centos镜像，不提供vim功能，运行该容器后，在容器内安装vim</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">然后提交该镜像，再导出该镜像为压缩文件，可以发给其他人用</span></span><br><span class="line">docker commit --&gt;后续讲解</span><br><span class="line"></span><br><span class="line">docker image save centos:7.8.2003 &gt; /export/software/centos1.8.2003.tgz</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">或者</span></span><br><span class="line">docker save -o [保存的目标文件名称] [镜像名称]</span><br><span class="line">docker save -o nginx.tgz nginx:latest</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">4.导入镜像</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">先删除本地的nginx镜像：</span></span><br><span class="line">docker rmi centos:7.8.2003</span><br><span class="line">docker image load -i /export/software/centos1.8.2003.tgz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">5.查看cocker服务的信息</span></span><br><span class="line">docker info</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">6.查看镜像详细信息</span></span><br><span class="line">docker image inspact 镜像id</span><br></pre></td></tr></table></figure>


<p><img src="/assets/image-20210731161354344.png" alt="image-20210731161354344"></p>
<h3 id="2-1-6-练习"><a href="#2-1-6-练习" class="headerlink" title="2.1.6 练习"></a>2.1.6 练习</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">需求：去DockerHub搜索并拉取一个Redis镜像</span><br><span class="line">目标：</span><br><span class="line">1）去DockerHub搜索Redis镜像</span><br><span class="line">2）查看Redis镜像的名称和版本</span><br><span class="line">3）利用docker pull命令拉取镜像</span><br><span class="line">4）利用docker save命令将 redis:latest打包为一个redis.tar包</span><br><span class="line">5）利用docker rmi 删除本地的redis:latest</span><br><span class="line">6）利用docker load 重新加载 redis.tar文件</span><br></pre></td></tr></table></figure>



<h2 id="2-2-容器操作"><a href="#2-2-容器操作" class="headerlink" title="2.2.容器操作"></a>2.2.容器操作</h2><h3 id="2-2-1-容器相关命令"><a href="#2-2-1-容器相关命令" class="headerlink" title="2.2.1.容器相关命令"></a>2.2.1.容器相关命令</h3><h5 id="（1）容器基本命令"><a href="#（1）容器基本命令" class="headerlink" title="（1）容器基本命令"></a>（1）容器基本命令</h5><p>容器操作的命令如图：</p>
<img src="assets/image-20210731161950495.png" alt="image-20210731161950495" style="zoom: 33%;" />

<p><code>容器保护三个状态：</code></p>
<ul>
<li><code>运行：进程正常运行</code></li>
<li><code>暂停：进程暂停，CPU不再运行，并不释放内存</code></li>
<li><code>停止：进程终止，回收进程占用的内存、CPU等资源</code></li>
</ul>
<p><code>其中：</code></p>
<ul>
<li><p><code>docker run</code>：创建并运行一个容器，处于运行状态</p>
</li>
<li><p><code>docker pause</code>：让一个运行的容器暂停</p>
</li>
<li><p><code>docker unpause</code>：让一个容器从暂停状态恢复运行</p>
</li>
<li><p><code>docker stop</code>：停止一个运行的容器</p>
</li>
<li><p><code>docker start</code>：让一个停止的容器再次运行</p>
</li>
<li><p><code>docker rm</code>：删除一个容器</p>
</li>
</ul>
<h5 id="（2）容器初体验"><a href="#（2）容器初体验" class="headerlink" title="（2）容器初体验"></a>（2）容器初体验</h5><p><code>docker run</code> 等于创建+启动</p>
<blockquote>
<p>docker run镜像名，如果镜像不存在本地，则会去在线下载该镜像</p>
</blockquote>
<blockquote>
<p><code>注意</code>:容器内的进程必须处于前台运行状态，否则容器就会直接退出，自己部署一个容器运行，命令不得后台运行，前台运行即可</p>
<p>如果容器内，什么事也没做，容器也会挂掉，<code>容器内，必须有一个进程在前台运行</code></p>
<p>我们运行nginx基础镜像，没有运行任何程序，因此容器直接挂掉</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#运行容器的玩法</span></span><br><span class="line"><span class="comment">#1.运行一个挂掉的容器（从错误示范学起）</span></span><br><span class="line">docker run centos:7.8:2003</span><br><span class="line"><span class="comment">#这个写法会产生多个独立的容器记录，且容器内没有程序在跑，因此挂了</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.运行容器，且进入容器内，且在容器内执行某个命令</span></span><br><span class="line">[root@node1 ~]<span class="comment"># docker run -it centos:7.8.2003 sh</span></span><br><span class="line">sh-4.2<span class="comment">#</span></span><br><span class="line">sh-4.2<span class="comment">#</span></span><br><span class="line">sh-4.2<span class="comment"># cat /etc/redhat-release</span></span><br><span class="line">Centos Linux release 7.8.2003 (Core)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.开启一个容器，让它帮你运行某个程序，属于前台运行，会卡住一个终端</span></span><br><span class="line">[root@node1 ~]<span class="comment"># docker run centos:7.8.2003 ping baidu.com</span></span><br><span class="line">PING baidu.com (198.18,0.13) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.运行一个活着的容器，docker ps可以看到的容器</span></span><br><span class="line"><span class="comment"># -d 参数，让容器在后台跑着 (针对宿主机而言)</span></span><br><span class="line"><span class="comment"># 返回容器id</span></span><br><span class="line">docker run -d centos:7.8.2003 ping baidu.com</span><br><span class="line">608dd314f21c931c35c2a0ebf29b021c7634dfd26e4d757cf542f0eff6c64727</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.丰富docker运行的参数</span></span><br><span class="line"><span class="comment"># -d 后台运行</span></span><br><span class="line"><span class="comment"># --rm 容器挂掉后自动被删除</span></span><br><span class="line"><span class="comment"># --name 给容器起个名字</span></span><br><span class="line">[root@node1 ~]<span class="comment"># docker run -d --rm --name pythonav centos:7.8.2003 pingpythonav.cn</span></span><br><span class="line">e3a7f6a7d0c6902d6af565b4bb9cf81a62d4840bbac978105b6d8da233f532a5</span><br><span class="line">[root@node1 ~]<span class="comment"># docker ps</span></span><br><span class="line">CONTAINER 		IDIMAGE			COMMAND			CREATED				STATUS</span><br><span class="line">PORTS		NAMES</span><br><span class="line">e3a7f6a7d0c6 centos:7.8.2003	<span class="string">&quot;ping pythonav.cn&quot;</span>	5 seconds ago	  Up 5 seconds	 		pythonav</span><br><span class="line"></span><br><span class="line"><span class="comment">#6.查看容器日志的玩法，刷新日志</span></span><br><span class="line"><span class="comment"># docker logs -f 容器id</span></span><br><span class="line">docker logs -f f2598cb26363</span><br><span class="line"><span class="comment">#查看最后五条</span></span><br><span class="line">docker logs f2598cb26363 | <span class="built_in">tail</span> -5</span><br><span class="line"></span><br><span class="line"><span class="comment">#7.进入正在运行的容器空间内</span></span><br><span class="line"><span class="comment">#exec指令用于进入容器空间内</span></span><br><span class="line">docker <span class="built_in">exec</span> -it f2598cb26363 bash</span><br><span class="line"></span><br><span class="line"><span class="comment">#8.查看容器的详细信息，用于高级的调试</span></span><br><span class="line">docker container inspect 容器<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 9.容器的端口映射</span></span><br><span class="line"><span class="comment"># 后台运行nginx容器，且起个名字，且端口映射宿主机的80端口，访问到容器内的80端口</span></span><br><span class="line">docker run -d --name bigdata_nginx -p 85:80 nginx</span><br><span class="line"><span class="comment"># 查看容器</span></span><br><span class="line">[root@yc_docker81 ~]<span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID	IMAGE	COMMAND		CREATED		STATUS		PORTS	NAMES</span><br><span class="line">2e73fac44507	nginx	<span class="string">&quot;/docker-entrypoint ....&quot;</span>  5 seconds ago	Up 4 seconds</span><br><span class="line">0.0.0.0:80-&gt;80/tcp,:::80-&gt;80/tcp  bigdata_nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#9.1查看容器的端口转发情况</span></span><br><span class="line">docker port 容器<span class="built_in">id</span></span><br><span class="line"><span class="comment"># docker port 2e73fac44507</span></span><br><span class="line">80/tcp -&gt; 0.0.0.0:85</span><br><span class="line">80/tcp -&gt; :::85</span><br><span class="line"></span><br><span class="line"><span class="comment">#9.2随机端口映射 -P 随机访问一个宿主机的空闲端口，映射到容器内打开的端口</span></span><br><span class="line">docker run -d --name bigdata_nginx_random -P nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#10.容器的提交</span></span><br><span class="line"><span class="comment"># 运行基础的centos:7.8.2003 ，在容器内安装vim，然后提交新的镜像</span></span><br><span class="line"><span class="comment">#新的镜像，再运行出的容器，默认就携带vim了</span></span><br><span class="line">[root@node1 ~]<span class="comment"># docker run -it centos:7.8.2003 bash</span></span><br><span class="line"><span class="comment">#提交容器</span></span><br><span class="line">docker commit 容器<span class="built_in">id</span> 新的镜像名</span><br><span class="line"></span><br><span class="line">[root@node1 ~]<span class="comment"># docker run -it bigdata163/centos-vim-7.8.2003 bash</span></span><br><span class="line">[root@f01fd5201723 /]<span class="comment"># vim xiake.txt</span></span><br><span class="line">[root@f01fd5201723 /]<span class="comment"># cat xiake.txt</span></span><br><span class="line">xin ku le peng you men ! xiake xiu xi !</span><br><span class="line"></span><br><span class="line"><span class="comment">#11.停止容器运行</span></span><br><span class="line">docker stop 容器<span class="built_in">id</span></span><br></pre></td></tr></table></figure>

<img src=".\assets\image-20230207155553757.png" alt="image-20230207155553757" style="zoom: 80%;" />





<h3 id="2-2-2-案例-创建并运行一个容器"><a href="#2-2-2-案例-创建并运行一个容器" class="headerlink" title="2.2.2 案例-创建并运行一个容器"></a>2.2.2 案例-创建并运行一个容器</h3><p>创建并运行nginx容器的命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name containerName -p 80:80 -d nginx</span><br></pre></td></tr></table></figure>

<p>命令解读：</p>
<ul>
<li>docker run ：创建并运行一个容器</li>
<li>–name : 给容器起一个名字，比如叫做mn</li>
<li>-p ：将宿主机端口与容器端口映射，冒号左侧是宿主机端口，右侧是容器端口</li>
<li>-d：后台运行容器</li>
<li>nginx：镜像名称，例如nginx</li>
</ul>
<p>这里的<code>-p</code>参数，是将容器端口映射到宿主机端口。</p>
<p>默认情况下，容器是隔离环境，我们直接访问宿主机的80端口，肯定访问不到容器中的nginx。</p>
<p>现在，将容器的80与宿主机的80关联起来，当我们访问宿主机的80端口时，就会被映射到容器的80，这样就能访问到nginx了：</p>
<img src="assets/image-20210731163255863.png" alt="image-20210731163255863" style="zoom:33%;" />



<h3 id="2-2-3案例-进入容器，修改文件"><a href="#2-2-3案例-进入容器，修改文件" class="headerlink" title="2.2.3案例-进入容器，修改文件"></a>2.2.3案例-进入容器，修改文件</h3><p><strong>需求</strong>：进入Nginx容器，修改HTML文件内容，添加“人工智能学院欢迎您”</p>
<p><strong>提示</strong>：进入容器要用到docker exec命令。</p>
<p><strong>步骤</strong>：</p>
<p>1）进入容器。进入我们刚刚创建的nginx容器的命令为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it mn bash</span><br></pre></td></tr></table></figure>

<p>命令解读：</p>
<ul>
<li><p>docker exec ：进入容器内部，执行一个命令</p>
</li>
<li><p>-it : 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互</p>
</li>
<li><p>mn ：要进入的容器的名称</p>
</li>
<li><p>bash：进入容器后执行的命令，bash是一个linux终端交互命令</p>
</li>
</ul>
<p>2）进入nginx的HTML所在目录 &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</p>
<p>容器内部会模拟一个独立的Linux文件系统，看起来如同一个linux服务器一样：</p>
<p><img src="/assets/image-20210731164159811.png" alt="image-20210731164159811"></p>
<p>nginx的环境、配置、运行文件全部都在这个文件系统中，包括我们要修改的html文件。</p>
<p>查看DockerHub网站中的nginx页面，可以知道nginx的html目录位置在<code>/usr/share/nginx/html</code></p>
<p>我们执行命令，进入该目录：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/share/nginx/html</span><br></pre></td></tr></table></figure>

<p> 查看目录下文件：</p>
<p><img src="/assets/image-20210731164455818.png" alt="image-20210731164455818"></p>
<p>3）修改index.html的内容</p>
<p>容器内没有vi命令，无法直接修改，我们用下面的命令来修改：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i -e <span class="string">&#x27;s#Welcome to nginx#人工智能学院欢迎您#g&#x27;</span> -e <span class="string">&#x27;s#&lt;head&gt;#&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;#g&#x27;</span> index.html</span><br></pre></td></tr></table></figure>

<p>在浏览器访问自己的虚拟机地址，例如我的是：<a href="http://192.168.88.163，即可看到结果：">http://192.168.88.163，即可看到结果：</a></p>
<h3 id="2-2-2-小结"><a href="#2-2-2-小结" class="headerlink" title="2.2.2.小结"></a>2.2.2.小结</h3><p>docker run命令的常见参数有哪些？</p>
<ul>
<li><code>--name</code>：指定容器名称</li>
<li><code>-p</code>：指定端口映射</li>
<li><code>-d</code>：让容器后台运行</li>
</ul>
<p>查看容器日志的命令：</p>
<ul>
<li><code>docker logs</code></li>
<li>添加<code>-f</code>参数可以持续查看日志</li>
</ul>
<p>查看容器状态：</p>
<ul>
<li><code>docker ps</code></li>
<li><code>docker ps -a </code>查看所有容器，包括已经停止的</li>
</ul>
<h2 id="2-3-数据卷（容器数据管理）"><a href="#2-3-数据卷（容器数据管理）" class="headerlink" title="2.3.数据卷（容器数据管理）"></a>2.3.数据卷（容器数据管理）</h2><p>在之前的nginx案例中，修改nginx的html页面时，需要进入nginx内部。并且因为没有编辑器，修改文件也很麻烦。</p>
<p>这就是因为容器与数据（容器内文件）耦合带来的后果。</p>
<img src="assets/image-20210731172440275.png" alt="image-20210731172440275" style="zoom: 33%;" />

<p>要解决这个问题，必须将数据与容器解耦，这就要用到数据卷了。</p>
<h3 id="2-3-1-什么是数据卷"><a href="#2-3-1-什么是数据卷" class="headerlink" title="2.3.1.什么是数据卷"></a>2.3.1.什么是数据卷</h3><p><strong>数据卷（volume）</strong>是一个虚拟目录，指向宿主机文件系统中的某个目录。</p>
<img src="assets/image-20210731173541846.png" alt="image-20210731173541846" style="zoom: 50%;" />

<p>一旦完成数据卷挂载，对容器的一切操作都会作用在数据卷对应的宿主机目录了。</p>
<p>这样，我们操作宿主机的<code>/var/lib/docker/volumes/html</code>目录，就等于操作容器内的<code>/usr/share/nginx/html</code>目录了</p>
<p><img src="/.%5Cassets%5Cimage-20230207170058954.png" alt="image-20230207170058954"></p>
<h3 id="2-3-2-数据集操作命令"><a href="#2-3-2-数据集操作命令" class="headerlink" title="2.3.2.数据集操作命令"></a>2.3.2.数据集操作命令</h3><p>数据卷操作的基本语法如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume [COMMAND]</span><br></pre></td></tr></table></figure>

<p><code>docker volume</code>命令是数据卷操作，根据命令后跟随的<code>command</code>来确定下一步的操作：</p>
<ul>
<li><code>create </code>创建一个<code>volume</code></li>
<li><code>inspect </code>显示一个或多个<code>volume</code>的信息</li>
<li><code>ls </code>列出所有的<code>volume</code></li>
<li><code>prune </code>删除未使用的<code>volume</code></li>
<li><code>rm </code>删除一个或多个指定的<code>volume</code></li>
</ul>
<h3 id="2-3-3-创建和查看数据卷"><a href="#2-3-3-创建和查看数据卷" class="headerlink" title="2.3.3.创建和查看数据卷"></a>2.3.3.创建和查看数据卷</h3><p><strong>需求</strong>：创建一个数据卷，并查看数据卷在宿主机的目录位置</p>
<p>① 创建数据卷</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume create html</span><br></pre></td></tr></table></figure>

<p>② 查看所有数据</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<p>结果：</p>
<p><img src="/assets/image-20210731173746910.png" alt="image-20210731173746910"></p>
<p>③ 查看数据卷详细信息卷</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume inspect html</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<p><img src="/assets/image-20210731173809877.png" alt="image-20210731173809877"></p>
<p>可以看到，我们创建的html这个数据卷关联的宿主机目录为<code>/var/lib/docker/volumes/html/_data</code>目录。</p>
<p><strong>小结</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">数据卷的作用：</span><br><span class="line"></span><br><span class="line">- 将容器与数据分离，解耦合，方便操作容器内数据，保证数据安全</span><br><span class="line"></span><br><span class="line">数据卷操作：</span><br><span class="line"></span><br><span class="line">- docker volume create：创建数据卷</span><br><span class="line">- docker volume ls：查看所有数据卷</span><br><span class="line">- docker volume inspect：查看数据卷详细信息，包括关联的宿主机目录位置</span><br><span class="line">- docker volume rm：删除指定数据卷</span><br><span class="line">- docker volume prune：删除所有未使用的数据卷</span><br></pre></td></tr></table></figure>



<h3 id="2-3-4-挂载数据卷"><a href="#2-3-4-挂载数据卷" class="headerlink" title="2.3.4.挂载数据卷"></a>2.3.4.挂载数据卷</h3><p>我们在创建容器时，可以通过 -v 参数来挂载一个数据卷到某个容器内目录，命令格式如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run \</span><br><span class="line">  -it</span><br><span class="line">  --name bigdata \</span><br><span class="line">  -v /export/data/docker-data/centos/:/root/data_container \</span><br><span class="line">  centos:7.8.2003 \</span><br></pre></td></tr></table></figure>

<p>这里的-v就是挂载数据卷的命令：</p>
<ul>
<li><code>-v /export/data/docker-data/centos/:/root/data_container</code> ：把<code>/export/data/docker-data/centos/</code>数据卷挂载到容器内的<code>/root/data_container</code>这个目录中</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意事项：</span><br><span class="line">1. 目录必须是绝对路径</span><br><span class="line">2. 如果目录不存在，会自动创建</span><br><span class="line">3. 可以挂载多个数据卷</span><br></pre></td></tr></table></figure>

<img src=".\assets\image-20230207173504996.png" alt="image-20230207173504996" style="zoom:67%;" />

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">实现多容器进行数据交换的方法</span><br><span class="line"></span><br><span class="line"><span class="comment">#1. 多个容器挂载同一个数据卷</span></span><br><span class="line"><span class="comment">#2. 数据卷容器</span></span><br></pre></td></tr></table></figure>

<img src=".\assets\image-20230207173246227.png" alt="image-20230207173246227" style="zoom:67%;" />

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">配置数据卷容器</span><br><span class="line"></span><br><span class="line"><span class="comment">#1.创建启动c3数据卷容器，使用–v 参数设置数据卷</span></span><br><span class="line"><span class="comment">#（这里-v /volume是容器目录，系统会自动分配一个宿主机数据卷目录）</span></span><br><span class="line">docker run –it --name=c3 –v /volume centos:7</span><br><span class="line"></span><br><span class="line"><span class="comment">#2. 创建启动c1 c2 容器，使用--volumes-from 参数设置数据卷</span></span><br><span class="line">docker run –it --name=c1 --volumes-from c3 centos:7</span><br><span class="line">docker run –it --name=c2 --volumes-from c3 centos:7</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">小结</span><br><span class="line">1.数据卷概念</span><br><span class="line">	•宿主机的一个目录或文件</span><br><span class="line">2.数据卷作用</span><br><span class="line">	•容器数据持久化</span><br><span class="line">	•客户端和容器数据交换</span><br><span class="line">	•容器间数据交换</span><br><span class="line">3.数据卷容器</span><br><span class="line">	•创建一个容器，挂载一个目录，让其他容器继承自该容器( --volume-from )。</span><br><span class="line">	•通过简单方式实现数据卷配置</span><br></pre></td></tr></table></figure>

<h3 id="2-3-5-案例-给nginx挂载数据卷"><a href="#2-3-5-案例-给nginx挂载数据卷" class="headerlink" title="2.3.5.案例-给nginx挂载数据卷"></a>2.3.5.案例-给nginx挂载数据卷</h3><p><strong>需求</strong>：创建一个nginx容器，修改容器内的html目录内的index.html内容</p>
<p><strong>分析</strong>：上个案例中，我们进入nginx容器内部，已经知道nginx的html目录所在位置<code>/usr/share/nginx/html</code> ，我们需要把这个目录挂载到<code>/export/data/docker-data/nginx-html/</code>这个数据卷上，方便操作其中的内容。</p>
<p><strong>提示</strong>：运行容器时使用 -v 参数挂载数据卷</p>
<p>步骤：</p>
<p>① 创建容器并挂载数据卷到容器内的HTML目录</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name mn -v /export/data/docker-data/nginx-html/:/usr/share/nginx/html -p 80:80 -d nginx</span><br></pre></td></tr></table></figure>

<p>② 进入html数据卷所在位置，并修改HTML内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看html数据卷的位置</span></span><br><span class="line">docker volume inspect /export/data/docker-data/nginx-html/</span><br><span class="line"><span class="comment"># 进入该目录</span></span><br><span class="line"><span class="built_in">cd</span> /export/data/docker-data/nginx-html/_data</span><br><span class="line"><span class="comment"># 修改文件</span></span><br><span class="line">vi index.html</span><br></pre></td></tr></table></figure>



<h3 id="2-3-6-案例-给MySQL挂载本地目录"><a href="#2-3-6-案例-给MySQL挂载本地目录" class="headerlink" title="2.3.6.案例-给MySQL挂载本地目录"></a>2.3.6.案例-给MySQL挂载本地目录</h3><p>容器不仅仅可以挂载数据卷，也可以直接挂载到宿主机目录上。关联关系如下：</p>
<ul>
<li>带数据卷模式：宿主机目录 –&gt; 数据卷 —&gt; 容器内目录</li>
<li>直接挂载模式：宿主机目录 —&gt; 容器内目录</li>
</ul>
<p>如图：</p>
<p><img src="/assets/image-20210731175155453.png" alt="image-20210731175155453"></p>
<p><strong>语法</strong>：</p>
<p>目录挂载与数据卷挂载的语法是类似的：</p>
<ul>
<li>-v [宿主机目录]:[容器内目录]</li>
<li>-v [宿主机文件]:[容器内文件]</li>
</ul>
<p><strong>需求</strong>：创建并运行一个MySQL容器，将宿主机目录直接挂载到容器</p>
<p>实现思路如下：</p>
<p>1）在将课前资料中的mysql.tar文件上传到虚拟机，通过load命令加载为镜像</p>
<p>2）创建目录&#x2F;tmp&#x2F;mysql&#x2F;data</p>
<p>3）创建目录&#x2F;tmp&#x2F;mysql&#x2F;conf，将课前资料提供的hmy.cnf文件上传到&#x2F;tmp&#x2F;mysql&#x2F;conf</p>
<p>4）去DockerHub查阅资料，创建并运行MySQL容器，要求：</p>
<p>① 挂载&#x2F;tmp&#x2F;mysql&#x2F;data到mysql容器内数据存储目录</p>
<p>② 挂载&#x2F;tmp&#x2F;mysql&#x2F;conf&#x2F;hmy.cnf到mysql容器的配置文件</p>
<p>③ 设置MySQL密码</p>
<h3 id="2-3-7-小结"><a href="#2-3-7-小结" class="headerlink" title="2.3.7.小结"></a>2.3.7.小结</h3><p>docker run的命令中通过 -v 参数挂载文件或目录到容器中：</p>
<ul>
<li><code>-v volume</code>名称:容器内目录</li>
<li><code>-v</code> 宿主机文件:容器内文</li>
<li><code>-v </code>宿主机目录:容器内目录</li>
</ul>
<p>数据卷挂载与目录直接挂载的</p>
<ul>
<li>数据卷挂载耦合度低，由docker来管理目录，但是目录较深，不好找</li>
<li>目录挂载耦合度高，需要我们自己管理目录，不过目录容易寻找查看</li>
</ul>
<h1 id="3-Docker应用部署"><a href="#3-Docker应用部署" class="headerlink" title="3.Docker应用部署"></a>3.Docker应用部署</h1><h3 id="（1）部署MySQL"><a href="#（1）部署MySQL" class="headerlink" title="（1）部署MySQL"></a>（1）部署MySQL</h3><ol>
<li>搜索mysql镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker search mysql</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>拉取mysql镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull mysql:5.6</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>创建容器，设置端口映射、目录映射</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/export/data/docker-data/目录下创建mysql目录用于存储mysql数据信息</span></span><br><span class="line">mkdir -p /export/data/docker-data/mysql</span><br><span class="line">cd /export/data/docker-data/mysql</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run -id \</span><br><span class="line">-p 3306:3306 \</span><br><span class="line">--name=bigdata_mysql \</span><br><span class="line">-v $PWD/conf:/etc/mysql/conf.d \</span><br><span class="line">-v $PWD/logs:/logs \</span><br><span class="line">-v $PWD/data:/var/lib/mysql \</span><br><span class="line">-e MYSQL_ROOT_PASSWORD=hadoop \</span><br><span class="line">mysql:5.7.29</span><br></pre></td></tr></table></figure>

<ul>
<li>参数说明：<ul>
<li><strong>-p 3306:3306</strong>：将容器的 3306 端口映射到宿主机的 33076端口。</li>
<li><strong>-v $PWD&#x2F;conf:&#x2F;etc&#x2F;mysql&#x2F;conf.d</strong>：将主机当前目录下的 conf&#x2F;my.cnf 挂载到容器的 &#x2F;etc&#x2F;mysql&#x2F;my.cnf。配置目录</li>
<li><strong>-v $PWD&#x2F;logs:&#x2F;logs</strong>：将主机当前目录下的 logs 目录挂载到容器的 &#x2F;logs。日志目录</li>
<li><strong>-v $PWD&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql</strong> ：将主机当前目录下的data目录挂载到容器的 &#x2F;var&#x2F;lib&#x2F;mysql 。数据目录</li>
<li><strong>-e MYSQL_ROOT_PASSWORD&#x3D;hadoop：</strong>初始化 root 用户的密码。</li>
</ul>
</li>
</ul>
<ol start="4">
<li>进入容器，操作mysql</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec –it bigdata_mysql /bin/bash</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>使用外部机器连接容器中的mysql</li>
</ol>
<p><img src="/.%5Cassets%5C1573636765632.png" alt="1573636765632"></p>
<h3 id="（2）部署Tomcat"><a href="#（2）部署Tomcat" class="headerlink" title="（2）部署Tomcat"></a>（2）部署Tomcat</h3><ol>
<li>搜索tomcat镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker search tomcat</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>拉取tomcat镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull tomcat</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>创建容器，设置端口映射、目录映射</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/root目录下创建tomcat目录用于存储tomcat数据信息</span></span><br><span class="line">mkdir ~/tomcat</span><br><span class="line">cd ~/tomcat</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -id --name=c_tomcat \</span><br><span class="line">-p 8080:8080 \</span><br><span class="line">-v $PWD:/usr/local/tomcat/webapps \</span><br><span class="line">tomcat </span><br></pre></td></tr></table></figure>

<ul>
<li><p>参数说明：</p>
<ul>
<li><p><strong>-p 8080:8080：</strong>将容器的8080端口映射到主机的8080端口</p>
<p><strong>-v $PWD:&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps：</strong>将主机中当前目录挂载到容器的webapps</p>
</li>
</ul>
</li>
</ul>
<ol start="4">
<li>使用外部机器访问tomcat</li>
</ol>
<p><img src="/.%5Cassets%5C1573649804623.png" alt="1573649804623"></p>
<h3 id="（3）部署Nginx"><a href="#（3）部署Nginx" class="headerlink" title="（3）部署Nginx"></a>（3）部署Nginx</h3><ol>
<li>搜索nginx镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker search nginx</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>拉取nginx镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>创建容器，设置端口映射、目录映射</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/root目录下创建nginx目录用于存储nginx数据信息</span></span><br><span class="line">mkdir ~/nginx</span><br><span class="line">cd ~/nginx</span><br><span class="line">mkdir conf</span><br><span class="line">cd conf</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在~/nginx/conf/下创建nginx.conf文件,粘贴下面内容</span></span><br><span class="line">vim nginx.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">user  nginx;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">error_log  /var/log/nginx/error.log warn;</span><br><span class="line">pid        /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span><br><span class="line">                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span><br><span class="line">                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    #gzip  on;</span><br><span class="line"></span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run -id --name=c_nginx \</span><br><span class="line">-p 80:80 \</span><br><span class="line">-v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf \</span><br><span class="line">-v $PWD/logs:/var/log/nginx \</span><br><span class="line">-v $PWD/html:/usr/share/nginx/html \</span><br><span class="line">nginx</span><br></pre></td></tr></table></figure>

<ul>
<li>参数说明：<ul>
<li><strong>-p 80:80</strong>：将容器的 80端口映射到宿主机的 80 端口。</li>
<li><strong>-v $PWD&#x2F;conf&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;nginx.conf</strong>：将主机当前目录下的 &#x2F;conf&#x2F;nginx.conf 挂载到容器的 :&#x2F;etc&#x2F;nginx&#x2F;nginx.conf。配置目录</li>
<li><strong>-v $PWD&#x2F;logs:&#x2F;var&#x2F;log&#x2F;nginx</strong>：将主机当前目录下的 logs 目录挂载到容器的&#x2F;var&#x2F;log&#x2F;nginx。日志目录</li>
</ul>
</li>
</ul>
<ol start="4">
<li>使用外部机器访问nginx</li>
</ol>
<p><img src="/.%5Cassets%5C1573652396669.png" alt="1573652396669"></p>
<h3 id="（4）部署Redis"><a href="#（4）部署Redis" class="headerlink" title="（4）部署Redis"></a>（4）部署Redis</h3><ol>
<li>搜索redis镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker search redis</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>拉取redis镜像</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull redis:5.0</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>创建容器，设置端口映射</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -id --name=c_redis -p 6379:6379 redis:5.0</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>使用外部机器连接redis</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-cli.exe -h 192.168.149.135 -p 6379</span><br></pre></td></tr></table></figure>



<h1 id="4-Dockerfile自定义镜像"><a href="#4-Dockerfile自定义镜像" class="headerlink" title="4.Dockerfile自定义镜像"></a>4.Dockerfile自定义镜像</h1><p>常见的镜像在DockerHub就能找到，但是我们自己写的项目就必须自己构建镜像了。</p>
<p>而要自定义镜像，就必须先了解镜像的结构才行。</p>
<h2 id="4-1-镜像结构"><a href="#4-1-镜像结构" class="headerlink" title="4.1.镜像结构"></a>4.1.镜像结构</h2><p>镜像是将应用程序及其需要的系统函数库、环境、配置、依赖打包而成。</p>
<p>我们以MySQL为例，来看看镜像的组成结构：</p>
<img src="assets/image-20210731175806273.png" alt="image-20210731175806273" style="zoom: 25%;" />



<p>简单来说，镜像就是在系统函数库、运行环境基础上，添加应用程序文件、配置文件、依赖文件等组合，然后编写好启动脚本打包在一起形成的文件。</p>
<p>我们要构建镜像，其实就是实现上述打包的过程。</p>
<h2 id="4-2-Dockerfile语法"><a href="#4-2-Dockerfile语法" class="headerlink" title="4.2.Dockerfile语法"></a>4.2.Dockerfile语法</h2><p>构建自定义的镜像时，并不需要一个个文件去拷贝，打包。</p>
<p>我们只需要告诉Docker，我们的镜像的组成，需要哪些BaseImage、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来Docker会帮助我们构建镜像。</p>
<p>而描述上述信息的文件就是Dockerfile文件。</p>
<p><strong>Dockerfile</strong>就是一个文本文件，其中包含一个个的**指令(Instruction)**，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。</p>
<img src="assets/image-20210731180321133.png" alt="image-20210731180321133" style="zoom:33%;" />



<p>更新详细语法说明，请参考官网文档： <a target="_blank" rel="noopener" href="https://docs.docker.com/engine/reference/builder">https://docs.docker.com/engine/reference/builder</a></p>
<h2 id="4-3-构建Java项目"><a href="#4-3-构建Java项目" class="headerlink" title="4.3.构建Java项目"></a>4.3.构建Java项目</h2><h3 id="4-3-1-基于Ubuntu构建Java项目"><a href="#4-3-1-基于Ubuntu构建Java项目" class="headerlink" title="4.3.1.基于Ubuntu构建Java项目"></a>4.3.1.基于Ubuntu构建Java项目</h3><p>需求：基于Ubuntu镜像构建一个新镜像，运行一个java项目</p>
<ul>
<li><p>步骤1：新建一个空文件夹docker-demo</p>
<p><img src="/assets/image-20210801101207444.png" alt="image-20210801101207444"></p>
</li>
<li><p>步骤2：拷贝课前资料中的docker-demo.jar文件到docker-demo这个目录</p>
<p><img src="/assets/image-20210801101314816.png" alt="image-20210801101314816"></p>
</li>
<li><p>步骤3：拷贝课前资料中的jdk8.tar.gz文件到docker-demo这个目录</p>
<p><img src="/assets/image-20210801101410200.png" alt="image-20210801101410200"></p>
</li>
<li><p>步骤4：拷贝课前资料提供的Dockerfile到docker-demo这个目录</p>
<p><img src="/assets/image-20210801101455590.png" alt="image-20210801101455590"></p>
<p>其中的内容如下：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定基础镜像</span></span><br><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">16.04</span></span><br><span class="line"><span class="comment"># 配置环境变量，JDK的安装目录</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_DIR=/usr/local</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝jdk和java项目的包</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> ./jdk8.tar.gz <span class="variable">$JAVA_DIR</span>/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> ./docker-demo.jar /tmp/app.jar</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装JDK</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">cd</span> <span class="variable">$JAVA_DIR</span> \</span></span><br><span class="line"><span class="language-bash"> &amp;&amp; tar -xf ./jdk8.tar.gz \</span></span><br><span class="line"><span class="language-bash"> &amp;&amp; <span class="built_in">mv</span> ./jdk1.8.0_144 ./java8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME=$JAVA_DIR/java8</span><br><span class="line"><span class="keyword">ENV</span> PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴露端口</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8090</span></span><br><span class="line"><span class="comment"># 入口，java项目的启动命令</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> java -jar /tmp/app.jar</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>步骤5：进入docker-demo</p>
<p>将准备好的docker-demo上传到虚拟机任意目录，然后进入docker-demo目录下</p>
</li>
<li><p>步骤6：运行命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t javaweb:1.0 .</span><br></pre></td></tr></table></figure></li>
</ul>
<p>最后访问 <a target="_blank" rel="noopener" href="http://192.168.150.101:8090/hello/count%EF%BC%8C%E5%85%B6%E4%B8%AD%E7%9A%84ip%E6%94%B9%E6%88%90%E4%BD%A0%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BAip">http://192.168.150.101:8090/hello/count，其中的ip改成你的虚拟机ip</a></p>
<h3 id="4-3-2-基于java8构建Java项目"><a href="#4-3-2-基于java8构建Java项目" class="headerlink" title="4.3.2.基于java8构建Java项目"></a>4.3.2.基于java8构建Java项目</h3><p>虽然我们可以基于Ubuntu基础镜像，添加任意自己需要的安装包，构建镜像，但是却比较麻烦。所以大多数情况下，我们都可以在一些安装了部分软件的基础镜像上做改造。</p>
<p>例如，构建java项目的镜像，可以在已经准备了JDK的基础镜像基础上构建。</p>
<p>需求：基于java:8-alpine镜像，将一个Java项目构建为镜像</p>
<p>实现思路如下：</p>
<ul>
<li><p>① 新建一个空的目录，然后在目录中新建一个文件，命名为Dockerfile</p>
</li>
<li><p>② 拷贝课前资料提供的docker-demo.jar到这个目录中</p>
</li>
<li><p>③ 编写Dockerfile文件：</p>
<ul>
<li><p>a ）基于java:8-alpine作为基础镜像</p>
</li>
<li><p>b ）将app.jar拷贝到镜像中</p>
</li>
<li><p>c ）暴露端口</p>
</li>
<li><p>d ）编写入口ENTRYPOINT</p>
<p>内容如下：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> java:<span class="number">8</span>-alpine</span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> ./app.jar /tmp/app.jar</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8090</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> java -jar /tmp/app.jar</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>④ 使用docker build命令构建镜像</p>
</li>
<li><p>⑤ 使用docker run创建容器并运行</p>
</li>
</ul>
<h2 id="4-4-小结"><a href="#4-4-小结" class="headerlink" title="4.4.小结"></a>4.4.小结</h2><p>小结：</p>
<ol>
<li><p>Dockerfile的本质是一个文件，通过指令描述镜像的构建过程</p>
</li>
<li><p>Dockerfile的第一行必须是FROM，从一个基础镜像来构建</p>
</li>
<li><p>基础镜像可以是基本操作系统，如Ubuntu。也可以是其他人制作好的镜像，例如：java:8-alpine</p>
</li>
</ol>
<h1 id="5-Docker-Compose"><a href="#5-Docker-Compose" class="headerlink" title="5.Docker-Compose"></a>5.Docker-Compose</h1><p>Docker Compose可以基于Compose文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器！</p>
<p><img src="/assets/image-20210731180921742.png" alt="image-20210731180921742"></p>
<h2 id="5-1-初识DockerCompose"><a href="#5-1-初识DockerCompose" class="headerlink" title="5.1.初识DockerCompose"></a>5.1.初识DockerCompose</h2><p>Compose文件是一个文本文件，通过指令定义集群中的每个容器如何运行。格式如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">version<span class="punctuation">:</span> <span class="string">&quot;3.8&quot;</span></span><br><span class="line"> services<span class="punctuation">:</span></span><br><span class="line">  mysql<span class="punctuation">:</span></span><br><span class="line">    image<span class="punctuation">:</span> mysql<span class="punctuation">:</span><span class="number">5.7</span><span class="number">.25</span></span><br><span class="line">    environment<span class="punctuation">:</span></span><br><span class="line">     MYSQL_ROOT_PASSWORD<span class="punctuation">:</span> <span class="number">123</span> </span><br><span class="line">    volumes<span class="punctuation">:</span></span><br><span class="line">     - <span class="string">&quot;/tmp/mysql/data:/var/lib/mysql&quot;</span></span><br><span class="line">     - <span class="string">&quot;/tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf&quot;</span></span><br><span class="line">  web<span class="punctuation">:</span></span><br><span class="line">    build<span class="punctuation">:</span> .</span><br><span class="line">    ports<span class="punctuation">:</span></span><br><span class="line">     - <span class="string">&quot;8090:8090&quot;</span></span><br></pre></td></tr></table></figure>

<p>上面的Compose文件就描述一个项目，其中包含两个容器：</p>
<ul>
<li>mysql：一个基于<code>mysql:5.7.25</code>镜像构建的容器，并且挂载了两个目录</li>
<li>web：一个基于<code>docker build</code>临时构建的镜像容器，映射端口时8090</li>
</ul>
<p>DockerCompose的详细语法参考官网：<a target="_blank" rel="noopener" href="https://docs.docker.com/compose/compose-file/">https://docs.docker.com/compose/compose-file/</a></p>
<p>其实DockerCompose文件可以看做是将多个docker run命令写到一个文件，只是语法稍有差异。</p>
<h2 id="5-2-安装DockerCompose"><a href="#5-2-安装DockerCompose" class="headerlink" title="5.2.安装DockerCompose"></a>5.2.安装DockerCompose</h2><p>参考课前资料</p>
<h4 id="1-下载"><a href="#1-下载" class="headerlink" title="1.下载"></a>1.下载</h4><p>Linux下需要通过命令下载：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`<span class="built_in">uname</span> -s`-`<span class="built_in">uname</span> -m` &gt; /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure>

<p>如果下载速度较慢，或者下载失败，可以使用课前资料提供的docker-compose文件：</p>
<p><img src="D:\222课程\spark+kafka教学文件\spark&kafka资料\容器化技术Docker精讲\day03-Docker\资料\assets\image-20210417133020614.png" alt="image-20210417133020614"></p>
<p>上传到<code>/usr/local/bin/</code>目录也可以。</p>
<h4 id="2-修改文件权限"><a href="#2-修改文件权限" class="headerlink" title="2.修改文件权限"></a>2.修改文件权限</h4><p>修改文件权限：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改权限</span></span><br><span class="line"><span class="built_in">chmod</span> +x /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure>

<h4 id="3-Base自动补全命令："><a href="#3-Base自动补全命令：" class="headerlink" title="3.Base自动补全命令："></a>3.Base自动补全命令：</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 补全命令</span></span><br><span class="line">curl -L https://raw.githubusercontent.com/docker/compose/1.29.1/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose</span><br></pre></td></tr></table></figure>

<p>如果这里出现错误，需要修改自己的hosts文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;199.232.68.133 raw.githubusercontent.com&quot;</span> &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure>

<h2 id="5-3-部署微服务集群"><a href="#5-3-部署微服务集群" class="headerlink" title="5.3.部署微服务集群"></a>5.3.部署微服务集群</h2><p><strong>需求</strong>：将之前学习的cloud-demo微服务集群利用DockerCompose部署</p>
<p><strong>实现思路</strong>：</p>
<p>① 查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件</p>
<p>② 修改自己的cloud-demo项目，将数据库、nacos地址都命名为docker-compose中的服务名</p>
<p>③ 使用maven打包工具，将项目中的每个微服务都打包为app.jar</p>
<p>④ 将打包好的app.jar拷贝到cloud-demo中的每一个对应的子目录中</p>
<p>⑤ 将cloud-demo上传至虚拟机，利用 docker-compose up -d 来部署</p>
<h3 id="5-3-1-compose文件"><a href="#5-3-1-compose文件" class="headerlink" title="5.3.1.compose文件"></a>5.3.1.compose文件</h3><p>查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件，而且每个微服务都准备了一个独立的目录：</p>
<p><img src="/assets/image-20210731181341330.png" alt="image-20210731181341330"></p>
<p>内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3.2&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">nacos:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nacos/nacos-server</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">MODE:</span> <span class="string">standalone</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8848:8848&quot;</span></span><br><span class="line">  <span class="attr">mysql:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql:5.7.25</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="number">123</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;$PWD/mysql/data:/var/lib/mysql&quot;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;$PWD/mysql/conf:/etc/mysql/conf.d/&quot;</span></span><br><span class="line">  <span class="attr">userservice:</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">./user-service</span></span><br><span class="line">  <span class="attr">orderservice:</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">./order-service</span></span><br><span class="line">  <span class="attr">gateway:</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">./gateway</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;10010:10010&quot;</span></span><br></pre></td></tr></table></figure>

<p>可以看到，其中包含5个service服务：</p>
<ul>
<li><code>nacos</code>：作为注册中心和配置中心<ul>
<li><code>image: nacos/nacos-server</code>： 基于nacos&#x2F;nacos-server镜像构建</li>
<li><code>environment</code>：环境变量<ul>
<li><code>MODE: standalone</code>：单点模式启动</li>
</ul>
</li>
<li><code>ports</code>：端口映射，这里暴露了8848端口</li>
</ul>
</li>
<li><code>mysql</code>：数据库<ul>
<li><code>image: mysql:5.7.25</code>：镜像版本是mysql:5.7.25</li>
<li><code>environment</code>：环境变量<ul>
<li><code>MYSQL_ROOT_PASSWORD: 123</code>：设置数据库root账户的密码为123</li>
</ul>
</li>
<li><code>volumes</code>：数据卷挂载，这里挂载了mysql的data、conf目录，其中有我提前准备好的数据</li>
</ul>
</li>
<li><code>userservice</code>、<code>orderservice</code>、<code>gateway</code>：都是基于Dockerfile临时构建的</li>
</ul>
<p>查看mysql目录，可以看到其中已经准备好了cloud_order、cloud_user表：</p>
<p><img src="/assets/image-20210801095205034.png" alt="image-20210801095205034"></p>
<p>查看微服务目录，可以看到都包含Dockerfile文件：</p>
<p><img src="/assets/image-20210801095320586.png" alt="image-20210801095320586"></p>
<p>内容如下：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> java:<span class="number">8</span>-alpine</span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> ./app.jar /tmp/app.jar</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> java -jar /tmp/app.jar</span></span><br></pre></td></tr></table></figure>





<h3 id="5-3-2-修改微服务配置"><a href="#5-3-2-修改微服务配置" class="headerlink" title="5.3.2.修改微服务配置"></a>5.3.2.修改微服务配置</h3><p>因为微服务将来要部署为docker容器，而容器之间互联不是通过IP地址，而是通过容器名。这里我们将order-service、user-service、gateway服务的mysql、nacos地址都修改为基于容器名的访问。</p>
<p>如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://mysql:3306/cloud_order?useSSL=false</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="number">123</span></span><br><span class="line">    <span class="attr">driver-class-name:</span> <span class="string">com.mysql.jdbc.Driver</span></span><br><span class="line">  <span class="attr">application:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">orderservice</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">nacos:</span></span><br><span class="line">      <span class="attr">server-addr:</span> <span class="string">nacos:8848</span> <span class="comment"># nacos服务地址</span></span><br></pre></td></tr></table></figure>



<h3 id="5-3-3-打包"><a href="#5-3-3-打包" class="headerlink" title="5.3.3.打包"></a>5.3.3.打包</h3><p>接下来需要将我们的每个微服务都打包。因为之前查看到Dockerfile中的jar包名称都是app.jar，因此我们的每个微服务都需要用这个名称。</p>
<p>可以通过修改pom.xml中的打包名称来实现，每个微服务都需要修改：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 服务打包的最终名称 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">finalName</span>&gt;</span>app<span class="tag">&lt;/<span class="name">finalName</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>打包后：</p>
<p><img src="/assets/image-20210801095951030.png" alt="image-20210801095951030"></p>
<h3 id="5-3-4-拷贝jar包到部署目录"><a href="#5-3-4-拷贝jar包到部署目录" class="headerlink" title="5.3.4.拷贝jar包到部署目录"></a>5.3.4.拷贝jar包到部署目录</h3><p>编译打包好的app.jar文件，需要放到Dockerfile的同级目录中。注意：每个微服务的app.jar放到与服务名称对应的目录，别搞错了。</p>
<p>user-service：</p>
<p><img src="/assets/image-20210801100201253.png" alt="image-20210801100201253"></p>
<p>order-service：</p>
<p><img src="/assets/image-20210801100231495.png" alt="image-20210801100231495"></p>
<p>gateway：</p>
<p><img src="/assets/image-20210801100308102.png" alt="image-20210801100308102"></p>
<h3 id="5-3-5-部署"><a href="#5-3-5-部署" class="headerlink" title="5.3.5.部署"></a>5.3.5.部署</h3><p>最后，我们需要将文件整个cloud-demo文件夹上传到虚拟机中，理由DockerCompose部署。</p>
<p>上传到任意目录：</p>
<p><img src="/assets/image-20210801100955653.png" alt="image-20210801100955653"></p>
<p>部署：</p>
<p>进入cloud-demo目录，然后运行下面的命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>







<h1 id="6-Docker镜像仓库"><a href="#6-Docker镜像仓库" class="headerlink" title="6.Docker镜像仓库"></a>6.Docker镜像仓库</h1><h2 id="6-1-搭建私有镜像仓库"><a href="#6-1-搭建私有镜像仓库" class="headerlink" title="6.1.搭建私有镜像仓库"></a>6.1.搭建私有镜像仓库</h2><p>参考课前资料《CentOS7安装Docker.md》</p>
<h3 id="Docker镜像仓库"><a href="#Docker镜像仓库" class="headerlink" title="Docker镜像仓库"></a>Docker镜像仓库</h3><p>搭建镜像仓库可以基于Docker官方提供的DockerRegistry来实现。</p>
<p>官网地址：<a target="_blank" rel="noopener" href="https://hub.docker.com/_/registry">https://hub.docker.com/_/registry</a></p>
<h4 id="1-简化版镜像仓库"><a href="#1-简化版镜像仓库" class="headerlink" title="1.简化版镜像仓库"></a>1.简化版镜像仓库</h4><p>Docker官方的Docker Registry是一个基础版本的Docker镜像仓库，具备仓库管理的完整功能，但是没有图形化界面。</p>
<p>搭建方式比较简单，命令如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">    --restart=always \</span><br><span class="line">    --name registry	\</span><br><span class="line">    -p 5000:5000 \</span><br><span class="line">    -v registry-data:/var/lib/registry \</span><br><span class="line">    registry</span><br></pre></td></tr></table></figure>

<p>命令中挂载了一个数据卷registry-data到容器内的&#x2F;var&#x2F;lib&#x2F;registry 目录，这是私有镜像库存放数据的目录。</p>
<p>访问<a target="_blank" rel="noopener" href="http://yourip:5000/v2/_catalog">http://YourIp:5000/v2/_catalog</a> 可以查看当前私有镜像服务中包含的镜像</p>
<h4 id="2-带有图形化界面版本"><a href="#2-带有图形化界面版本" class="headerlink" title="2.带有图形化界面版本"></a>2.带有图形化界面版本</h4><p>使用DockerCompose部署带有图象界面的DockerRegistry，命令如下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.0&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">registry</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./registry-data:/var/lib/registry</span></span><br><span class="line">  <span class="attr">ui:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">joxit/docker-registry-ui:static</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8080</span><span class="string">:80</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">REGISTRY_TITLE=传智教育私有仓库</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">REGISTRY_URL=http://registry:5000</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">registry</span></span><br></pre></td></tr></table></figure>

<h4 id="3-配置Docker信任地址"><a href="#3-配置Docker信任地址" class="headerlink" title="3.配置Docker信任地址"></a>3.配置Docker信任地址</h4><p>我们的私服采用的是http协议，默认不被Docker信任，所以需要做一个配置：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打开要修改的文件</span></span><br><span class="line">vi /etc/docker/daemon.json</span><br><span class="line"><span class="comment"># 添加内容：</span></span><br><span class="line"><span class="string">&quot;insecure-registries&quot;</span>:[<span class="string">&quot;http://192.168.150.101:8080&quot;</span>]</span><br><span class="line"><span class="comment"># 重加载</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="comment"># 重启docker</span></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>



<h2 id="6-2-推送、拉取镜像"><a href="#6-2-推送、拉取镜像" class="headerlink" title="6.2.推送、拉取镜像"></a>6.2.推送、拉取镜像</h2><p>推送镜像到私有镜像服务必须先tag，步骤如下：</p>
<p>① 重新tag本地镜像，名称前缀为私有仓库的地址：192.168.150.101:8080&#x2F;</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker tag nginx:latest 192.168.150.101:8080/nginx:1.0 </span><br></pre></td></tr></table></figure>



<p>② 推送镜像</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push 192.168.150.101:8080/nginx:1.0 </span><br></pre></td></tr></table></figure>



<p>③ 拉取镜像</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull 192.168.150.101:8080/nginx:1.0 </span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/19/Docker%E5%AE%9E%E7%94%A8%E7%AF%87/" data-id="clj254b6k000100ur0cmsfon9" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Day02：可视化ETL工具Kettle" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/14/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle/" class="article-date">
  <time class="dt-published" datetime="2023-06-14T00:06:25.681Z" itemprop="datePublished">2023-06-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/14/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle/">Kettle</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="可视化ETL工具Kettle"><a href="#可视化ETL工具Kettle" class="headerlink" title="可视化ETL工具Kettle"></a>可视化ETL工具Kettle</h1><h2 id="一、数据仓库与ETL"><a href="#一、数据仓库与ETL" class="headerlink" title="一、数据仓库与ETL"></a>一、数据仓库与ETL</h2><h3 id="1、数据仓库"><a href="#1、数据仓库" class="headerlink" title="1、数据仓库"></a>1、数据仓库</h3><ul>
<li>本质：专门针对于数据存储模型</li>
<li>实现：MySQL、Oracle、Hive……</li>
<li>应用：专门用于实现将各种各样数据进行统一化规范化的数据存储，为所有数据应用提供数据<ul>
<li>数据分析</li>
<li>数据挖掘</li>
<li>用户画像</li>
<li>推荐系统</li>
<li>风控系统</li>
</ul>
</li>
<li>特点<ul>
<li>本身不产生数据</li>
<li>本身也不使用数据</li>
<li>用于实现复杂数据的存储</li>
</ul>
</li>
<li>与数据库区别<ul>
<li>数据库：一般用于支撑业务数据的存储<ul>
<li>网站后台：用户数据、商品数据、订单数据</li>
</ul>
</li>
<li>数据仓库：专门为数据数据处理提供数据的<ul>
<li>业务数据</li>
<li>用户行为</li>
<li>爬虫数据</li>
<li>第三方数据</li>
<li>日志数据</li>
</ul>
</li>
</ul>
</li>
<li>问题<ul>
<li>数据种类非常的多，每一种数据的内容或者格式都不一样<ul>
<li>有结构化、有非结构化</li>
<li>有合法的，有非法的</li>
<li>有需要的，有不需要的</li>
</ul>
</li>
<li>MySQL是一个专门用于存储结构化数据的数据存储工具<ul>
<li>·结构化</li>
<li>需要</li>
<li>合法</li>
</ul>
</li>
<li>如何将各种各样的数据存储在MYSQL中？</li>
</ul>
</li>
<li>解决<ul>
<li>数据产生以后，不能直接放入数据仓库【MySQL】中存储</li>
<li>对原始数据进行一步预处理，将需要的、合法的数据放入数据仓库中</li>
<li>这一步预处理：ETL【数据清洗】</li>
</ul>
</li>
</ul>
<h3 id="2、ETL"><a href="#2、ETL" class="headerlink" title="2、ETL"></a>2、ETL</h3><ul>
<li>功能：实现数据的预处理，数据清洗过程，将原始数据经过ETL处理变成想要的数据，进行下一步的应用</li>
<li>实现<ul>
<li>抽取：读取需要处理的原始数据</li>
<li>转换：将原始数据转换为目标数据<ul>
<li>过滤：将不需要的数据过滤掉<ul>
<li>原始数据中有100列</li>
<li>实际需要30列</li>
<li>过滤掉70列</li>
</ul>
</li>
<li>补全：将需要用到的数据补全<ul>
<li>每一个访问网站或者APP时，会有一个IP地址</li>
<li>后台通过IP能获取到我们当前所在的国家、省份、城市</li>
</ul>
</li>
<li>转换：原始数据的格式不是我们想要的格式，转换为想要的格式<ul>
<li>原始数据：22&#x2F;Aug&#x2F;2020:12:20:35</li>
<li>|</li>
<li>|  转换</li>
<li>|</li>
<li>目标格式：2020-08-22  12:20:35</li>
</ul>
</li>
</ul>
</li>
<li>加载：将处理好的目标数据放入数据仓库中</li>
</ul>
</li>
</ul>
<h3 id="3、Kettle"><a href="#3、Kettle" class="headerlink" title="3、Kettle"></a>3、Kettle</h3><ul>
<li>功能：实现可视化ETL<ul>
<li>可视化：不用写复杂的代码程序，可以通过图形化的界面来实现数据的处理</li>
</ul>
</li>
<li>特点<ul>
<li>学习以及使用的成本比较低</li>
<li>功能非常强大</li>
</ul>
</li>
</ul>
<h2 id="二、Windows版本部署"><a href="#二、Windows版本部署" class="headerlink" title="二、Windows版本部署"></a>二、Windows版本部署</h2><h3 id="1、JDK安装配置"><a href="#1、JDK安装配置" class="headerlink" title="1、JDK安装配置"></a>1、JDK安装配置</h3><ul>
<li><p>安装JDK</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105223805.png" alt="image-20200722105223805"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105243800.png" alt="image-20200722105243800"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105303004.png" alt="image-20200722105303004"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105358146.png" alt="image-20200722105358146"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105506499.png" alt="image-20200722105506499"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105609566.png" alt="image-20200722105609566"></p>
</li>
<li><p>配置JDK环境变量</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105711385.png" alt="image-20200722105711385"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105732574.png" alt="image-20200722105732574"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105746214.png" alt="image-20200722105746214"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105855306.png" alt="image-20200722105855306"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722105933177.png" alt="image-20200722105933177"></p>
<ul>
<li><p>添加bin目录的位置</p>
<ul>
<li>第一种界面</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">;C:\Program Files\Java\jdk1.8.0_241\bin</span><br></pre></td></tr></table></figure>

<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722110139880.png" alt="image-20200722110139880"></p>
<ul>
<li>第二种界面</li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722110249007.png" alt="image-20200722110249007"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\Java\jdk1.8.0_241\bin</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>验证安装的结果</p>
<ul>
<li><p>在windows命令行执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722110511213.png" alt="image-20200722110511213"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722110534198.png" alt="image-20200722110534198"></p>
</li>
</ul>
<h3 id="2、Kettle安装启动"><a href="#2、Kettle安装启动" class="headerlink" title="2、Kettle安装启动"></a>2、Kettle安装启动</h3><ul>
<li><p>解压安装</p>
<ul>
<li>解压到一个不包含中文的路径中即可</li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722110833924.png" alt="image-20200722110833924"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722113554732.png" alt="image-20200722113554732"></p>
</li>
<li><p>启动</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722113631022.png" alt="image-20200722113631022"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722113730624.png" alt="image-20200722113730624"></p>
</li>
</ul>
<h2 id="三、Kettle使用"><a href="#三、Kettle使用" class="headerlink" title="三、Kettle使用"></a>三、Kettle使用</h2><h3 id="1、转换"><a href="#1、转换" class="headerlink" title="1、转换"></a>1、转换</h3><ul>
<li>功能：实现一个转换的程序<ul>
<li>输入：要读取什么数据进行转换</li>
<li>转换：要对数据怎么进行处理【过滤、补全、转换】</li>
<li>输出：要将处理好的数据保存到什么地方</li>
</ul>
</li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722114144063.png" alt="image-20200722114144063"></p>
<h3 id="2、作业"><a href="#2、作业" class="headerlink" title="2、作业"></a>2、作业</h3><ul>
<li><p>功能：将多个转换根据需求构建任务流</p>
<ul>
<li>任务流：很多个任务【每一个转换程序】根据自动运行的条件来运行就是任务流</li>
<li>实际工作中，一次要执行很多个转换任务，如何实现这些任务的自动化执行</li>
<li>自动运行<ul>
<li>第一种：定时运行<ul>
<li>每天的00:01分开始自动运行</li>
</ul>
</li>
<li>第二种：依赖关系<ul>
<li>A先运行，A运行成功，B就自动运行</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>举例</p>
<ul>
<li><p>转换1：实现对数据的过滤</p>
</li>
<li><p>转换2：实现对数据的补全</p>
</li>
<li><p>转换3：实现对数据的转换</p>
</li>
<li><p>作业：一个任务流</p>
<ul>
<li>转换1：每天00:10分自动运行</li>
<li>转换2：转换1运行成功，转换2就开始运行</li>
<li>转换3：转换2运行成功，转换3就开始运行</li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722114924436.png" alt="image-20200722114924436"></p>
</li>
</ul>
</li>
</ul>
<h2 id="四、实战案例一"><a href="#四、实战案例一" class="headerlink" title="四、实战案例一"></a>四、实战案例一</h2><h3 id="1、需求"><a href="#1、需求" class="headerlink" title="1、需求"></a>1、需求</h3><ul>
<li>将txt文件中的数据写入Excel表格中</li>
</ul>
<h3 id="2、分析"><a href="#2、分析" class="headerlink" title="2、分析"></a>2、分析</h3><ul>
<li>任务：一个转换程序<ul>
<li>输入：读取txt文件中内容</li>
<li>转换：不需要</li>
<li>输出：将内容加载到一个Excel文件中</li>
</ul>
</li>
</ul>
<h3 id="3、实现"><a href="#3、实现" class="headerlink" title="3、实现"></a>3、实现</h3><ul>
<li><p>step1：构建转换流程图</p>
<ul>
<li><p>新建一个转换任务</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722142250319.png" alt="image-20200722142250319"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722142310820.png" alt="image-20200722142310820"></p>
</li>
<li><p>将输入和输出拖入流程图的面板中</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722142458479.png" alt="image-20200722142458479"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722142542150.png" alt="image-20200722142542150"></p>
</li>
<li><p>连线</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722142722676.png" alt="image-20200722142722676"></p>
</li>
</ul>
</li>
<li><p>step2：配置输入</p>
<ul>
<li>关联文件</li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722143501694.png" alt="image-20200722143501694"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722143632745.png" alt="image-20200722143632745"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722143734940.png" alt="image-20200722143734940"></p>
<ul>
<li><p>配置文件的格式</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144128741.png" alt="image-20200722144128741"></p>
</li>
<li><p>选择输出到下一步的数据</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144224932.png" alt="image-20200722144224932"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144239822.png" alt="image-20200722144239822"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144446344.png" alt="image-20200722144446344"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144456628.png" alt="image-20200722144456628"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144531292.png" alt="image-20200722144531292"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144543660.png" alt="image-20200722144543660"></p>
</li>
</ul>
</li>
<li><p>step3：配置输出</p>
<ul>
<li><p>输出目标文件</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144706570.png" alt="image-20200722144706570"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144814951.png" alt="image-20200722144814951"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722144918502.png" alt="image-20200722144918502"></p>
</li>
<li><p>预览输出信息</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145005181.png" alt="image-20200722145005181"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145020311.png" alt="image-20200722145020311"></p>
</li>
</ul>
</li>
<li><p>step4：测试运行</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145128899.png" alt="image-20200722145128899"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145136836.png" alt="image-20200722145136836"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145204498.png" alt="image-20200722145204498"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145234929.png" alt="image-20200722145234929"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145300553.png" alt="image-20200722145300553"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145342524.png" alt="image-20200722145342524"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722145349915.png" alt="image-20200722145349915"></p>
</li>
</ul>
<h2 id="五、实战案例二"><a href="#五、实战案例二" class="headerlink" title="五、实战案例二"></a>五、实战案例二</h2><h3 id="1、需求-1"><a href="#1、需求-1" class="headerlink" title="1、需求"></a>1、需求</h3><ul>
<li>读取Excel文件中的数据，存储MySQL中</li>
</ul>
<h3 id="2、分析-1"><a href="#2、分析-1" class="headerlink" title="2、分析"></a>2、分析</h3><ul>
<li><p>这是一个转换程序</p>
</li>
<li><p>输入：读取这个Excel文件</p>
</li>
<li><p>转换：不需要实现转换</p>
</li>
<li><p>输出：存储到MySQL中的表中</p>
<ul>
<li><p>数据库：kettle_demo</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create database kettle_demo;</span><br></pre></td></tr></table></figure>

<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722155531955.png" alt="image-20200722155531955"></p>
</li>
<li><p>表：t_user</p>
<ul>
<li>让Kettle根据上游的数据自行创建</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3、实现-1"><a href="#3、实现-1" class="headerlink" title="3、实现"></a>3、实现</h3><ul>
<li><p>step1：构建转换流程图</p>
<ul>
<li><p>新建保存</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722153632700.png" alt="image-20200722153632700"></p>
</li>
<li><p>定义输入</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722153825528.png" alt="image-20200722153825528"></p>
</li>
<li><p>定义输出</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722153849321.png" alt="image-20200722153849321"></p>
</li>
</ul>
</li>
<li><p>step2：配置输入</p>
<ul>
<li><p>定义输入的数据</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154052274.png" alt="image-20200722154052274"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154130148.png" alt="image-20200722154130148"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154146185.png" alt="image-20200722154146185"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154157423.png" alt="image-20200722154157423"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154236283.png" alt="image-20200722154236283"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154317003.png" alt="image-20200722154317003"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154343906.png" alt="image-20200722154343906">、</p>
</li>
<li><p>定义输出的字段</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154439414.png" alt="image-20200722154439414"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154624225.png" alt="image-20200722154624225"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154639730.png" alt="image-20200722154639730"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154716523.png" alt="image-20200722154716523"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722154730317.png" alt="image-20200722154730317"></p>
</li>
</ul>
</li>
<li><p>step3：配置输出</p>
<ul>
<li><p>将连接MySQL的工具放入Kettle的lib目录中</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160018987.png" alt="image-20200722160018987"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160104092.png" alt="image-20200722160104092"></p>
</li>
<li><p>&#x3D;&#x3D;<strong>重新启动Kettle</strong>&#x3D;&#x3D;</p>
</li>
<li><p>构建MySQL连接：地址、用户名、密码、数据库</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722155803639.png" alt="image-20200722155803639"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160250214.png" alt="image-20200722160250214"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160310389.png" alt="image-20200722160310389"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160508104.png" alt="image-20200722160508104"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160529093.png" alt="image-20200722160529093"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160549087.png" alt="image-20200722160549087"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160559340.png" alt="image-20200722160559340"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160642263.png" alt="image-20200722160642263"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160657900.png" alt="image-20200722160657900"></p>
</li>
</ul>
</li>
<li><p>step4：测试运行</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160730805.png" alt="image-20200722160730805"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160739216.png" alt="image-20200722160739216"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160759504.png" alt="image-20200722160759504"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722160844136.png" alt="image-20200722160844136"></p>
</li>
</ul>
<h2 id="六、常用组件"><a href="#六、常用组件" class="headerlink" title="六、常用组件"></a>六、常用组件</h2><h3 id="1、共享数据库连接"><a href="#1、共享数据库连接" class="headerlink" title="1、共享数据库连接"></a>1、共享数据库连接</h3><ul>
<li>新建的数据库连接都只属于某一个转换程序</li>
<li>如果你想让所有的转换程序都能使用这个连接，需要开启共享</li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722165840910.png" alt="image-20200722165840910"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722165859797.png" alt="image-20200722165859797"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722165919365.png" alt="image-20200722165919365"></p>
<h3 id="2、表输入组件"><a href="#2、表输入组件" class="headerlink" title="2、表输入组件"></a>2、表输入组件</h3><ul>
<li><p>需求：将t_user中的数据，同步到t_user1这张表中</p>
</li>
<li><p>分析</p>
<ul>
<li>这是一个转换任务</li>
<li>输入：读取t_user表的数据</li>
<li>转换：没有转换过程</li>
<li>输出：将结果写入t_user1表中</li>
</ul>
</li>
<li><p>实现</p>
<ul>
<li><p>开发程序</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722164702600.png" alt="image-20200722164702600"></p>
</li>
<li><p>配置输入</p>
<ul>
<li>先配置数据库连接共享</li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722165958428.png" alt="image-20200722165958428"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170047492.png" alt="image-20200722170047492"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170105618.png" alt="image-20200722170105618"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170215354.png" alt="image-20200722170215354"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170330357.png" alt="image-20200722170330357"></p>
</li>
<li><p>配置输出</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170419413.png" alt="image-20200722170419413"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170438223.png" alt="image-20200722170438223"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170452804.png" alt="image-20200722170452804"></p>
</li>
<li><p>测试运行</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170536458.png" alt="image-20200722170536458"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170549399.png" alt="image-20200722170549399"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170622208.png" alt="image-20200722170622208"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722170632510.png" alt="image-20200722170632510"></p>
</li>
</ul>
</li>
</ul>
<h3 id="3、插入更新组件"><a href="#3、插入更新组件" class="headerlink" title="3、插入更新组件"></a>3、插入更新组件</h3><ul>
<li><p>工作需求：将 A表的数据同步到B表中，保证B表的数据与A表的数据一致，实现是不断更新的操作</p>
<ul>
<li>A表发生了更新，更新的数据也会同步到B表中</li>
<li>A表没有发生更新，即使程序运行，B表也不发生改变</li>
<li>数据同步的过程<ul>
<li>每次只同步更新的数据</li>
<li>已经同步过的数据，就不会再进行同步</li>
</ul>
</li>
<li>工作中一般一天会同步一次，程序就每天执行一次</li>
</ul>
</li>
<li><p>解决：插入更新的输出组件</p>
</li>
<li><p>功能：只会同步发生更新的数据，已经同步过的数据不会再次同步</p>
<ul>
<li>数据更新<ul>
<li>插入一条新的数据</li>
<li>更改一条老的数据</li>
</ul>
</li>
</ul>
</li>
<li><p>实现：将t_user表的数据同步到t_user2中【任何的时刻，这两张表 数据同步时是一致的】</p>
<ul>
<li><p>开发转化 任务流程图</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722172727176.png" alt="image-20200722172727176"></p>
</li>
<li><p>定义输入</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722172804528.png" alt="image-20200722172804528"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722172825165.png" alt="image-20200722172825165"></p>
</li>
<li><p>定义输出</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722173646566.png" alt="image-20200722173646566"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722173715767.png" alt="image-20200722173715767"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722173750781.png" alt="image-20200722173750781"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722173859869.png" alt="image-20200722173859869"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722173918025.png" alt="image-20200722173918025"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722173939760.png" alt="image-20200722173939760"></p>
</li>
<li><p>测试运行</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722173956739.png" alt="image-20200722173956739"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722174010199.png" alt="image-20200722174010199"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722174019228.png" alt="image-20200722174019228"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722174035354.png" alt="image-20200722174035354"></p>
</li>
<li><p>如果修改了t_user的数据，重新执行程序，观察t_user2中的数据是否与t_user是一致的</p>
<ul>
<li><p>修改t_user的数据</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722174237259.png" alt="image-20200722174237259"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722174257213.png" alt="image-20200722174257213"></p>
</li>
<li><p>重新运行程序</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722174325258.png" alt="image-20200722174325258"></p>
</li>
<li><p>观察t_user2的数据</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722174412978.png" alt="image-20200722174412978"></p>
</li>
</ul>
</li>
<li><p>同步业务</p>
<ul>
<li>全量：每次将所有的数据都同步一份<ul>
<li>保证A和B是一致的<ul>
<li>每次先删除B所有内容，然后，再同步</li>
</ul>
</li>
<li>程序的性能比较差，数据量大了以后，非常慢，不建议使用</li>
<li>表输出：全量的组件</li>
</ul>
</li>
<li>增量：每次将发生更新的数据同步，没有发生更新就是已经同步过的数据不再同步<ul>
<li>保证A和B是一致的</li>
<li>工作中都使用增量的方式</li>
<li>插入更新：增量的组件</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="七、Kettle-Job"><a href="#七、Kettle-Job" class="headerlink" title="七、Kettle Job"></a>七、Kettle Job</h2><h3 id="1、Job的功能"><a href="#1、Job的功能" class="headerlink" title="1、Job的功能"></a>1、Job的功能</h3><ul>
<li>转换：实现一种数据的转换处理，是一个转换任务</li>
<li>作业：实现多个转换任务按照一定的规则运行，就是一个任务流<ul>
<li>时间规则：从00:10分开始，每5种运行一次</li>
<li>依赖规则：A成功了，就执行B</li>
</ul>
</li>
<li>功能：将多个转换根据彼此之间的 关系实现任务流运行</li>
</ul>
<h3 id="2、Job的开发"><a href="#2、Job的开发" class="headerlink" title="2、Job的开发"></a>2、Job的开发</h3><ul>
<li><p>需求：每5s就运行一个Kettle的转换任务</p>
</li>
<li><p>实现</p>
<ul>
<li><p>构建一个作业</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722184809959.png" alt="image-20200722184809959"></p>
</li>
<li><p>配置转换任务</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185018655.png" alt="image-20200722185018655"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722184844483.png" alt="image-20200722184844483"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722184904596.png" alt="image-20200722184904596"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722184929577.png" alt="image-20200722184929577"></p>
</li>
<li><p>配置作业运行的规则</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185004590.png" alt="image-20200722185004590"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185211573.png" alt="image-20200722185211573"></p>
</li>
<li><p>运行</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185247683.png" alt="image-20200722185247683"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185310911.png" alt="image-20200722185310911"></p>
</li>
</ul>
</li>
</ul>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185421352.png" alt="image-20200722185421352"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185439558.png" alt="image-20200722185439558"></p>
<ul>
<li><p>扩展：多个转换任务，按照时间以及顺序运行</p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185634596.png" alt="image-20200722185634596"></p>
<p><img src="/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle.assets/image-20200722185754113.png" alt="image-20200722185754113"></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/14/Day02%EF%BC%9A%E5%8F%AF%E8%A7%86%E5%8C%96ETL%E5%B7%A5%E5%85%B7Kettle/" data-id="clj254b6c000000urhiaz72i0" data-title="Kettle" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Day01：数据库管理系统MySQL" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/13/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL/" class="article-date">
  <time class="dt-published" datetime="2023-06-13T08:06:42.989Z" itemprop="datePublished">2023-06-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/13/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL/">MySQL</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="数据库管理系统MySQL"><a href="#数据库管理系统MySQL" class="headerlink" title="数据库管理系统MySQL"></a>数据库管理系统MySQL</h1><h2 id="一、MySQL的介绍"><a href="#一、MySQL的介绍" class="headerlink" title="一、MySQL的介绍"></a>一、MySQL的介绍</h2><h3 id="1、大数据本质"><a href="#1、大数据本质" class="headerlink" title="1、大数据本质"></a>1、大数据本质</h3><ul>
<li>利用大数据的软件工具对大数据进行处理，从数据中挖掘价值</li>
</ul>
<h3 id="2、数据处理流程"><a href="#2、数据处理流程" class="headerlink" title="2、数据处理流程"></a>2、数据处理流程</h3><ul>
<li>数据采集：将产生各种数据进行统一化的存储</li>
<li>数据存储：将数据存储数据仓库中</li>
<li>数据处理：使用SQL开发语言开发程序对数据进行处理</li>
<li>数据应用：将处理好的结果进行 应用</li>
</ul>
<h3 id="3、数据存储及处理"><a href="#3、数据存储及处理" class="headerlink" title="3、数据存储及处理"></a>3、数据存储及处理</h3><ul>
<li>存储的形式：文件<ul>
<li>不能满足企业中对于数据处理需求</li>
</ul>
</li>
<li>工作需求：更加规范的数据存储、处理<ul>
<li>早期：Excel【表格，聚合统计分析，图表】</li>
<li>问题<ul>
<li>Excel能承载的数据量大小：MB<ul>
<li>实际工作中要处理的数据大小：GB</li>
</ul>
</li>
<li>Excel中提供的功能不能满足对数据处理的需求<ul>
<li>支持开发不同的功能</li>
<li>开发的方式不太友好</li>
</ul>
</li>
</ul>
</li>
<li>解决<ul>
<li>数据库管理系统</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4、数据库管理系统"><a href="#4、数据库管理系统" class="headerlink" title="4、数据库管理系统"></a>4、数据库管理系统</h3><ul>
<li>功能<ul>
<li>专门用户数据存储、处理数据的工具</li>
</ul>
</li>
<li>特点<ul>
<li>承载数据量会更大</li>
<li>更加规范化</li>
<li>功能更加全面</li>
<li>开发接口更加优化：SQL</li>
</ul>
</li>
<li>应用场景<ul>
<li>网站后台中存储商品信息、订单信息、用户注册 信息</li>
</ul>
</li>
</ul>
<h3 id="5、MySQL介绍及概念"><a href="#5、MySQL介绍及概念" class="headerlink" title="5、MySQL介绍及概念"></a>5、MySQL介绍及概念</h3><ul>
<li><p>常见的数据库管理系统</p>
<ul>
<li>Oracle：Sun公司商业化数据库产品，性能功能是最强大，但是是收费的商业化产品</li>
<li>SQL Server：微软公司的产品，受Windows局限性比较大 ，市场占有率并不高，收费</li>
<li>MySQL：Sun公司的社区产品，体积小，速度快，总体使用的成本比较低</li>
</ul>
</li>
<li><p>MySQL的介绍</p>
<ul>
<li>典型的市场占有率是最高的数据库管理系统</li>
<li>在国内非常广泛<ul>
<li>所有网站后台的存储</li>
</ul>
</li>
</ul>
</li>
<li><p>概念</p>
<ul>
<li><p>数据库管理系统</p>
<ul>
<li>专门用户存储和处理数据【结构化数据】的工具</li>
<li>MySQL就是一个数据库管理系统</li>
</ul>
</li>
<li><p>结构化数据</p>
<ul>
<li>例如：表格，行和列是固定的</li>
<li>行和列是固定的结构，就是数据的格式存在一定的规律</li>
</ul>
</li>
<li><p>数据库：MySQL中用于管理和区分数据表的单元</p>
<ul>
<li>database</li>
<li>理解为对数据进行分类存放的划分</li>
<li>数据库1：存放用户的数据</li>
<li>数据库2：存放商品的数据</li>
<li>数据库3：存放订单的数据</li>
<li>类似于一个Excel文件<ul>
<li>人事：人事的Excel文件</li>
<li>财务：财务的Excel文件</li>
</ul>
</li>
</ul>
</li>
<li><p>表格：MySQL中用于在数据库中划分数据的单元</p>
<ul>
<li>将数据进行更细的划分</li>
<li>类似于一个Excel文件中会有多张表<ul>
<li>人事Excel文件 <ul>
<li>在职人员信息表</li>
<li>离职人员信息表</li>
</ul>
</li>
<li>财务Excel文件<ul>
<li>报销信息表</li>
<li>收入信息表</li>
<li>报税信息表</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>数据库管理系统与Excel对比</p>
<table>
<thead>
<tr>
<th align="center">Excel</th>
<th align="center">MySQL</th>
</tr>
</thead>
<tbody><tr>
<td align="center">一个Excel文件</td>
<td align="center">一个数据库</td>
</tr>
<tr>
<td align="center">可以有多个Excel的sheet表格</td>
<td align="center">可以有多张数据表</td>
</tr>
<tr>
<td align="center">表格有行和列</td>
<td align="center">表格中有行和列</td>
</tr>
</tbody></table>
<ul>
<li>区别：<ul>
<li>MySQL功能更加强大</li>
<li>Excel的开发比较复杂</li>
<li>MySQL对数据进行处理：SQL</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>MySQL的使用</p>
<ul>
<li>SQL：开发语言，实现数据的存储以及分析管理</li>
</ul>
</li>
</ul>
<h2 id="二、MySQL及DataGrip部署"><a href="#二、MySQL及DataGrip部署" class="headerlink" title="二、MySQL及DataGrip部署"></a>二、MySQL及DataGrip部署</h2><h3 id="1、MySQL安装"><a href="#1、MySQL安装" class="headerlink" title="1、MySQL安装"></a>1、MySQL安装</h3><ul>
<li>参考MySQL安装文档实现安装</li>
</ul>
<h3 id="2、DataGrip的安装"><a href="#2、DataGrip的安装" class="headerlink" title="2、DataGrip的安装"></a>2、DataGrip的安装</h3><ul>
<li>功能：使用图形化界面的方式来操作MySQL，进行数据的管理</li>
<li>参考DataGrip安装文档实现安装</li>
</ul>
<h3 id="3、DataGrip连接MySQL"><a href="#3、DataGrip连接MySQL" class="headerlink" title="3、DataGrip连接MySQL"></a>3、DataGrip连接MySQL</h3><ul>
<li><p>创建一个连接，配置连接MySQL即可</p>
<ul>
<li><p>MySQL所在机器的地址和端口</p>
<ul>
<li>地址：localhost</li>
<li>端口：3306</li>
</ul>
</li>
<li><p>MySQL的连接驱动</p>
<ul>
<li>下载</li>
</ul>
</li>
<li><p>MySQL用户名和密码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">用户名：root</span><br><span class="line">密码：123456</span><br></pre></td></tr></table></figure>
</li>
<li><p>MySQL连接地址属性</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbc:mysql://localhost:3306?serverTimezone=UTC</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>参考视频或者课件中的图片实现连接</p>
</li>
</ul>
<h2 id="三、SQL介绍及其规则"><a href="#三、SQL介绍及其规则" class="headerlink" title="三、SQL介绍及其规则"></a>三、SQL介绍及其规则</h2><h3 id="1、SQL的介绍"><a href="#1、SQL的介绍" class="headerlink" title="1、SQL的介绍"></a>1、SQL的介绍</h3><ul>
<li><p>Struct Qurey Language：结构化查询语言</p>
</li>
<li><p>一种编程语言，是一种命令，通过这种命令或者编程语言开发程序来实现数据处理</p>
<ul>
<li>MySQL使用SQL命令来管理MySQL中数据</li>
</ul>
</li>
<li><p>SQL是所有RDBMS【关系型数据库管理系统】通用语言</p>
<ul>
<li>在语法上有一点点区别</li>
</ul>
</li>
</ul>
<h3 id="2、SQL的分类"><a href="#2、SQL的分类" class="headerlink" title="2、SQL的分类"></a>2、SQL的分类</h3><ul>
<li><p>MySQL中的SQL根据不同的功能模块划分不同的命令的分类</p>
</li>
<li><p>DDL：数据定义语言</p>
<ul>
<li>如何管理我们的数据库和表</li>
<li>数据库的管理：创建、删除、切换<ul>
<li>学生信息数据库</li>
</ul>
</li>
<li>表的管理：创建、删除、清空、描述<ul>
<li>学生表</li>
<li>成绩表</li>
<li>学籍表</li>
</ul>
</li>
</ul>
</li>
<li><p>DML：数据操作语言</p>
<ul>
<li>如何管理表中的数据</li>
<li>对表中数据实现以下功能<ul>
<li>插入：insert</li>
<li>更改：update</li>
<li>删除：delete</li>
</ul>
</li>
<li>例如<ul>
<li>录入学生信息</li>
<li>更改学生信息</li>
<li>删除学生信息</li>
</ul>
</li>
</ul>
</li>
<li><p>DQL：数据查询语言</p>
<ul>
<li><p>实现对表中数据的查询和统计分析</p>
</li>
<li><p>我们在工作中60%的开发都是开发SQL，有90%都是在开发DQL</p>
</li>
<li><p>select</p>
</li>
</ul>
</li>
</ul>
<h3 id="3、SQL的规则"><a href="#3、SQL的规则" class="headerlink" title="3、SQL的规则"></a>3、SQL的规则</h3><ul>
<li><p>所有的SQL语句都需要以分号来作为结束符，表示这条命令结束了，可以提交运行</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> databases;</span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mysql.user;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="四、SQL分析之DDL"><a href="#四、SQL分析之DDL" class="headerlink" title="四、SQL分析之DDL"></a>四、SQL分析之DDL</h2><h3 id="1、数据库管理"><a href="#1、数据库管理" class="headerlink" title="1、数据库管理"></a>1、数据库管理</h3><ul>
<li><p>创建</p>
<ul>
<li><p>功能：构建一个新的数据库</p>
</li>
<li><p>语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database [ if <span class="keyword">not</span> <span class="keyword">exists</span> ] 数据库的名字;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<ul>
<li><p>创建一个新的数据库叫做：itcast01</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database itcast01;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626202110922.png" alt="image-20200626202110922"></p>
</li>
<li><p>创建一个新的数据库：itcast02</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> itcast02;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626202312950.png" alt="image-20200626202312950"></p>
</li>
<li><p>if not exists：如果不存在的情况下，就创建，如果已经存在就不会创建</p>
<ul>
<li><p>功能：为了避免程序报错</p>
</li>
<li><p>如果不加：数据库已存在，就会报错</p>
</li>
<li><p>如果加了：数据库已存在，不会报错</p>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626202616343.png" alt="image-20200626202616343"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>列举</p>
<ul>
<li><p>功能：用于列举当前MySQL中所有的数据库名称</p>
</li>
<li><p>语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span>  databases;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626201927898.png" alt="image-20200626201927898"></p>
</li>
</ul>
</li>
<li><p>查看</p>
<ul>
<li><p>功能：查看当前所在的数据库</p>
</li>
<li><p>语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> database();</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626202921195.png" alt="image-20200626202921195"></p>
<ul>
<li>null表示我们当前不在任何一个数据库中</li>
</ul>
</li>
</ul>
</li>
<li><p>切换</p>
<ul>
<li><p>功能：切换到某个数据库中</p>
</li>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use 数据库名称;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<ul>
<li><p>切换到itcast01这个数据库中</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use itcast01;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626203115436.png" alt="image-20200626203115436"></p>
</li>
<li><p>切换到itcast02这个数据库中</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use itcast02;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626203205537.png" alt="image-20200626203205537"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>删除</p>
<ul>
<li><p>功能：删除已存在的一个数据库</p>
</li>
<li><p>语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> database [ if <span class="keyword">exists</span> ] 数据库名称;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<ul>
<li><p>删除itcast01这个数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span>  database itcast01;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626203451258.png" alt="image-20200626203451258"></p>
</li>
<li><p>if exists ：如果存在，就删除，如果不存在就不删除</p>
<ul>
<li><p>功能：为了避免程序报错</p>
</li>
<li><p>如果不加：数据库不存在，删除就会报错</p>
</li>
<li><p>如果加了：数据库不存在，删除不会报错</p>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626203741535.png" alt="image-20200626203741535"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2、数据表管理"><a href="#2、数据表管理" class="headerlink" title="2、数据表管理"></a>2、数据表管理</h3><ul>
<li><p>数据类型</p>
<ul>
<li><p>定义：用于描述表中列的一个数据格式</p>
</li>
<li><p>类型：</p>
<ul>
<li><p>字符类型：中文、英文或者比较长的数字、日期都可以使用字符串来存储</p>
<ul>
<li><p>字符类型是万能的类型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x27;a&#x27;：这就是一个字符，一个数字、一个英文字母、一个符号</span><br><span class="line">&#x27;abc,12344&#x27;：这就是一个字符串，很多个字符构成一个整体</span><br></pre></td></tr></table></figure>

<ul>
<li>字符串表示的数字是不能参与计算的</li>
</ul>
</li>
<li><p>&#x3D;&#x3D;只要是字符类型，就使用varchar（N）&#x3D;&#x3D;</p>
<ul>
<li>N表示字符串的长度，只能大不能小</li>
<li>手机号码：varchar（11）<ul>
<li>varchar（20）：可以</li>
<li>varchar(10)：不可以</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>数字类型</p>
<ul>
<li>整数<ul>
<li>整形：int</li>
<li>&#x3D;&#x3D;只要是整数就用：int&#x3D;&#x3D;</li>
</ul>
</li>
<li>小数<ul>
<li>单精度：float</li>
<li>双精度：double</li>
<li>&#x3D;&#x3D;只要是小数就用：double&#x3D;&#x3D;</li>
</ul>
</li>
</ul>
</li>
<li><p>日期类型</p>
<ul>
<li>日期是一种特殊的格式</li>
<li>&#x3D;&#x3D;date：用于存储年月日&#x3D;&#x3D;<ul>
<li>yyyy-MM-dd</li>
<li>2020-01-01</li>
</ul>
</li>
<li>&#x3D;&#x3D;datetime：用于存储年月日，时分秒&#x3D;&#x3D;<ul>
<li>yyyy-MM-dd HH:mm:ss</li>
<li>2020-01-01 12:30:50</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>创建</p>
<ul>
<li><p>功能：在某个数据库中创建一张，定义表的结构【表中哪些列以及每一列的类型】</p>
</li>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table [if not exists] [数据库名称.]表的名称(</span><br><span class="line">   col1 type1,</span><br><span class="line">   col2 type2,</span><br><span class="line">   col3 type3,</span><br><span class="line">   ……</span><br><span class="line">   colN typeN</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<ul>
<li>注意事项<ul>
<li>所有的符号都是英文的，不允许出现中文符号</li>
<li>除了最后一行就是结尾括号的前一号不用加逗号，其他的都要加逗号</li>
<li>每一列都要指定对应的类型<ul>
<li>字符串：varchar(N)</li>
<li>整数：int</li>
<li>小数：double</li>
<li>年月日日期：date</li>
<li>年月日时分秒：datetime</li>
</ul>
</li>
<li>如果不加数据库名称，表示在当前数据库中创建表</li>
</ul>
</li>
</ul>
</li>
<li><p>测试</p>
<ul>
<li><p>创建一张学生表student：学生学号、学生姓名、学生年龄、学生性别</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student(</span><br><span class="line">   stuid varchar(10),</span><br><span class="line">   stuname varchar(10),</span><br><span class="line">   age int,</span><br><span class="line">   sex varchar(2)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626211200711.png" alt="image-20200626211200711"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>列举</p>
<ul>
<li><p>功能：列举当前数据库中所有的表</p>
</li>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show tables;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200626210834791.png" alt="image-20200626210834791"></p>
<p>​	<img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629210140287.png" alt="image-20200629210140287"></p>
</li>
</ul>
</li>
<li><p>描述</p>
<ul>
<li><p>功能：查看一张表的详细的结构信息</p>
</li>
<li><p>语法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc  [dbname.]tbname;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">desc student;</span><br><span class="line">desc bigdata.student;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629210418658.png" alt="image-20200629210418658"></p>
</li>
</ul>
</li>
<li><p>删除</p>
<ul>
<li><p>功能：删除一张不需要再使用的表</p>
</li>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop table [ if exists ] [dbname.]tbname;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop table if exists student;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629211104002.png" alt="image-20200629211104002"></p>
</li>
</ul>
</li>
</ul>
<h2 id="五、SQL分析之DML"><a href="#五、SQL分析之DML" class="headerlink" title="五、SQL分析之DML"></a>五、SQL分析之DML</h2><h3 id="1、创建表格"><a href="#1、创建表格" class="headerlink" title="1、创建表格"></a>1、创建表格</h3><ul>
<li><p>创建一个商品的分类表：category</p>
<ul>
<li>分类编号：cid</li>
<li>分类名称：cname</li>
</ul>
</li>
<li><p>创建语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table category(</span><br><span class="line">  cid varchar(5),</span><br><span class="line">  cname varchar(10)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629212641728.png" alt="image-20200629212641728"></p>
</li>
</ul>
<h3 id="2、插入数据"><a href="#2、插入数据" class="headerlink" title="2、插入数据"></a>2、插入数据</h3><ul>
<li><p>功能：写入一条数据进入数据表</p>
</li>
<li><p>关键字：insert</p>
</li>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into tbname(co11,col2,col3……)  values(value1,value2,value3……);</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">insert into category(cid,cname) values(&#x27;c001&#x27;,&#x27;电器&#x27;);</span><br><span class="line">insert into category(cname) values(&#x27;服饰&#x27;);</span><br><span class="line">insert into category(cid,cname) values(null,&#x27;化妆品&#x27;);</span><br><span class="line">insert into category values(&#x27;c002&#x27;,&#x27;书籍&#x27;);</span><br><span class="line">insert into category values(null,&#x27;蔬菜&#x27;);</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629213403110.png" alt="image-20200629213403110"></p>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629214132789.png" alt="image-20200629214132789"></p>
<ul>
<li><p>查询某张表的所有内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from category;</span><br></pre></td></tr></table></figure>
</li>
<li><p>&#x3D;&#x3D;注意事项&#x3D;&#x3D;</p>
<ul>
<li>所给定的列的名称必须与后面的值一一对应</li>
<li>给定值的时候，除了数值类型或者null，其他类型必须加上单引号</li>
<li>给定的值不能超过创建表时定义的长度</li>
<li>如果要给表中的每一列都赋值，就可以不写列名</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3、更新数据"><a href="#3、更新数据" class="headerlink" title="3、更新数据"></a>3、更新数据</h3><ul>
<li><p>功能：修改数据表中的数据</p>
</li>
<li><p>关键字：update</p>
</li>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update 表的名称 set col1 = newValue,col2 = newValue …… [where 条件];</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<ul>
<li><p>需求1：将服饰的分类id更改为c003</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update  category set  cid = &#x27;c003&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629215253675.png" alt="image-20200629215253675"></p>
<ul>
<li>上面不能满足我们的需求，因为更改了其他不需要更改的数据</li>
<li>解决：加上where 条件<ul>
<li>只有满足where条件的数据才会被更改</li>
<li>没有指定where条件，就更改所有数据</li>
</ul>
</li>
</ul>
</li>
<li><p>需求2：将服饰的分类id更改为c004</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update category set cid = &#x27;c004&#x27; where cname = &#x27;服饰&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629215715473.png" alt="image-20200629215715473"></p>
</li>
<li><p>需求3：将化妆品的分类id更改为c001，并且将分类名称更改为化妆</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update category set cid=&#x27;c001&#x27;,cname=&#x27;化妆&#x27; where cname = &#x27;化妆品&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629215920737.png" alt="image-20200629215920737"></p>
</li>
<li><p>需求4：将所有 c003的分类名称更改为笔记本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update category set cname = &#x27;笔记本&#x27; where cid = &#x27;c003&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629220038167.png" alt="image-20200629220038167"></p>
</li>
<li><p>&#x3D;&#x3D;注意：&#x3D;&#x3D;</p>
<ul>
<li>更改的列的新的值必须与列的类型相符</li>
<li>新的值不能超过这一列的长度</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4、删除数据"><a href="#4、删除数据" class="headerlink" title="4、删除数据"></a>4、删除数据</h3><ul>
<li><p>功能：删除数据表中的数据</p>
</li>
<li><p>关键字：delete</p>
</li>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete from 表的名称  [where 条件];</span><br></pre></td></tr></table></figure>

<ul>
<li><p>如果不加where条件，会删除整张表所有的数据</p>
</li>
<li><p>where 条件：符合条件的数据将会被删除</p>
</li>
<li><p>需求1：删除所有分类名称为笔记本的分类数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete from category where cname = &#x27;笔记本&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629221111664.png" alt="image-20200629221111664"></p>
</li>
<li><p>需求2：删除分类id不为c001的分类的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete from category where cid != &#x27;c001&#x27;;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>清空表中所有的数据</p>
<ul>
<li><p>delete：用于删除表中的数据，一行一行删除</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">delete from category;</span><br></pre></td></tr></table></figure>
</li>
<li><p>truncate：用于清空整张表的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">truncate category;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200629221411664.png" alt="image-20200629221411664"></p>
</li>
<li><p>区别</p>
<ul>
<li>delete：DML命令，一条一条删除</li>
<li>truncate：DDL命令，类似于将整张表删除，然后重新创建一张一样的空表</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="六、SQL分析之DQL"><a href="#六、SQL分析之DQL" class="headerlink" title="六、SQL分析之DQL"></a>六、SQL分析之DQL</h2><h3 id="1、准备数据"><a href="#1、准备数据" class="headerlink" title="1、准备数据"></a>1、准备数据</h3><ul>
<li><p>创建测试数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> database if <span class="keyword">exists</span> bigdata;</span><br><span class="line"><span class="keyword">create</span> database bigdata;</span><br><span class="line">use bigdata;</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建商品表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> product(</span><br><span class="line"> pid <span class="type">int</span>,</span><br><span class="line"> pname <span class="type">varchar</span>(<span class="number">20</span>),</span><br><span class="line"> price <span class="keyword">double</span>,</span><br><span class="line"> category_id <span class="type">varchar</span>(<span class="number">32</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
</li>
<li><p>插入商品测试数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">1</span>,<span class="string">&#x27;联想&#x27;</span>,<span class="number">5000</span>,<span class="string">&#x27;c001&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">2</span>,<span class="string">&#x27;海尔&#x27;</span>,<span class="number">3000</span>,<span class="string">&#x27;c001&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">3</span>,<span class="string">&#x27;雷神&#x27;</span>,<span class="number">5000</span>,<span class="string">&#x27;c001&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">4</span>,<span class="string">&#x27;杰克琼斯&#x27;</span>,<span class="number">800</span>,<span class="string">&#x27;c002&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">5</span>,<span class="string">&#x27;真维斯&#x27;</span>,<span class="number">200</span>,<span class="string">&#x27;c002&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">6</span>,<span class="string">&#x27;花花公子&#x27;</span>,<span class="number">440</span>,<span class="string">&#x27;c002&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">7</span>,<span class="string">&#x27;劲霸&#x27;</span>,<span class="number">2000</span>,<span class="string">&#x27;c002&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">8</span>,<span class="string">&#x27;香奈儿&#x27;</span>,<span class="number">800</span>,<span class="string">&#x27;c003&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">9</span>,<span class="string">&#x27;相宜本草&#x27;</span>,<span class="number">200</span>,<span class="string">&#x27;c003&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">10</span>,<span class="string">&#x27;面霸&#x27;</span>,<span class="number">5</span>,<span class="string">&#x27;c003&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">11</span>,<span class="string">&#x27;好想你枣&#x27;</span>,<span class="number">56</span>,<span class="string">&#x27;c004&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">12</span>,<span class="string">&#x27;香飘飘奶茶&#x27;</span>,<span class="number">1</span>,<span class="string">&#x27;c005&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product(pid,pname,price,category_id) <span class="keyword">VALUES</span>(<span class="number">13</span>,<span class="string">&#x27;海澜之家&#x27;</span>,<span class="number">1</span>,<span class="string">&#x27;c002&#x27;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建商品分类类：categroy</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> category(</span><br><span class="line">  category_id <span class="type">varchar</span>(<span class="number">10</span>),</span><br><span class="line">  category_name <span class="type">varchar</span>(<span class="number">100</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
</li>
<li><p>插入商品分类测试数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> category <span class="keyword">values</span>(<span class="string">&#x27;c001&#x27;</span>,<span class="string">&#x27;电脑&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> category <span class="keyword">values</span>(<span class="string">&#x27;c002&#x27;</span>,<span class="string">&#x27;服装&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> category <span class="keyword">values</span>(<span class="string">&#x27;c003&#x27;</span>,<span class="string">&#x27;化妆品&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> category <span class="keyword">values</span>(<span class="string">&#x27;c004&#x27;</span>,<span class="string">&#x27;吃的&#x27;</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> category <span class="keyword">values</span>(<span class="string">&#x27;c005&#x27;</span>,<span class="string">&#x27;喝的&#x27;</span>);</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2、基本语法"><a href="#2、基本语法" class="headerlink" title="2、基本语法"></a>2、基本语法</h3><ul>
<li><p>功能：实现对于数据表中的数据的查询、统计分析、处理</p>
</li>
<li><p>关键字：select</p>
</li>
<li><p>语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">from</span> <span class="number">2</span> <span class="keyword">where</span> <span class="number">3</span> <span class="keyword">group</span> <span class="keyword">by</span> <span class="number">4</span> <span class="keyword">having</span> <span class="number">5</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="number">6</span> limit <span class="number">7</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>1：用于决定查询的结果中有哪些列，给定哪些列，结果就会显示这些列</p>
<ul>
<li>写列的名字，多列用逗号隔开</li>
<li>*号代表所有的列</li>
</ul>
</li>
<li><p>2：用于表示查询哪张表，给定表的名字</p>
</li>
<li><p>3：条件查询，只有满足条件的数据才会被返回</p>
<ul>
<li>不满足条件的数据会被过滤掉，不会在结果中显示</li>
<li>符合where条件的行才会在结果中显示</li>
</ul>
</li>
<li><p>4：用于实现分组的，将多条数据按照某一列或者多列进行分组，划分到同一组中</p>
<ul>
<li>用于实现统计分析</li>
<li>语法：group by col</li>
</ul>
</li>
<li><p>5：用于实现分组后的条件过滤</p>
<ul>
<li>功能类似于where</li>
<li>满足having后的条件就会出现在结果中</li>
<li>不满足条件就会被过滤掉</li>
<li>与where的区别<ul>
<li>where：分组之前过滤</li>
<li>having：分组之后过滤</li>
</ul>
</li>
</ul>
</li>
<li><p>6：用于实现将查询的结果按照某一列或者多列进行排序</p>
<ul>
<li>order by col  [ asc | desc]</li>
<li>asc：升序排序</li>
<li>desc：降序排序</li>
<li>如果不指定，默认是升序排序</li>
</ul>
</li>
<li><p>7：用于实现分页输出</p>
</li>
</ul>
</li>
</ul>
<h3 id="3、简单查询"><a href="#3、简单查询" class="headerlink" title="3、简单查询"></a>3、简单查询</h3><ul>
<li><p>查询所有的商品信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702152955689.png" alt="image-20200702152955689"></p>
</li>
<li><p>查询所有的商品名称和价格</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select pname,price from product;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702153232051.png" alt="image-20200702153232051"></p>
</li>
<li><p>查询所有的商品名称和价格，结果的列的名称分别为商品和价格</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select pname as &#x27;商品&#x27;, price as &#x27;价格&#x27; from product;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702153554316.png" alt="image-20200702153554316"></p>
<ul>
<li>as：用于给列或者表取别名</li>
</ul>
</li>
<li><p>查询所有商品的价格，并去掉重复价格</p>
<ul>
<li>查询所有商品价格</li>
</ul>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702153803436.png" alt="image-20200702153803436"></p>
<ul>
<li><p>去掉重复价格</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select distinct price from product;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702153930200.png" alt="image-20200702153930200"></p>
</li>
<li><p>distinct：用于对列值进行去重</p>
</li>
</ul>
</li>
<li><p>将所有商品的价格+10元显示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select price as &#x27;价格&#x27; , price + 10 as &#x27;新价格&#x27; from product;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702154219464.png" alt="image-20200702154219464"></p>
<ul>
<li>直接对数值类型的列进行运算<ul>
<li>加：+</li>
<li>减：-</li>
<li>乘：*</li>
<li>除：&#x2F;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4、条件查询：where"><a href="#4、条件查询：where" class="headerlink" title="4、条件查询：where"></a>4、条件查询：where</h3><ul>
<li><p>功能：对于数据行的过滤</p>
</li>
<li><p>查询商品名称为“花花公子”的商品所有信息 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where pname = &#x27;花花公子&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702155631783.png" alt="image-20200702155631783"></p>
</li>
<li><p>查询价格为800商品  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where price = 800;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702155805675.png" alt="image-20200702155805675"></p>
</li>
<li><p>查询价格不是800的所有商品</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from  product where  price != 800;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702160012180.png" alt="image-20200702160012180"></p>
</li>
<li><p>查询商品价格大于60元的所有商品信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where price &gt; 60;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702160137164.png" alt="image-20200702160137164"></p>
<ul>
<li><p>等于：&#x3D;</p>
</li>
<li><p>不等于：！&#x3D;</p>
</li>
<li><p>小于：&lt;</p>
</li>
<li><p>大于：&gt;</p>
</li>
<li><p>小于等于：&lt;&#x3D;</p>
</li>
<li><p>大于等于：&gt;&#x3D;</p>
</li>
</ul>
</li>
<li><p>查询商品价格在200到1000之间所有商品</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from product where price &gt;= 200 and price &lt;= 1000;</span><br><span class="line">select * from product where price between 200 and 1000;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702160548070.png" alt="image-20200702160548070"></p>
<ul>
<li>and：并列关系，两个条件都要满足</li>
</ul>
</li>
<li><p>查询商品价格是200或800的所有商品</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where price = 200 or price = 800;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702160828528.png" alt="image-20200702160828528"></p>
<ul>
<li>or：或者关系，两个条件满足其中一个即可</li>
</ul>
</li>
<li><p>查询含有’霸’字的所有商品</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where pname like &#x27;%霸%&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702161145607.png" alt="image-20200702161145607"></p>
<ul>
<li>%：任意多个字符</li>
</ul>
</li>
<li><p>查询以’香’开头的所有商品</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where pname like &#x27;香%&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702161427047.png" alt="image-20200702161427047"></p>
</li>
<li><p>查询第二个字为’想’的所有商品</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from  product where pname like &#x27;_想%&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702161702350.png" alt="image-20200702161702350"></p>
<ul>
<li>_：表示一个字符</li>
</ul>
</li>
<li><p>查询没有分类的商品</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into product values(14,&#x27;weiC 100&#x27;,9.9,null);</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702162050786.png" alt="image-20200702162050786"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where category_id is null;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702162218157.png" alt="image-20200702162218157"></p>
</li>
<li><p>查询有分类的商品</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where category_id is not null;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702162327329.png" alt="image-20200702162327329"></p>
</li>
</ul>
<h3 id="5、聚合查询"><a href="#5、聚合查询" class="headerlink" title="5、聚合查询"></a>5、聚合查询</h3><ul>
<li><p>聚合函数</p>
<ul>
<li>函数：MySQL为你定义好的功能，你只要调用这个命令就可以实现聚合功能</li>
<li>MYSQL默认为我们提供的常见的聚合函数<ul>
<li>count(colname)：统计某一列的行数，统计个数，null不参与统计</li>
<li>sum（colname）：计算某一列的所有值的和，只能对数值类型求和，如果不是数值，结果为0</li>
<li>max（colname）：计算某一列的所有值中的最大值</li>
<li>min（colname）：计算某一列的所有值中的最小值</li>
<li>avg（colname）：计算某一列的平均值</li>
</ul>
</li>
</ul>
</li>
<li><p>查询商品的总条数 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(pid) as &#x27;总个数&#x27; from product;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702201119336.png" alt="image-20200702201119336"></p>
</li>
<li><p>查询价格大于200商品的总条数 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(pid) as &#x27;大于200的商品个数&#x27; from product where price &gt; 200;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702201447950.png" alt="image-20200702201447950"></p>
</li>
<li><p>查询分类为’c001’的所有商品价格的总和  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select sum(price) as totalPrice from product where category_id = &#x27;c001&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702201649601.png" alt="image-20200702201649601"></p>
</li>
<li><p>查询分类为’c002’所有商品的平均价格 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select avg(price) as &#x27;平均价格&#x27; from product where category_id = &#x27;c002&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702201929937.png" alt="image-20200702201929937"></p>
</li>
<li><p>查询商品的最大价格和最小价格  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select max(price) as &#x27;最大价格&#x27;,min(price) as &#x27;最小价格&#x27; from product;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702202344072.png" alt="image-20200702202344072"></p>
</li>
</ul>
<h3 id="6、分组查询：gourp-by"><a href="#6、分组查询：gourp-by" class="headerlink" title="6、分组查询：gourp by"></a>6、分组查询：gourp by</h3><ul>
<li><p>关键字：group by col …… having</p>
</li>
<li><p>功能：按照某些列进行分组，对分组后的数据进行处理，一般都会搭配聚合函数使用</p>
</li>
<li><p>统计各个分类商品的个数  </p>
<ul>
<li><p>分析过程</p>
<ul>
<li><p>结果长什么样？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">category_id			个数</span><br><span class="line">c001				3</span><br><span class="line">c002				5</span><br><span class="line">c003				3</span><br><span class="line">c004				2</span><br><span class="line">c005				1</span><br></pre></td></tr></table></figure>
</li>
<li><p>按照什么分组？</p>
<ul>
<li>按照category_id进行分组</li>
</ul>
</li>
<li><p>统计每组商品的个数</p>
<ul>
<li>count</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select category_id,count(*) as &#x27;个数&#x27; from product group by category_id;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702203429283.png" alt="image-20200702203429283"></p>
</li>
<li><p>统计查询每种分类中的商品的最大价格和最小价格</p>
<ul>
<li>分析<ul>
<li>结果长什么样？<ul>
<li>三列：分类的id		最大价格			最小价格</li>
</ul>
</li>
<li>按照分类的id进行分组</li>
<li>统计每个分组内部的最大价格和最小价格</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select  </span><br><span class="line">    category_id,</span><br><span class="line">    max(price) as maxprice,</span><br><span class="line">    min(price) as minprice   </span><br><span class="line">from </span><br><span class="line">    product  </span><br><span class="line">group by </span><br><span class="line">    category_id;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702203945489.png" alt="image-20200702203945489"></p>
</li>
<li><p>统计各个分类商品的个数,且只显示个数大于1的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select category_id,count(*) as &#x27;个数&#x27; from product group by category_id;</span><br></pre></td></tr></table></figure>

<ul>
<li>需要对分组后的结果再进行行的过滤</li>
<li>where：实现对数据行的过滤，指定条件<ul>
<li>这个需求中不能使用where</li>
<li>因为where会在group by之前执行，而个数是在分组之后才产生的列</li>
</ul>
</li>
<li>having：实现对数据行的过滤，指定条件，写法与where一致<ul>
<li>用于分组之后结果数据的过滤</li>
<li>对分组以后的 结果进行过滤</li>
</ul>
</li>
<li>什么时候用where，什么时候用having<ul>
<li>你要过滤的条件是分组之前就存在的，还是分组以后才产生的</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select category_id,count(*) as &#x27;个数&#x27; from product group by category_id having count(*) &gt; 1;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702204613303.png" alt="image-20200702204613303"></p>
</li>
</ul>
<h3 id="7、排序查询：order-by"><a href="#7、排序查询：order-by" class="headerlink" title="7、排序查询：order by"></a>7、排序查询：order by</h3><ul>
<li><p>关键字：order by col…… 【 asc | desc】</p>
</li>
<li><p>功能：将结果按照某些列进行升序或者 降序的排序来显示</p>
<ul>
<li>默认是升序</li>
<li>asc：升序</li>
<li>desc：降序</li>
</ul>
</li>
<li></li>
<li><p>查询所有商品的信息，并按照价格降序排序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product order by  price desc;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702205645391.png" alt="image-20200702205645391"></p>
</li>
<li><p>查询所有商品的信息，并按照价格排序(降序)，如果价格相同，以分类排序(降序)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product order by price desc,category_id desc;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702205923524.png" alt="image-20200702205923524"></p>
</li>
<li><p>统计各个分类商品的个数 ，并按照个数降序排序</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> category_id,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> <span class="string">&#x27;个数&#x27;</span> <span class="keyword">from</span> product <span class="keyword">group</span> <span class="keyword">by</span> category_id;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702210133787.png" alt="image-20200702210133787"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> category_id,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> <span class="string">&#x27;个数&#x27;</span> <span class="keyword">from</span> product <span class="keyword">group</span> <span class="keyword">by</span> category_id <span class="keyword">order</span> <span class="keyword">by</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702210257846.png" alt="image-20200702210257846"></p>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702210324695.png" alt="image-20200702210324695"></p>
</li>
</ul>
<h3 id="8、分页查询：limit"><a href="#8、分页查询：limit" class="headerlink" title="8、分页查询：limit"></a>8、分页查询：limit</h3><ul>
<li><p>关键字：limit</p>
</li>
<li><p>功能：限制输出的结果</p>
</li>
<li><p>语法：limit M,N</p>
<ul>
<li>M：你想从第M+1条开始显示</li>
<li>N：显示N条</li>
<li>显示第一条到第三条<ul>
<li>M：0</li>
<li>N：3</li>
</ul>
</li>
<li>显示第9条到第10条<ul>
<li>M：8</li>
<li>N：2</li>
</ul>
</li>
<li>如果从第一条开始，M为0，可以省略不写<ul>
<li>limit N</li>
</ul>
</li>
</ul>
</li>
<li><p>查询product表的前5条记录</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product limit <span class="number">0</span>,<span class="number">5</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product limit <span class="number">5</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702211351033.png" alt="image-20200702211351033"></p>
</li>
<li><p>查询product表的第4条和第5条记录</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product limit <span class="number">3</span>,<span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>  <img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702211507141.png" alt="image-20200702211507141"></p>
</li>
<li><p>查询商品个数最多的分类的前三名</p>
<ul>
<li><p>查询所有商品分类的商品个数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> category_id,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> numb  <span class="keyword">from</span> product <span class="keyword">group</span> <span class="keyword">by</span> category_id;</span><br></pre></td></tr></table></figure>
</li>
<li><p>对上一步做排序</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> category_id,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> numb  <span class="keyword">from</span> product <span class="keyword">group</span> <span class="keyword">by</span> category_id <span class="keyword">order</span> <span class="keyword">by</span> numb <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>limit选择前三名</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> category_id,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> numb  <span class="keyword">from</span> product <span class="keyword">group</span> <span class="keyword">by</span> category_id <span class="keyword">order</span> <span class="keyword">by</span> numb <span class="keyword">desc</span> limit <span class="number">3</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702211811837.png" alt="image-20200702211811837"></p>
</li>
</ul>
</li>
</ul>
<h3 id="9、结果保存"><a href="#9、结果保存" class="headerlink" title="9、结果保存"></a>9、结果保存</h3><ul>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into 表的名称   select……</span><br></pre></td></tr></table></figure>
</li>
<li><p>功能：将一条select语句运行的结果写入一张表中</p>
</li>
<li><p>注意：结果表的列一定要与Select语句的结果的列要匹配</p>
<ul>
<li>列的名称可以不一样</li>
<li>但是列的类型和个数必须一一对应</li>
</ul>
</li>
<li><p>统计各个分类商品的个数 ，并按照个数降序排序，并将结果进行保存</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">  category_id,</span><br><span class="line">  <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> numb</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">  product</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">  category_id</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">  numb <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702213032264.png" alt="image-20200702213032264"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--创建一张表用于存储分析的结果</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">result</span> (</span><br><span class="line">  cid <span class="type">varchar</span>(<span class="number">100</span>),</span><br><span class="line">  numb <span class="type">int</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702213133496.png" alt="image-20200702213133496"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--将分析的结果存储在这张表中</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">result</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">  category_id,</span><br><span class="line">  <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> numb</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">  product</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">  category_id</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">  numb <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702213315008.png" alt="image-20200702213315008"></p>
</li>
</ul>
<h2 id="七、多表关系与查询"><a href="#七、多表关系与查询" class="headerlink" title="七、多表关系与查询"></a>七、多表关系与查询</h2><h3 id="1、多表关系"><a href="#1、多表关系" class="headerlink" title="1、多表关系"></a>1、多表关系</h3><ul>
<li>电商数据库<ul>
<li>用户表<ul>
<li>用户id、用户名称、用户手机……</li>
</ul>
</li>
<li>商品表<ul>
<li>商品id、商品名称、商品价格、库存、尺寸……</li>
</ul>
</li>
<li>订单表<ul>
<li>订单id、用户id、商品id、总金额、支付方式</li>
</ul>
</li>
</ul>
</li>
<li>员工数据库<ul>
<li>员工表<ul>
<li>员工id、员工姓名、员工性别、年龄、部门id……</li>
</ul>
</li>
<li>部门表<ul>
<li>部门id、部门名称、部门位置、部门领导……</li>
</ul>
</li>
<li>员工和部门之间的关系<ul>
<li>员工属于某一个部门</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702220547447.png" alt="image-20200702220547447"></p>
<ul>
<li>表与表之间通过某些列来实现关联，表现数据之间的关系</li>
</ul>
<h3 id="2、join"><a href="#2、join" class="headerlink" title="2、join"></a>2、join</h3><ul>
<li><p>功能：通过两张表之间关联的列，实现将两张表的列进行合并</p>
</li>
<li><p>关键字：A    join B   on  条件</p>
</li>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select 查询的两张表的哪些列  from A表  join  B表  on 关联条件;</span><br></pre></td></tr></table></figure>
</li>
<li><p>本质：通过某种列的关系，将两张表的列进行了关联</p>
</li>
<li><p>需求1：查询每个商品的名称以及所属分类的名称</p>
<ul>
<li><p>分析结果长什么样？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">商品名称			分类名称</span><br><span class="line">联想					电脑</span><br><span class="line">……</span><br><span class="line">weiC 100			 吃的</span><br></pre></td></tr></table></figure>
</li>
<li><p>问题：商品名称 属于商品表，分类名称属于分类表</p>
</li>
<li><p>关系：分类id：categor_id</p>
</li>
<li><p>查询</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--将商品表与分类表通过分类id进行关联，并显示两张表的所有列</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">   a.<span class="operator">*</span>,</span><br><span class="line">   b.<span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">   product <span class="keyword">as</span> a <span class="keyword">join</span> category <span class="keyword">as</span> b <span class="keyword">on</span> a.category_id <span class="operator">=</span> b.category_id;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702222803025.png" alt="image-20200702222803025"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">  a.pname,</span><br><span class="line">  b.category_name</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">  product a <span class="keyword">join</span> category b <span class="keyword">on</span> a.category_id <span class="operator">=</span> b.category_id;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702223043014.png" alt="image-20200702223043014"></p>
</li>
</ul>
</li>
<li><p>需求2：统计每个分类名称对应的商品个数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">  b.category_name,</span><br><span class="line">  <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> numb</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">  product a <span class="keyword">join</span> category b <span class="keyword">on</span> a.category_id <span class="operator">=</span> b.category_id</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">  b.category_name;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702223505148.png" alt="image-20200702223505148"></p>
</li>
<li><p>需求3：统计除了吃的分类以外的所有分类的商品个数，并显示个数最多的前三个分类</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">   b.category_name,</span><br><span class="line">   <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> numb</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">   product a <span class="keyword">join</span> category b <span class="keyword">on</span> a.category_id <span class="operator">=</span> b.category_id</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">   b.category_name <span class="operator">!=</span> <span class="string">&#x27;吃的&#x27;</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">   b.category_name</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">   numb <span class="keyword">desc</span></span><br><span class="line">limit <span class="number">3</span>;</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702224023108.png" alt="image-20200702224023108"></p>
</li>
<li><p>分类</p>
<ul>
<li><p>inner join：内连接，inner可以省略</p>
<ul>
<li>关联条件中，两张表都有这个值，结果就有</li>
<li>类似于集合中两个集合的交集</li>
</ul>
</li>
<li><p>left outer join：左外连接，outer可以省略</p>
<ul>
<li><p>关联条件中，左表中有，结果就有</p>
</li>
<li><p>类似于集合中左表的全集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">  a.pname,</span><br><span class="line">  b.category_name</span><br><span class="line">from</span><br><span class="line">  product a left join category b on a.category_id = b.category_id;</span><br></pre></td></tr></table></figure>

<ul>
<li>左表是product，右表是category</li>
<li>如果product表中有一条数据的category_id是c006，而category中没有</li>
<li>结果有</li>
</ul>
</li>
</ul>
</li>
<li><p>right   outer join：右外连接，outer可以省略</p>
<ul>
<li><p>关联条件中，右表中有，结果就有</p>
</li>
<li><p>类似于集合中右表的全集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">  a.pname,</span><br><span class="line">  b.category_name</span><br><span class="line">from</span><br><span class="line">  product a right join category b on a.category_id = b.category_id;</span><br></pre></td></tr></table></figure>

<ul>
<li>左表是product，右表是category</li>
<li>如果category表中有一条数据的category_id是c006，而product中没有</li>
<li>结果有</li>
</ul>
</li>
</ul>
</li>
<li><p>full   join：全连接</p>
<ul>
<li>关联条件中，两张表任意一边有，结果就有</li>
<li>类似于集合中的两张表全集</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3、子查询"><a href="#3、子查询" class="headerlink" title="3、子查询"></a>3、子查询</h3><ul>
<li><p>功能：在select语句中嵌套select语句</p>
</li>
<li><p>需求1：查询化妆品这个分类对应的所有商品信息</p>
<ul>
<li>分析结果长什么样？<ul>
<li>所有商品信息：product</li>
</ul>
</li>
<li>条件：化妆品这个分类对应的商品<ul>
<li>化妆品：category</li>
</ul>
</li>
<li>解决：先获取化妆品对应的分类id，然后根据分类id到商品表中查询这个分类id对应的商品</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select category_id from category where category_name = &#x27;化妆品&#x27;;</span><br><span class="line">select * from product where category_id = &#x27;c003&#x27;;</span><br></pre></td></tr></table></figure>

<p>|</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from product where category_id = (select category_id from category where category_name = &#x27;化妆品&#x27;);</span><br></pre></td></tr></table></figure>

<ul>
<li>先执行内层的SQL语句</li>
<li>然后执行外层的SQL语句</li>
</ul>
<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702230753367.png" alt="image-20200702230753367"></p>
</li>
<li><p>需求2：查询相宜本草对应的分类的名称</p>
<ul>
<li>结果：显示分类的 名称：category</li>
<li>条件：相宜本草  pname：product</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--先查询相宜本草对应的分类id</span><br><span class="line">select category_id from product where pname = &#x27;相宜本草&#x27;;</span><br><span class="line">--根据分类id到分类表中查询分类的名称</span><br><span class="line">select category_name from category where category_id = &#x27;c003&#x27;;</span><br><span class="line">|</span><br><span class="line">select category_name from category where category_id = (select category_id from product where pname = &#x27;相宜本草&#x27;);</span><br></pre></td></tr></table></figure>

<p><img src="/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL.assets/image-20200702231153230.png" alt="image-20200702231153230"></p>
</li>
<li><p>join与子查询的应用场景</p>
<ul>
<li>如果你的查询结果包含多张表的列<ul>
<li>join</li>
</ul>
</li>
<li>如果你的查询结果只有一张表的列，条件来自于别的表<ul>
<li>子查询</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/13/Day01%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9FMySQL/" data-id="clj254b6q000600ur54xq7xkr" data-title="MySQL" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/06/hello-world/" class="article-date">
  <time class="dt-published" datetime="2023-06-06T07:12:57.129Z" itemprop="datePublished">2023-06-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/06/06/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/06/06/hello-world/" data-id="clj254b6p000500ur2slf5xzj" data-title="Hello World" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  

</section>
        <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/06/19/Sqoop/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/06/19/Spark%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/06/19/Hive3%E5%AE%89%E8%A3%85/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/06/19/flume/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/06/19/Docker%E5%AE%9E%E7%94%A8%E7%AF%87/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li></ul>
    </div>
  </div>

  
</aside>
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 By Autoload<br>
      Driven - <a href="https://hexo.io/" target="_blank">Hexo</a>|Theme - <a href="https://github.com/autoload/hexo-theme-auto" target="_blank">Auto</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>